<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>AWS Rust SDK Design</title>
        <meta name="robots" content="noindex" />


        <!-- Custom HTML head -->
        
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="overview.html"><strong aria-hidden="true">1.</strong> Design Overview</a></li><li class="chapter-item expanded "><a href="tenets.html"><strong aria-hidden="true">2.</strong> Tenets</a></li><li class="chapter-item expanded "><a href="faq.html"><strong aria-hidden="true">3.</strong> Design FAQ</a></li><li class="chapter-item expanded "><a href="transport/overview.html"><strong aria-hidden="true">4.</strong> Transport</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="transport/operation.html"><strong aria-hidden="true">4.1.</strong> HTTP Operations</a></li><li class="chapter-item expanded "><a href="transport/middleware.html"><strong aria-hidden="true">4.2.</strong> HTTP Middleware</a></li></ol></li><li class="chapter-item expanded "><a href="smithy/overview.html"><strong aria-hidden="true">5.</strong> Smithy</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="smithy/simple_shapes.html"><strong aria-hidden="true">5.1.</strong> Simple Shapes</a></li><li class="chapter-item expanded "><a href="smithy/recursive_shapes.html"><strong aria-hidden="true">5.2.</strong> Recursive Shapes</a></li><li class="chapter-item expanded "><a href="smithy/aggregate_shapes.html"><strong aria-hidden="true">5.3.</strong> Aggregate Shapes</a></li><li class="chapter-item expanded "><a href="smithy/endpoint.html"><strong aria-hidden="true">5.4.</strong> Endpoint Resolution</a></li><li class="chapter-item expanded "><a href="smithy/backwards-compat.html"><strong aria-hidden="true">5.5.</strong> Backwards Compatibility</a></li></ol></li><li class="chapter-item expanded "><a href="rfcs/overview.html"><strong aria-hidden="true">6.</strong> RFCs</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="rfcs/rfc0001_shared_config.html"><strong aria-hidden="true">6.1.</strong> RFC-0001: Sharing configuration between multiple clients</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0002_http_versions.html"><strong aria-hidden="true">6.2.</strong> RFC-0002: Supporting multiple HTTP versions for SDKs that use Event Stream</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0003_presigning_api.html"><strong aria-hidden="true">6.3.</strong> RFC-0003: API for Pre-signed URLs</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0004_retry_behavior.html"><strong aria-hidden="true">6.4.</strong> RFC-0004: Retry Behavior</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0005_service_generation.html"><strong aria-hidden="true">6.5.</strong> RFC-0005: Smithy Rust service framework</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0006_service_specific_middleware.html"><strong aria-hidden="true">6.6.</strong> RFC-0006: Service-specific middleware</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0007_split_release_process.html"><strong aria-hidden="true">6.7.</strong> RFC-0007: Split release process</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0008_paginators.html"><strong aria-hidden="true">6.8.</strong> RFC-0008: Paginators</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0009_example_consolidation.html"><strong aria-hidden="true">6.9.</strong> RFC-0009: Example Consolidation</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0010_waiters.html"><strong aria-hidden="true">6.10.</strong> RFC-0010: Waiters</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0011_crates_io_alpha_publishing.html"><strong aria-hidden="true">6.11.</strong> RFC-0011: Publishing Alpha to Crates.io</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0012_independent_crate_versioning.html"><strong aria-hidden="true">6.12.</strong> RFC-0012: Independent Crate Versioning</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0013_body_callback_apis.html"><strong aria-hidden="true">6.13.</strong> RFC-0013: Body Callback APIs</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0014_timeout_config.html"><strong aria-hidden="true">6.14.</strong> RFC-0014: Fine-grained timeout configuration</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0015_using_features_responsibly.html"><strong aria-hidden="true">6.15.</strong> RFC-0015: How Cargo "features" should be used in the SDK and runtime crates</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0016_flexible_checksum_support.html"><strong aria-hidden="true">6.16.</strong> RFC-0016: Supporting Flexible Checksums</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0017_customizable_client_operations.html"><strong aria-hidden="true">6.17.</strong> RFC-0017: Customizable Client Operations</a></li></ol></li><li class="chapter-item expanded "><a href="contributing/overview.html"><strong aria-hidden="true">7.</strong> Contributing</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="contributing/writing_and_debugging_a_low-level_feature_that_relies_on_HTTP.html"><strong aria-hidden="true">7.1.</strong> Writing and debugging a low-level feature that relies on HTTP</a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">AWS Rust SDK Design</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="design-overview"><a class="header" href="#design-overview">Design Overview</a></h1>
<p>The AWS Rust SDK aims to provide an official, high quality &amp; complete interface to AWS services. We plan to eventually use the CRT to provide signing &amp; credential management. The Rust SDK will provide first-class support for the CRT as well as <a href="https://tokio.rs/">Tokio </a> &amp; <a href="https://hyper.rs">Hyper</a>. The Rust SDK empowers advanced customers to bring their own HTTP/IO implementations.</p>
<p>Our design choices are guided by our <a href="./tenets.html">Tenets</a>.</p>
<h2 id="acknowledgments"><a class="header" href="#acknowledgments">Acknowledgments</a></h2>
<p>The design builds on the learnings, ideas, hard work, and GitHub issues of the 142 Rusoto contributors &amp; thousands of users who built this first and learned the hard way.</p>
<h2 id="external-api-overview"><a class="header" href="#external-api-overview">External API Overview</a></h2>
<p>The Rust SDK is &quot;modular&quot; meaning that each AWS service is its own crate. Each crate provides two layers to access the service:</p>
<ol>
<li>The &quot;fluent&quot; API. For most use cases, a high level API that ties together connection management and serialization will be the quickest path to success.</li>
</ol>
<pre><pre class="playground"><code class="language-rust">#[tokio::main]
async fn main() {
    let client = dynamodb::Client::from_env();
    let tables = client
        .list_tables()
        .limit(10)
        .send()
        .await.expect(&quot;failed to load tables&quot;);
}
</code></pre></pre>
<ol start="2">
<li>The &quot;low-level&quot; API: It is also possible for customers to assemble the pieces themselves. This offers more control over operation construction &amp; dispatch semantics:</li>
</ol>
<pre><pre class="playground"><code class="language-rust">#[tokio::main]
async fn main() {
    let conf = dynamodb::Config::builder().build();
    let conn = aws_hyper::Client::https();
    let operation = dynamodb::ListTables::builder()
        .limit(10)
        .build(&amp;conf)
        .expect(&quot;invalid operation&quot;);
    let tables = conn.call(operation).await.expect(&quot;failed to list tables&quot;);
}
</code></pre></pre>
<p>The Fluent API is implemented as a thin wrapper around the core API to improve ergonomics.</p>
<h2 id="internals"><a class="header" href="#internals">Internals</a></h2>
<p>The Rust SDK is built on Tower Middleware, Tokio &amp; Hyper. We're continuing to iterate on the internals to enable running the AWS SDK in other executors &amp; HTTP stacks. As an example, you can see a demo of adding <code>reqwest</code> as a custom HTTP stack to gain access to its HTTP Proxy support!</p>
<p>For more details about the SDK internals see <a href="transport/operation.html">Operation Design</a></p>
<h2 id="code-generation"><a class="header" href="#code-generation">Code Generation</a></h2>
<p>The Rust SDK is code generated from Smithy models, using Smithy codegeneration utilities. The Code generation is written in Kotlin. More details can be found in the <a href="./smithy/overview.html">Smithy</a> section.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rust-sdk-design-tenets"><a class="header" href="#rust-sdk-design-tenets">Rust SDK Design Tenets</a></h1>
<blockquote>
<p>Unless you know better ones! These are our tenets today, but we'd love your thoughts. Do you wish we had different priorities? Let us know by opening and issue or starting a discussion.</p>
</blockquote>
<ol>
<li><a href="tenets.html#batteries-included-but-replaceable"><strong>Batteries included, but replaceable.</strong></a> The AWS SDK for Rust should provide a best-in-class experience for many use cases, <strong>but</strong>, customers will use the SDK in unique and unexpected ways. <strong>Meet customers where they are;</strong> strive to be compatible with their tools. Provide mechanisms to allow customers make different choices.</li>
<li><a href="tenets.html#make-common-problems-easy-to-solve"><strong>Make common problems easy to solve.</strong></a> The AWS SDK for Rust should make common problems solvable. Guide customers to patterns that set them up for long-term success.</li>
<li><a href="tenets.html#design-for-the-future"><strong>Design for the Future.</strong></a> The AWS SDK for Rust should evolve with AWS without breaking existing customers. APIs will evolve in unpredictable directions, new protocols will gain adoption, and new services will be created that we never could have imagined. Don’t simplify or unify code today that prevents evolution tomorrow.</li>
</ol>
<h2 id="details-justifications-and-ramifications"><a class="header" href="#details-justifications-and-ramifications">Details, Justifications, and Ramifications</a></h2>
<h3 id="batteries-included-but-replaceable"><a class="header" href="#batteries-included-but-replaceable">Batteries included, but replaceable.</a></h3>
<p>Some customers will use the Rust SDK as their first experience with async Rust, potentially <strong>any</strong> Rust. They may not be familiar with Tokio or the concept of an async executor. We are not afraid to have an opinion about the best solution for most customers.</p>
<p>Other customers will come to the SDK with specific requirements. Perhaps they're integrating the SDK into a much larger project that uses <code>async_std</code>. Maybe they need to set custom headers, modify the user agent, or audit every request. They should be able to use the Rust SDK without forking it to meet their needs.</p>
<h3 id="make-common-problems-easy-to-solve"><a class="header" href="#make-common-problems-easy-to-solve">Make common problems easy to solve</a></h3>
<p>If solving a common problem isn’t obvious from the API, it should be obvious from the documentation. The SDK should guide users towards the best solutions for common tasks, <strong>first</strong> with well named methods, <strong>second</strong> with documentation, and <strong>third</strong> with real -world usage examples. Provide misuse resistant APIs. Async Rust has the potential to introduce subtle bugs; the Rust SDK should help customers avoid them.</p>
<h3 id="design-for-the-future"><a class="header" href="#design-for-the-future">Design for the Future</a></h3>
<p>APIs evolve in unpredictable ways, and it's crucial that the SDK can evolve without breaking existing customers. This means designing the SDK so that fundamental changes to the internals can be made without altering the external interface we surface to customers:</p>
<ul>
<li>Keeping the shared core as small &amp; opaque as possible.</li>
<li>Don’t leak our internal dependencies to customers</li>
<li>With every design choice, consider, &quot;Can I reverse this choice in the future?&quot;</li>
</ul>
<p>This may not result in DRY code, and that’s OK! Code that is auto generated has different goals and tradeoffs than code that has been written by hand.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="design-faq"><a class="header" href="#design-faq">Design FAQ</a></h1>
<h2 id="what-is-smithy"><a class="header" href="#what-is-smithy">What is Smithy?</a></h2>
<p>Smithy is the interface design language used by AWS services. <code>smithy-rs</code> allows users to generate a Rust client for any
Smithy based service (pending protocol support), including those outside of AWS.</p>
<h2 id="why-is-there-one-crate-per-service"><a class="header" href="#why-is-there-one-crate-per-service">Why is there one crate per service?</a></h2>
<ol>
<li>
<p><strong>Compilation time:</strong> Although it's possible to use cargo features to conditionally compile individual services, we
decided that this added significant complexity to the generated code. In Rust the &quot;unit of compilation&quot; is a Crate,
so by using smaller crates we can get better compilation parallelism. Furthermore, ecosystem services like <code>docs.rs</code>
have an upper limit on the maximum amount of time required to build an individual crate—if we packaged the entire SDK
as a single crate, we would quickly exceed this limit.</p>
</li>
<li>
<p><strong>Versioning:</strong> It is expected that over time we may major-version-bump individual services. New updates will be pushed
for <em>some</em> AWS service nearly every day. Maintaining separate crates allows us to only increment versions for the
relevant pieces that change. See <a href="./rfcs/rfc0012_independent_crate_versioning.html">Independent Crate Versioning</a> for
more info.</p>
</li>
</ol>
<h2 id="why-dont-the-sdk-service-crates-implement-serdeserialize-or-serdedeserialize-for-any-types"><a class="header" href="#why-dont-the-sdk-service-crates-implement-serdeserialize-or-serdedeserialize-for-any-types">Why don't the SDK service crates implement <code>serde::Serialize</code> or <code>serde::Deserialize</code> for any types?</a></h2>
<ol>
<li>
<p><strong>Compilation time:</strong> <code>serde</code> makes heavy use of <a href="https://crates.io/crates/serde_derive/1.0.136/dependencies">several crates</a>
<em>(<code>proc-macro2</code>, <code>quote</code>, and <code>syn</code>)</em> that are very expensive to compile. Several service crates are already quite large
and adding a <code>serde</code> dependency would increase compile times beyond what we consider acceptable. When we last checked,
adding <code>serde</code> derives made compilation 23% slower.</p>
</li>
<li>
<p><strong>Misleading results:</strong> We can't use <code>serde</code> for serializing requests to AWS or deserializing responses from AWS because
both sides of that process would require too much customization. Adding serialize/deserialize impls for operations has
the potential to confuse users when they find it doesn't actually capture all the necessary information (like headers and
trailers) sent in a request or received in a response.</p>
</li>
</ol>
<p>In the future, we may add <code>serde</code> support behind a feature gate. However, we would only support this for operation <code>Input</code>
and <code>Output</code> structs with the aim of making SDK-related tests easier to set up and run.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="transport"><a class="header" href="#transport">Transport</a></h1>
<p>The transport layer of smithy-rs and the Rust SDK. Our goal is support customers to bring their own HTTP stack and runtime.</p>
<h2 id="where-we-are-today"><a class="header" href="#where-we-are-today">Where we are today</a></h2>
<p><code>aws-hyper</code> assembles a middleware stack with <code>tower</code>. It provides a way to use an HTTP client other than Hyper, however, it currently has a hard dependency on Hyper &amp; Tokio. <code>hyper::Body</code> is being used directly as the body implementation for responses.</p>
<h2 id="where-we-want-to-go"><a class="header" href="#where-we-want-to-go">Where we want to go</a></h2>
<ol>
<li>Extend <code>HttpService</code> to add a <code>sleep</code> method. This is required to enable runtimes other than Tokio to define how they should sleep.</li>
<li>Replace <code>hyper::Body</code> in responses with SDK Body. For now, SDKBody will probably privately wrap <code>hyper::Body</code>.</li>
<li>Merge <code>aws-hyper</code> into <code>aws-http</code>. Tokio becomes an optional feature—When the Tokio feature is opted out the &quot;fast path&quot; variants for the connection variants are <code>cfg</code>'d out.</li>
<li>By default, customers get a fully baked HTTP stack, but they can opt out of certain features and BYO implementation of <code>HttpService</code>.</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="http-based-operations"><a class="header" href="#http-based-operations">HTTP-based Operations</a></h1>
<p>The Smithy code generator for Rust (and by extension), the AWS SDK use an <code>Operation</code> abstraction to provide a unified
interface for dispatching requests. <code>Operation</code>s contain:</p>
<ul>
<li>A base HTTP request (with a potentially streaming body)</li>
<li>A typed property bag of configuration options</li>
<li>A fully generic response handler</li>
</ul>
<p>In the typical case, these configuration options include things like a <code>CredentialsProvider</code>, however, they can also be
full middleware layers that will get added by the dispatch stack.</p>
<h2 id="operation-phases"><a class="header" href="#operation-phases">Operation Phases</a></h2>
<p>This section details the flow of a request through the SDK until a response is returned to the user.</p>
<h3 id="input-construction"><a class="header" href="#input-construction">Input Construction</a></h3>
<p>A customer interacts with the SDK builders to construct an input. The <code>build()</code> method on an input returns
an <code>Operation&lt;Output&gt;</code>. This codifies the base HTTP request &amp; all the configuration and middleware layers required to modify and dispatch the request.</p>
<pre><code class="language-rust ignore">pub struct Operation&lt;H, R&gt; {
    request: Request,
    response_handler: H,
    _retry_policy: R,
}

pub struct Request {
    inner: http::Request&lt;SdkBody&gt;,
    properties: PropertyBag,
}
</code></pre>
<p>For most requests, <code>.build()</code> will NOT consume the input. A user can call <code>.build()</code> multiple times to produce multiple operations from the same input.</p>
<p>By using a property bag, we can define the <code>Operation</code> in Smithy core. AWS specific configuration can be added later in the stack.</p>
<h3 id="operation-construction"><a class="header" href="#operation-construction">Operation Construction</a></h3>
<p>In order to construct an operation, the generated code injects appropriate middleware &amp; configuration via the configuration property bag. It does this by reading the configuration properties out of the service
config, copying them as necessary, and loading them into the <code>Request</code>:</p>
<pre><code class="language-rust ignore">// This is approximately the generated code, I've cleaned a few things up for readability.
pub fn build(self, config: &amp;dynamodb::config::Config) -&gt; Operation&lt;BatchExecuteStatement&gt; {
    let op = BatchExecuteStatement::new(BatchExecuteStatementInput {
        statements: self.statements,
    });
    let req = op.build_http_request().map(SdkBody::from);

    let mut req = operation::Request::new(req);
    let mut props = req.properties_mut();
    props.insert_signing_config(config.signing_service());
    props.insert_endpoint_resolver(config.endpoint_resolver.clone());
    Operation::new(req)
}
</code></pre>
<h3 id="operation-dispatch-and-middleware"><a class="header" href="#operation-dispatch-and-middleware">Operation Dispatch and Middleware</a></h3>
<p>The Rust SDK endeavors to behave as predictably as possible. This means that if at all possible we will not dispatch extra HTTP requests during the dispatch of normal operation. Making this work is covered in more detail in the design of credentials providers &amp; endpoint resolution.</p>
<p>The upshot is that we will always prefer a design where the user has explicit control of when credentials are loaded and endpoints are resolved. This doesn't mean that users can't use easy-to-use options (We will provide an automatically refreshing credentials provider), however, the credential provider won't load requests during the dispatch of an individual request.</p>
<h2 id="operation-parsing-and-response-loading"><a class="header" href="#operation-parsing-and-response-loading">Operation Parsing and Response Loading</a></h2>
<p>The fundamental trait for HTTP-based protocols is <code>ParseHttpResponse</code></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="http-middleware"><a class="header" href="#http-middleware">HTTP middleware</a></h1>
<p>Signing, endpoint specification, and logging are all handled as middleware. The Rust SDK takes a minimalist approach to middleware:</p>
<p>Middleware is defined as minimally as possible, then adapted into the middleware system used by the IO layer. Tower is the de facto standard for HTTP middleware in Rust—we will probably use it. But we also want to make our middleware usable for users who aren't using Tower (or if we decide to not use Tower in the long run).</p>
<p>Because of this, rather than implementing all our middleware as &quot;Tower Middleware&quot;, we implement it narrowly (e.g. as a function that operates on <code>operation::Request</code>), then define optional adapters to make our middleware tower compatible.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="smithy"><a class="header" href="#smithy">Smithy</a></h1>
<p>The Rust SDK uses Smithy models and code generation tooling to generate an SDK. Smithy is an open source IDL (interface design language) developed by Amazon. Although the Rust SDK uses Smithy models for AWS services, smithy-rs and Smithy models in general are not AWS specific.</p>
<p>Design documentation here covers both our implementation of Smithy Primitives (e.g. simple shape) as well as more complex Smithy traits like <a href="smithy/./endpoint.html">Endpoint</a>.</p>
<h2 id="internals-1"><a class="header" href="#internals-1">Internals</a></h2>
<p>Smithy introduces a few concepts that are defined here:</p>
<ol>
<li>
<p>Shape: The core Smithy primitive. A smithy model is composed of nested shapes defining an API.</p>
</li>
<li>
<p><code>Symbol</code>: A Representation of a type including namespaces &amp; and any dependencies required to use a type. A shape can be converted into a symbol by a <code>SymbolVisitor</code>. A <code>SymbolVisitor</code> maps shapes to types in your programming language (e.g. Rust). In the Rust SDK, see <a href="https://github.com/awslabs/smithy-rs/blob/c049a37f8cba5f9bec2e96c28db83e7efb2edc53/codegen/src/main/kotlin/software/amazon/smithy/rust/codegen/smithy/SymbolVisitor.kt">SymbolVisitor.kt</a>. Symbol visitors are composable—many specific behaviors are mixed in via small &amp; focused symbol providers, e.g. support for the streaming trait is mixed in separately.</p>
</li>
<li>
<p><code>Writer</code>: Writers are code generation primitives that collect code prior to being written to a file. Writers enable language specific helpers to be added to simplify codegen for a given language. For example, <code>smithy-rs</code> adds <code>rustBlock</code> to <a href="https://github.com/awslabs/smithy-rs/blob/908dec558e26bbae6fe4b7d9d1c221dd81699b59/codegen/src/main/kotlin/software/amazon/smithy/rust/codegen/rustlang/RustWriter.kt"><code>RustWriter</code></a> to create a &quot;Rust block&quot; of code.</p>
<pre><code class="language-kotlin">writer.rustBlock(&quot;struct Model&quot;) {
    model.fields.forEach {
        write(&quot;${field.name}: #T&quot;, field.symbol)
    }
}
</code></pre>
<p>This would produce something like:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct Model {
   field1: u32,
   field2: String
}
<span class="boring">}
</span></code></pre></pre>
</li>
<li>
<p>Generators: A Generator, e.g. <code>StructureGenerator</code>, <code>UnionGenerator</code> generates more complex Rust code from a Smithy model. Protocol generators pull these individual tools together to generate code for an entire service / protocol.</p>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="simple-shapes"><a class="header" href="#simple-shapes">Simple Shapes</a></h1>
<div class="table-wrapper"><table><thead><tr><th>Smithy Type (links to design discussions)</th><th>Rust Type (links to Rust documentation)</th></tr></thead><tbody>
<tr><td>blob</td><td><code>Vec&lt;u8&gt;</code></td></tr>
<tr><td>boolean</td><td><a href="https://doc.rust-lang.org/std/primitive.bool.html"><code>bool</code></a></td></tr>
<tr><td><a href="smithy/simple_shapes.html#strings">string</a></td><td><a href="https://doc.rust-lang.org/std/string/struct.String.html"><code>String</code></a></td></tr>
<tr><td>byte</td><td><code>i8</code></td></tr>
<tr><td>short</td><td><code>i16</code></td></tr>
<tr><td>integer</td><td><code>i32</code></td></tr>
<tr><td>long</td><td><code>i64</code></td></tr>
<tr><td>float</td><td><code>f32</code></td></tr>
<tr><td>double</td><td><code>f64</code></td></tr>
<tr><td><a href="smithy/simple_shapes.html#big-numbers">bigInteger</a></td><td><code>BigInteger</code> (Not implemented yet)</td></tr>
<tr><td><a href="smithy/simple_shapes.html#big-numbers">bigDecimal</a></td><td><code>BigDecimal</code> (Not implemented yet)</td></tr>
<tr><td><a href="smithy/simple_shapes.html#timestamps">timestamp</a></td><td><a href="https://github.com/awslabs/smithy-rs/blob/main/rust-runtime/aws-smithy-types/src/date_time/mod.rs"><code>DateTime</code></a></td></tr>
<tr><td><a href="smithy/simple_shapes.html#documents">document</a></td><td><a href="https://github.com/awslabs/smithy-rs/blob/v0.14/rust-runtime/aws-smithy-types/src/lib.rs#L38-L52"><code>Document</code></a></td></tr>
</tbody></table>
</div>
<h3 id="big-numbers"><a class="header" href="#big-numbers">Big Numbers</a></h3>
<p>Rust currently has no standard library or universally accepted large-number crate. Until one is stabilized, a string representation is a reasonable compromise:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct BigInteger(String);
pub struct BigDecimal(String);
<span class="boring">}
</span></code></pre></pre>
<p>This will enable us to add helpers over time as requested. Users will also be able to define their own conversions into their preferred large-number libraries.</p>
<p>As of 5/23/2021 BigInteger / BigDecimal are not included in AWS models. Implementation is tracked <a href="https://github.com/awslabs/smithy-rs/issues/312">here</a>.</p>
<h3 id="timestamps"><a class="header" href="#timestamps">Timestamps</a></h3>
<p><a href="https://github.com/chronotope/chrono">chrono</a> is the current de facto library for datetime in Rust, but it is pre-1.0. DateTimes are represented by an SDK defined structure modeled on <code>std::time::Duration</code> from the Rust standard library.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span>
<span class="boring">fn main() {
</span>/// DateTime in time.
///
/// DateTime in time represented as seconds and sub-second nanos since
/// the Unix epoch (January 1, 1970 at midnight UTC/GMT).
///
/// This type can be converted to/from the standard library's [`SystemTime`](std::time::SystemTime):
/// ```rust
/// # fn doc_fn() -&gt; Result&lt;(), aws_smithy_types::date_time::ConversionError&gt; {
/// # use aws_smithy_types::date_time::DateTime;
/// # use std::time::SystemTime;
/// use std::convert::TryFrom;
///
/// let the_millennium_as_system_time = SystemTime::try_from(DateTime::from_secs(946_713_600))?;
/// let now_as_date_time = DateTime::from(SystemTime::now());
/// # Ok(())
/// # }
/// ```
///
/// The [`aws-smithy-types-convert`](https://crates.io/crates/aws-smithy-types-convert) crate
/// can be used for conversions to/from other libraries, such as
/// [`time`](https://crates.io/crates/time) or [`chrono`](https://crates.io/crates/chrono).
#[derive(Debug, PartialEq, Clone, Copy)]
pub struct DateTime {
    seconds: i64,
    subsecond_nanos: u32,
}

<span class="boring">}
</span></code></pre></pre>
<p>Functions in the <code>aws-smithy-types-convert</code> crate provide conversions to other crates, such as <code>time</code> or <code>chrono</code>.</p>
<h3 id="strings"><a class="header" href="#strings">Strings</a></h3>
<p>Rust has two different String representations:</p>
<ul>
<li><code>String</code>, an owned, heap allocated string.</li>
<li><code>&amp;str</code>, a reference to a string, owned elsewhere.</li>
</ul>
<p>In ideal world, input shapes, where there is no reason for the strings to be owned would use <code>&amp;'a str</code>. Outputs would likely use <code>String</code>. However, Smithy does not provide a distinction between input and output shapes.</p>
<p>A third compromise could be storing <code>Arc&lt;String&gt;</code>, an atomic reference counted pointer to a <code>String</code>. This may be ideal for certain advanced users, but is likely to confuse most users and produces worse ergonomics. <em>This is an open design area where we will seek user feedback.</em> Rusoto uses <code>String</code> and there has been <a href="https://github.com/rusoto/rusoto/issues/1806">one feature request</a> to date to change that.</p>
<p>Current models represent strings as <code>String</code>.</p>
<h3 id="document-types"><a class="header" href="#document-types">Document Types</a></h3>
<p>Smithy defines the concept of &quot;Document Types&quot;:</p>
<blockquote>
<p>[Documents represent] protocol-agnostic open content that is accessed like JSON data. Open content is useful for modeling unstructured data that has no schema, data that can't be modeled using rigid types, or data that has a schema that evolves outside of the purview of a model. The serialization format of a document is an implementation detail of a protocol and MUST NOT have any effect on the types exposed by tooling to represent a document value.</p>
</blockquote>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span>
<span class="boring">fn main() {
</span>/// Document Type
///
/// Document types represents protocol-agnostic open content that is accessed like JSON data.
/// Open content is useful for modeling unstructured data that has no schema, data that can't be
/// modeled using rigid types, or data that has a schema that evolves outside of the purview of a model.
/// The serialization format of a document is an implementation detail of a protocol.
#[derive(Debug, Clone, PartialEq)]
pub enum Document {
    /// JSON object
    Object(HashMap&lt;String, Document&gt;),
    /// JSON array
    Array(Vec&lt;Document&gt;),
    /// JSON number
    Number(Number),
    /// JSON string
    String(String),
    /// JSON boolean
    Bool(bool),
    /// JSON null
    Null,
}

/// A number type that implements Javascript / JSON semantics, modeled on serde_json:
/// &lt;https://docs.serde.rs/src/serde_json/number.rs.html#20-22&gt;
#[derive(Debug, Clone, Copy, PartialEq)]
pub enum Number {
    /// Unsigned 64-bit integer value
    PosInt(u64),
    /// Signed 64-bit integer value
    NegInt(i64),
    /// 64-bit floating-point value
    Float(f64),
}

macro_rules! to_num_fn {
    ($name:ident, $typ:ident, $styp:expr) =&gt; {
        #[doc = &quot;Converts to a `&quot;]
        #[doc = $styp]
        #[doc = &quot;`. This conversion may be lossy.&quot;]
        pub fn $name(self) -&gt; $typ {
            match self {
                Number::PosInt(val) =&gt; val as $typ,
                Number::NegInt(val) =&gt; val as $typ,
                Number::Float(val) =&gt; val as $typ,
            }
        }
    };

    ($name:ident, $typ:ident) =&gt; {
        to_num_fn!($name, $typ, stringify!($typ));
    };
}

impl Number {
    to_num_fn!(to_f32, f32);
    to_num_fn!(to_f64, f64);

    to_num_fn!(to_i8, i8);
    to_num_fn!(to_i16, i16);
    to_num_fn!(to_i32, i32);
    to_num_fn!(to_i64, i64);

    to_num_fn!(to_u8, u8);
    to_num_fn!(to_u16, u16);
    to_num_fn!(to_u32, u32);
    to_num_fn!(to_u64, u64);
}

<span class="boring">}
</span></code></pre></pre>
<p>Individual protocols define their own document serialization behavior, with some protocols such as AWS and EC2 Query not supporting document types.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="recursive-shapes"><a class="header" href="#recursive-shapes">Recursive Shapes</a></h1>
<blockquote>
<p>Note: Throughout this document, the word &quot;box&quot; always refers to a Rust <a href="https://doc.rust-lang.org/std/boxed/struct.Box.html"><code>Box&lt;T&gt;</code></a>, a heap allocated pointer to T, and not the Smithy concept of boxed vs. unboxed.</p>
</blockquote>
<p>Recursive shapes pose a problem for Rust, because the following Rust code will not compile:</p>
<pre><pre class="playground"><code class="language-rust compile_fail"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct TopStructure {
    intermediate: IntermediateStructure
}

struct IntermediateStructure {
    top: Option&lt;TopStructure&gt;
}
<span class="boring">}
</span></code></pre></pre>
<pre><code class="language-rust ignore">  |
3 | struct TopStructure {
  | ^^^^^^^^^^^^^^^^^^^ recursive type has infinite size
4 |     intermediate: IntermediateStructure
  |     ----------------------------------- recursive without indirection
  |
  = help: insert indirection (e.g., a `Box`, `Rc`, or `&amp;`) at some point to make `main::TopStructure` representable
</code></pre>
<p>This occurs because Rust types must be a size known at compile time. The way around this, as the message suggests, is to Box the offending type. <code>smithy-rs</code> implements this design in <a href="https://github.com/awslabs/smithy-rs/blob/main/codegen/src/main/kotlin/software/amazon/smithy/rust/codegen/smithy/transformers/RecursiveShapeBoxer.kt">RecursiveShapeBoxer.kt</a></p>
<p>To support this, as the message suggests, we must &quot;<code>Box</code>&quot; the offending type. There is a touch of trickiness—only one element in the cycle needs to be boxed, but we need to select it deterministically such that we always pick the same element between multiple codegen runs. To do this the Rust SDK will:</p>
<ol>
<li>Topologically sort the graph of shapes.</li>
<li>Identify cycles that do not pass through an existing Box<T>, List, Set, or Map</li>
<li>For each cycle, select the earliest shape alphabetically &amp; mark it as Box<T> in the Smithy model by attaching the custom <code>RustBoxTrait</code> to the member.</li>
<li>Go back to step 1.</li>
</ol>
<p>This would produce valid Rust:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct TopStructure {
    intermediate: IntermediateStructure
}

struct IntermediateStructure {
    top: Box&lt;Option&lt;TopStructure&gt;&gt;
}
<span class="boring">}
</span></code></pre></pre>
<p><strong>Backwards Compatibility Note!</strong></p>
<p>Box<T> is not generally compatible with T in Rust. There are several unlikely but valid model changes that will cause the SDK to produce code that may break customers. If these are problematic, all are avoidable with customizations.</p>
<ol>
<li>
<p>A recursive link is added to an existing structure. This causes a member that was not boxed before to become Box<T>.</p>
<blockquote>
<p><strong>Workaround</strong>: Mark the new member as Box<T> in a customization.</p>
</blockquote>
</li>
<li>
<p>A field is removed from a structure that removes the recursive dependency. The SDK would generate T instead of Box<T>.</p>
<blockquote>
<p><strong>Workaround</strong>: Mark the member that used to be boxed as Box<T> in a customization. The Box will be unnecessary, but we will keep it for backwards compatibility.</p>
</blockquote>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="aggregate-shapes"><a class="header" href="#aggregate-shapes">Aggregate Shapes</a></h1>
<div class="table-wrapper"><table><thead><tr><th>Smithy Type</th><th>Rust Type</th></tr></thead><tbody>
<tr><td><a href="smithy/aggregate_shapes.html#list">List</a></td><td><code>Vec&lt;Member&gt;</code></td></tr>
<tr><td><a href="smithy/aggregate_shapes.html#set">Set</a></td><td><code>Vec&lt;Member&gt;</code></td></tr>
<tr><td><a href="smithy/aggregate_shapes.html#map">Map</a></td><td><code>HashMap&lt;String, Value&gt;</code></td></tr>
<tr><td><a href="smithy/aggregate_shapes.html#structure">Structure</a></td><td><code>struct</code></td></tr>
<tr><td><a href="smithy/aggregate_shapes.html#union">Union</a></td><td><code>enum</code></td></tr>
</tbody></table>
</div>
<p>Most generated types are controlled by <a href="https://github.com/awslabs/smithy-rs/blob/main/codegen/src/main/kotlin/software/amazon/smithy/rust/codegen/smithy/SymbolVisitor.kt">SymbolVisitor</a>.</p>
<h2 id="list"><a class="header" href="#list">List</a></h2>
<p>List objects in Smithy are transformed into vectors in Rust. Based on the output of the <a href="https://awslabs.github.io/smithy/javadoc/1.5.1/software/amazon/smithy/model/knowledge/NullableIndex.html">NullableIndex</a>, the generated list may be <code>Vec&lt;T&gt;</code> or <code>Vec&lt;Option&lt;T&gt;&gt;</code>.</p>
<h2 id="set"><a class="header" href="#set">Set</a></h2>
<p>Because floats are not Hashable in Rust, for simplicity smithy-rs translates all sets to into <code>Vec&lt;T&gt;</code> instead of <code>HashSet&lt;T&gt;</code>. In the future, a breaking change may be made to introduce a library-provided wrapper type for Sets.</p>
<h2 id="map"><a class="header" href="#map">Map</a></h2>
<p>Because <code>key</code> MUST be a string in Smithy maps, we avoid the hashibility issue encountered with <code>Set</code>. There are optimizations that could be considered (e.g. since these maps will probably never be modified), however, pending customer feedback, Smithy Maps become <code>HashMap&lt;String, V&gt;</code> in Rust.</p>
<h2 id="structure"><a class="header" href="#structure">Structure</a></h2>
<blockquote>
<p>See <code>StructureGenerator.kt</code> for more details</p>
</blockquote>
<p>Smithy <code>structure</code> becomes a <code>struct</code> in Rust. Backwards compatibility &amp; usability concerns lead to a few design choices:</p>
<ol>
<li>As specified by <code>NullableIndex</code>, fields are <code>Option&lt;T&gt;</code> when Smithy models them as nullable.</li>
<li>All structs are marked <code>#[non_exhaustive]</code></li>
<li>All structs derive <code>Debug</code> &amp; <code>PartialEq</code>. Structs <strong>do not</strong> derive <code>Eq</code> because a <code>float</code> member may be added in the future.</li>
<li>Struct fields are public. Public struct fields allow for <a href="https://doc.rust-lang.org/nomicon/borrow-splitting.html">split borrows</a>. When working with output objects this significantly improves ergonomics, especially with optional fields.
<code>rust,ignore let out = dynamo::ListTablesOutput::new(); out.some_field.unwrap(); // &lt;- partial move, impossible with an accessor </code></li>
<li>Builders are generated for structs that provide ergonomic and backwards compatible constructors. A builder for a struct is always available via the convenience method <code>SomeStruct::builder()</code></li>
<li>Structures manually implement debug: In order to support the <a href="https://awslabs.github.io/smithy/1.0/spec/core/documentation-traits.html#sensitive-trait">sensitive trait</a>, a <code>Debug</code> implementation for structures is manually generated.</li>
</ol>
<h3 id="example-structure-output"><a class="header" href="#example-structure-output">Example Structure Output</a></h3>
<p><strong>Smithy Input</strong>:</p>
<pre><code class="language-java">@documentation(&quot;&lt;p&gt;Contains I/O usage metrics...&quot;)
structure IOUsage {
    @documentation(&quot;... elided&quot;)
    ReadIOs: ReadIOs,
    @documentation(&quot;... elided&quot;)
    WriteIOs: WriteIOs
}

long ReadIOs

long WriteIOs
</code></pre>
<p><strong>Rust Output</strong>:</p>
<pre><code class="language-rust ignore">/// &lt;p&gt;Contains I/O usage metrics for a command that was invoked.&lt;/p&gt;
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct IOUsage {
    /// &lt;p&gt;The number of read I/O requests that the command made.&lt;/p&gt;
    pub read_i_os: i64,
    /// &lt;p&gt;The number of write I/O requests that the command made.&lt;/p&gt;
    pub write_i_os: i64,
}
impl std::fmt::Debug for IOUsage {
    fn fmt(&amp;self, f: &amp;mut std::fmt::Formatter&lt;'_&gt;) -&gt; std::fmt::Result {
        let mut formatter = f.debug_struct(&quot;IOUsage&quot;);
        formatter.field(&quot;read_i_os&quot;, &amp;self.read_i_os);
        formatter.field(&quot;write_i_os&quot;, &amp;self.write_i_os);
        formatter.finish()
    }
}
/// See [`IOUsage`](crate::model::IOUsage)
pub mod io_usage {
    /// A builder for [`IOUsage`](crate::model::IOUsage)
    #[non_exhaustive]
    #[derive(Debug, Clone, Default)]
    pub struct Builder {
        read_i_os: std::option::Option&lt;i64&gt;,
        write_i_os: std::option::Option&lt;i64&gt;,
    }
    impl Builder {
        /// &lt;p&gt;The number of read I/O requests that the command made.&lt;/p&gt;
        pub fn read_i_os(mut self, inp: i64) -&gt; Self {
            self.read_i_os = Some(inp);
            self
        }
        pub fn set_read_i_os(mut self, inp: i64) -&gt; Self {
            self.read_i_os = Some(inp);
            self
        }
        /// &lt;p&gt;The number of write I/O requests that the command made.&lt;/p&gt;
        pub fn write_i_os(mut self, inp: i64) -&gt; Self {
            self.write_i_os = Some(inp);
            self
        }
        pub fn set_write_i_os(mut self, inp: i64) -&gt; Self {
            self.write_i_os = Some(inp);
            self
        }
        /// Consumes the builder and constructs a [`IOUsage`](crate::model::IOUsage)
        pub fn build(self) -&gt; crate::model::IOUsage {
            crate::model::IOUsage {
                read_i_os: self.read_i_os.unwrap_or_default(),
                write_i_os: self.write_i_os.unwrap_or_default(),
            }
        }
    }
}
impl IOUsage {
    /// Creates a new builder-style object to manufacture [`IOUsage`](crate::model::IOUsage)
    pub fn builder() -&gt; crate::model::io_usage::Builder {
        crate::model::io_usage::Builder::default()
    }
}
</code></pre>
<h2 id="union"><a class="header" href="#union">Union</a></h2>
<p>Smithy <code>Union</code> is modeled as <code>enum</code> in Rust.</p>
<pre><code>1. Generated `enum`s must be marked `#[non_exhaustive]`.
2. Generated `enum`s must provide an `Unknown` variant. If parsing receives an unknown input that doesn't match any of the given union variants, `Unknown` should be constructed. [Tracking Issue](https://github.com/awslabs/smithy-rs/issues/185).
1. Union members (enum variants) are **not** nullable, because Smithy union members cannot contain null values.
2. When union members contain references to other shapes, we generate a wrapping variant (see below).
3. Union members do not require `#[non_exhaustive]`, because changing the shape targeted by a union member is not backwards compatible.
4. `is_variant` and `as_variant` helper functions are generated to improve ergonomics.
</code></pre>
<h3 id="generated-union-example"><a class="header" href="#generated-union-example">Generated Union Example</a></h3>
<p>The union generated for a simplified <code>dynamodb::AttributeValue</code>
<strong>Smithy</strong>:</p>
<pre><code class="language-java">namespace test

union AttributeValue {
    @documentation(&quot;A string value&quot;)
    string: String,
    bool: Boolean,
    bools: BoolList,
    map: ValueMap
}

map ValueMap {
    key: String,
    value: AttributeValue
}

list BoolList {
    member: Boolean
}
</code></pre>
<p><strong>Rust</strong>:</p>
<pre><code class="language-rust ignore">#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub enum AttributeValue {
    /// a string value
    String(std::string::String),
    Bool(bool),
    Bools(std::vec::Vec&lt;bool&gt;),
    Map(std::collections::HashMap&lt;std::string::String, crate::model::AttributeValue&gt;),
}

impl AttributeValue {
    pub fn as_bool(&amp;self) -&gt; Result&lt;&amp;bool, &amp;crate::model::AttributeValue&gt; {
        if let AttributeValue::Bool(val) = &amp;self { Ok(&amp;val) } else { Err(self) }
    }
    pub fn is_bool(&amp;self) -&gt; bool {
        self.as_bool().is_some()
    }
    pub fn as_bools(&amp;self) -&gt; Result&lt;&amp;std::vec::Vec&lt;bool&gt;, &amp;crate::model::AttributeValue&gt; {
        if let AttributeValue::Bools(val) = &amp;self { Ok(&amp;val) } else { Err(self) }
    }
    pub fn is_bools(&amp;self) -&gt; bool {
        self.as_bools().is_some()
    }
    pub fn as_map(&amp;self) -&gt; Result&lt;&amp;std::collections::HashMap&lt;std::string::String, crate::model::AttributeValue&gt;, &amp;crate::model::AttributeValue&gt; {
        if let AttributeValue::Map(val) = &amp;self { Ok(&amp;val) } else { Err(self) }
    }
    pub fn is_map(&amp;self) -&gt; bool {
        self.as_map().is_some()
    }
    pub fn as_string(&amp;self) -&gt; Result&lt;&amp;std::string::String, &amp;crate::model::AttributeValue&gt; {
        if let AttributeValue::String(val) = &amp;self { Ok(&amp;val) } else { Err(self) }
    }
    pub fn is_string(&amp;self) -&gt; bool {
        self.as_string().is_some()
    }
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="endpoint-resolution"><a class="header" href="#endpoint-resolution">Endpoint Resolution</a></h1>
<h2 id="requirements"><a class="header" href="#requirements">Requirements</a></h2>
<p>The core codegen generates HTTP requests that do not contain an authority, scheme or post. These properties must be set later based on configuration. Existing AWS services have a number of requirements that increase the complexity:</p>
<ol>
<li>Endpoints must support manual configuration by end users:</li>
</ol>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let config = dynamodb::Config::builder()
    .endpoint(StaticEndpoint::for_uri(&quot;http://localhost:8000&quot;))
<span class="boring">}
</span></code></pre></pre>
<p>When a user specifies a custom endpoint URI, <em>typically</em> they will want to avoid having this URI mutated by other endpoint discovery machinery.</p>
<ol start="2">
<li>
<p>Endpoints must support being customized on a per-operation basis by the endpoint trait. This will prefix the base endpoint, potentially driven by fields of the operation. <a href="https://awslabs.github.io/smithy/1.0/spec/core/endpoint-traits.html#endpoint-trait">Docs</a></p>
</li>
<li>
<p>Endpoints must support being customized by <a href="https://awslabs.github.io/smithy/1.0/spec/aws/aws-core.html#client-endpoint-discovery">endpoint discovery</a>. A request, customized by a predefined set of fields from the input operation is dispatched to a specific URI. That operation returns the endpoint that should be used. Endpoints must be cached by a cache key containing:</p>
</li>
</ol>
<pre><code>(access_key_id, [all input fields], operation)
</code></pre>
<p>Endpoints retrieved in this way specify a TTL.</p>
<ol start="4">
<li>Endpoints must be able to customize the signing (and other phases of the operation). For example, requests sent to a global region will have a region set by the endpoint provider.</li>
</ol>
<h2 id="design"><a class="header" href="#design">Design</a></h2>
<p>Configuration objects for services <em>must</em> contain an <code>Endpoint</code>. This endpoint may be set by a user or it will default to the <code>endpointPrefix</code> from the service definition. In the case of endpoint discovery, <em>this</em> is the endpoint that we will start with.</p>
<p>During operation construction (see <a href="smithy/../transport/operation.html#operation-construction">Operation Construction</a>) an <code>EndpointPrefix</code> may be set on the property bag. The eventual endpoint middleware will search for this in the property bag and (depending on the URI mutability) utilize this prefix when setting the endpoint.</p>
<p>In the case of endpoint discovery, we envision a different pattern:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// EndpointClient manages the endpoint cache
let (tx, rx) = dynamodb::EndpointClient::new();
let client = aws_hyper::Client::new();
// `endpoint_req` is an operation that can be dispatched to retrieve endpoints
// During operation construction, the endpoint resolver is configured to be `rx` instead static endpoint
// resolver provided by the service.
let (endpoint_req, req) = GetRecord::builder().endpoint_disco(rx).build_with_endpoint();
// depending on the duration of endpoint expiration, this may be spawned into a separate task to continuously
// refresh endpoints.
if tx.needs(endpoint_req) {
    let new_endpoint = client.
        call(endpoint_req)
        .await;
    tx.send(new_endpoint)
}
let rsp = client.call(req).await?;
<span class="boring">}
</span></code></pre></pre>
<p>We believe that this design results in an SDK that both offers customers more control &amp; reduces the likelihood of bugs from nested operation dispatch. Endpoint resolution is currently extremely rare in AWS services so this design may remain a prototype while we solidify other behaviors.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="backwards-compatibility"><a class="header" href="#backwards-compatibility">Backwards Compatibility</a></h1>
<p>AWS SDKs require that clients can evolve in a backwards compatible way as new fields and operations are added. The types
generated by <code>smithy-rs</code> are specifically designed to meet these requirements. Specifically, the following
transformations must not break compilation when upgrading to a new version:</p>
<ul>
<li><a href="smithy/backwards-compat.html#new-operation-added">New operation added</a></li>
<li><a href="smithy/backwards-compat.html#new-member-added-to-structure">New member added to structure</a></li>
<li><a href="smithy/backwards-compat.html#new-union-variant-added">New union variant added</a></li>
<li>New error added (todo)</li>
<li>New enum variant added (todo)</li>
</ul>
<p>However, the following changes are <em>not</em> backwards compatible:</p>
<ul>
<li>Error <strong>removed</strong> from operation.</li>
</ul>
<p>In general, the best tool in Rust to solve these issues in the <code>#[non_exhaustive]</code> attribute which will be explored in
detail below.</p>
<h2 id="new-operation-added"><a class="header" href="#new-operation-added">New Operation Added</a></h2>
<p><strong>Before</strong></p>
<pre><code class="language-smithy">$version: &quot;1&quot;
namespace s3

service S3 {
    operations: [GetObject]
}
</code></pre>
<p><strong>After</strong></p>
<pre><code class="language-smithy">$version: &quot;1&quot;
namespace s3

service S3 {
    operations: [GetObject, PutObject]
}
</code></pre>
<p>Adding support for a new operation is backwards compatible because SDKs to not expose any sort of &quot;service trait&quot; that
provides an interface over an entire service. This <em>prevents</em> clients from inheriting or implementing an interface that
would be broken by the addition of a new operation.</p>
<h2 id="new-member-added-to-structure"><a class="header" href="#new-member-added-to-structure">New member added to structure</a></h2>
<h3 id="summary"><a class="header" href="#summary">Summary</a></h3>
<ul>
<li>Structures are marked <code>#[non_exhaustive]</code></li>
<li>Structures must be instantiated using builders</li>
<li>Structures must not derive <code>Default</code> in the event that required fields are added in the future.</li>
</ul>
<p>In general, adding a new <code>public</code> member to a structure in Rust is not backwards compatible. However, by applying
the <code>#[non_exhaustive]</code> to the structures generated by the Rust SDK, the Rust compiler will prevent users from using our
structs in ways that prevent new fields from being added in the future. <strong>Note</strong>: in this context, the optionality of
the fields is irrelevant.</p>
<p>Specifically, <a href="https://doc.rust-lang.org/reference/attributes/type_system.html"><code>#[non_exhaustive]</code></a> prohibits the
following patterns:</p>
<ol>
<li>
<p>Direct structure instantiation:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">fn foo() {
</span>let ip_addr = IpAddress { addr: &quot;192.168.1.1&quot; };
<span class="boring">}
</span><span class="boring">}
</span></code></pre></pre>
<p>If a new member <code>is_local: boolean</code> was added to the IpAddress structure, this code would not compile. To enable
users to still construct
our structures while maintaining backwards compatibility, all structures expose a builder, accessible
at <code>SomeStruct::Builder</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">fn foo() {
</span>let ip_addr = IpAddress::builder().addr(&quot;192.168.1.1&quot;).build();
<span class="boring">}
</span><span class="boring">}
</span></code></pre></pre>
</li>
<li>
<p>Structure destructuring:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">fn foo() {
</span>let IpAddress { addr } = some_ip_addr();
<span class="boring">}
</span><span class="boring">}
</span></code></pre></pre>
<p>This will also fail to compile if a new member is added, however, by adding <code>#[non_exhaustive]</code>, the <code>..</code> multifield
wildcard MUST be added to support new fields being added in the future:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">fn foo() {
</span>let IpAddress { addr, .. } = some_ip_addr();
<span class="boring">}
</span><span class="boring">}
</span></code></pre></pre>
</li>
</ol>
<h3 id="validation--required-members"><a class="header" href="#validation--required-members">Validation &amp; Required Members</a></h3>
<p><strong>Adding a required member to a structure is <em>not</em> considered backwards compatible.</strong> When a required member is added to
a structure:</p>
<ol>
<li>The builder will change to become fallible, meaning that instead of returning <code>T</code> it will
return <code>Result&lt;T, BuildError&gt;</code>.</li>
<li>Previous builder invocations that did not set the new field will still stop compiling if this was the first required
field.</li>
<li>Previous builder invocations will now return a <code>BuildError</code> because the required field is unset.</li>
</ol>
<h2 id="new-union-variant-added"><a class="header" href="#new-union-variant-added">New union variant added</a></h2>
<p>Similar to structures, <code>#[non_exhaustive]</code> also applies to unions. In order to allow new union variants to be added in
the future, all unions (<code>enum</code> in Rust) generated by the Rust SDK must be marked with <code>#[non_exhaustive]</code>. <strong>Note</strong>:
because new fields cannot be added to union variants, the union variants themselves do <strong>not</strong> need
to be <code>#[non_exhaustive]</code>. To support new variants from services, each union contains an <code>Unknown</code> variant. By
marking <code>Unknown</code> as non_exhaustive, we prevent customers from instantiating it directly.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub enum AttributeValue {
    B(aws_smithy_types::Blob),
    Bool(bool),
    Bs(std::vec::Vec&lt;aws_smithy_types::Blob&gt;),
    L(std::vec::Vec&lt;crate::model::AttributeValue&gt;),
    M(std::collections::HashMap&lt;std::string::String, crate::model::AttributeValue&gt;),
    N(std::string::String),
    Ns(std::vec::Vec&lt;std::string::String&gt;),
    Null(bool),
    S(std::string::String),
    Ss(std::vec::Vec&lt;std::string::String&gt;),

    // By marking `Unknown` as non_exhaustive, we prevent client code from instantiating it directly.
    #[non_exhaustive]
    Unknown,
}
<span class="boring">}
</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfcs"><a class="header" href="#rfcs">RFCs</a></h1>
<p><strong>What is an RFC?:</strong> An RFC is a document that proposes a change to <code>smithy-rs</code> or the AWS Rust SDK. Request for Comments means a request for discussion and oversight about the future of the project from maintainers, contributors and users.</p>
<p><strong>When should I write an RFC?:</strong> The AWS Rust SDK team proactively decides to write RFCs for major features or complex changes that we feel require extra scrutiny. However, the process can be used to request feedback on any change. Even changes that seem obvious and simple at first glance can be improved once a group of interested and experienced people have a chance to weigh in.</p>
<p><strong>Who can submit an RFC?:</strong> An RFC can be submitted by anyone. In most cases, RFCs are authored by SDK maintainers, but everyone is welcome to submit RFCs.</p>
<p><strong>Where do I start?:</strong> If you're ready to write and submit an RFC, please start a GitHub discussion with a summary of what you're trying to accomplish first. That way, the AWS Rust SDK team can ensure they have the bandwidth to review and shepherd the RFC through the whole process before you've expended effort in writing it. Once you've gotten the go-ahead, start with the <a href="rfcs/./rfc_template.html">RFC template</a>.</p>
<h2 id="previously-submitted-rfcs"><a class="header" href="#previously-submitted-rfcs">Previously Submitted RFCs</a></h2>
<ul>
<li><a href="rfcs/./rfc0001_shared_config.html">RFC-0001: AWS Configuration</a></li>
<li><a href="rfcs/./rfc0002_http_versions.html">RFC-0002: Supporting multiple HTTP versions for SDKs that use Event Stream</a></li>
<li><a href="rfcs/./rfc0003_presigning_api.html">RFC-0003: API for Presigned URLs</a></li>
<li><a href="rfcs/./rfc0004_retry_behavior.html">RFC-0004: Retry Behavior</a></li>
<li><a href="rfcs/./rfc0005_service_generation.html">RFC-0005: Service Generation</a></li>
<li><a href="rfcs/./rfc0006_service_specific_middleware.html">RFC-0006: Service-specific middleware</a></li>
<li><a href="rfcs/./rfc0007_split_release_process.html">RFC-0007: Split Release Process</a></li>
<li><a href="rfcs/./rfc0008_paginators.html">RFC-0008: Paginators</a></li>
<li><a href="rfcs/./rfc0009_example_consolidation.html">RFC-0009: Example Consolidation</a></li>
<li><a href="rfcs/./rfc0010_waiters.html">RFC-0010: Waiters</a></li>
<li><a href="rfcs/./rfc0011_crates_io_alpha_publishing.html">RFC-0011: Publishing Alpha to Crates.io</a></li>
<li><a href="rfcs/./rfc0012_independent_crate_versioning.html">RFC-0012: Independent Crate Versioning</a></li>
<li><a href="rfcs/./rfc0013_body_callback_apis.html">RFC-0013: Body Callback APIs</a></li>
<li><a href="rfcs/./rfcs/rfc0014_timeout_config.html">RFC-0014: Fine-grained timeout configuration</a></li>
<li><a href="rfcs/./rfcs/rfc0015_using_features_responsibly.html">RFC-0015: How Cargo &quot;features&quot; should be used in the SDK and runtime crates</a></li>
<li><a href="rfcs/./rfcs/rfc0016_flexible_checksum_support.html">RFC-0016: Supporting Flexible Checksums</a></li>
<li><a href="rfcs/./rfcs/rfc0017_customizable_client_operations.html">RFC-0017: Customizable Client Operations</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="aws-configuration-rfc"><a class="header" href="#aws-configuration-rfc">AWS Configuration RFC</a></h1>
<blockquote>
<p>Status: Implemented. For an ordered list of proposed changes see: <a href="rfcs/rfc0001_shared_config.html#changes-checklist">Proposed changes</a>.</p>
</blockquote>
<p>An AWS SDK loads configuration from multiple locations. Some of these locations can be loaded synchronously. Some are
async. Others may actually use AWS services such as STS or SSO.</p>
<p>This document proposes an overhaul to the configuration design to facilitate three things:</p>
<ol>
<li>Future-proof: It should be easy to add additional sources of region and credentials, sync and async, from many
sources, including code-generated AWS services.</li>
<li>Ergonomic: There should be one obvious way to create an AWS service client. Customers should be able to easily
customize the client to make common changes. It should encourage sharing of things that are expensive to create.</li>
<li>Shareable: A config object should be usable to configure multiple AWS services.</li>
</ol>
<h2 id="usage-guide"><a class="header" href="#usage-guide">Usage Guide</a></h2>
<blockquote>
<p>The following is an imagined usage guide if this RFC where implemented.</p>
</blockquote>
<h3 id="getting-started"><a class="header" href="#getting-started">Getting Started</a></h3>
<p>Using the SDK requires two crates:</p>
<ol>
<li><code>aws-sdk-&lt;someservice&gt;</code>: The service you want to use (e.g. <code>dynamodb</code>, <code>s3</code>, <code>sesv2</code>)</li>
<li><code>aws-config</code>: AWS metaconfiguration. This crate contains all the of logic to load configuration for the SDK (regions,
credentials, retry configuration, etc.)</li>
</ol>
<p>Add the following to your Cargo.toml:</p>
<pre><code class="language-toml">[dependencies]
aws-sdk-dynamo = &quot;0.1&quot;
aws-config = &quot;0.5&quot;

tokio = { version = &quot;1&quot;, features = [&quot;full&quot;] }
</code></pre>
<p>Let's write a small example project to list tables:</p>
<pre><pre class="playground"><code class="language-rust">use aws_sdk_dynamodb as dynamodb;

#[tokio::main]
async fn main() -&gt; Result&lt;(), dynamodb::Error&gt; {
    let config = aws_config::load_from_env().await;
    let dynamodb = dynamodb::Client::new(&amp;config);
    let resp = dynamodb.list_tables().send().await;
    println!(&quot;my tables: {}&quot;, resp.tables.unwrap_or_default());
    Ok(())
}
</code></pre></pre>
<blockquote>
<p>Tip: Every AWS service exports a top level <code>Error</code> type (e.g. <a href="https://awslabs.github.io/aws-sdk-rust/aws_sdk_dynamodb/enum.Error.html">aws_sdk_dynamodb::Error</a>).
Individual operations return specific error types that contain only the <a href="https://awslabs.github.io/aws-sdk-rust/aws_sdk_dynamodb/error/struct.ListTablesError.html">error variants returned by the operation</a>.
Because all the individual errors implement <code>Into&lt;dynamodb::Error&gt;</code>, you can use <code>dynamodb::Error</code> as the return type along with <code>?</code>.</p>
</blockquote>
<p>Next, we'll explore some other ways to configure the SDK. Perhaps you want to override the region loaded from the
environment with your region. In this case, we'll want more control over how we load config,
using <code>aws_config::from_env()</code> directly:</p>
<pre><pre class="playground"><code class="language-rust">use aws_sdk_dynamodb as dynamodb;

#[tokio::main]
async fn main() -&gt; Result&lt;(), dynamodb::Error&gt; {
    let region_provider = RegionProviderChain::default_provider().or_else(&quot;us-west-2&quot;);
    let config = aws_config::from_env().region(region_provider).load().await;
    let dynamodb = dynamodb::Client::new(&amp;config);
    let resp = dynamodb.list_tables().send().await;
    println!(&quot;my tables: {}&quot;, resp.tables.unwrap_or_default());
    Ok(())
}
</code></pre></pre>
<h3 id="sharing-configuration-between-multiple-services"><a class="header" href="#sharing-configuration-between-multiple-services">Sharing configuration between multiple services</a></h3>
<p>The <code>Config</code> produced by <code>aws-config</code> can be used with any AWS service. If we wanted to read our Dynamodb DB tables
aloud with Polly, we could create a Polly client as well. First, we'll need to add Polly to our <code>Cargo.toml</code>:</p>
<pre><code class="language-toml">[dependencies]
aws-sdk-dynamo = &quot;0.1&quot;
aws-sdk-polly = &quot;0.1&quot;
aws-config = &quot;0.5&quot;

tokio = { version = &quot;1&quot;, features = [&quot;full&quot;] }
</code></pre>
<p>Then, we can use the shared configuration to build both service clients. The region override will apply to both clients:</p>
<pre><pre class="playground"><code class="language-rust">use aws_sdk_dynamodb as dynamodb;
use aws_sdk_polly as polly;

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn Error&gt;&gt; { // error type changed to `Box&lt;dyn Error&gt;` because we now have dynamo and polly errors
    let config = aws_config::env_loader().with_region(Region::new(&quot;us-west-2&quot;)).load().await;

    let dynamodb = dynamodb::Client::new(&amp;config);
    let polly = polly::Client::new(&amp;config);

    let resp = dynamodb.list_tables().send().await;
    let tables = resp.tables.unwrap_or_default();
    let table_sentence = format!(&quot;my dynamo DB tables are: {}&quot;, tables.join(&quot;, &quot;));
    let audio = polly.synthesize_speech()
        .output_format(OutputFormat::Mp3)
        .text(table_sentence)
        .voice_id(VoiceId::Joanna)
        .send()
        .await?;

    // Get MP3 data from the response and save it
    let mut blob = resp
        .audio_stream
        .collect()
        .await
        .expect(&quot;failed to read data&quot;);

    let mut file = tokio::fs::File::create(&quot;tables.mp3&quot;)
        .await
        .expect(&quot;failed to create file&quot;);

    file.write_all_buf(&amp;mut blob)
        .await
        .expect(&quot;failed to write to file&quot;);
    Ok(())
}
</code></pre></pre>
<h3 id="specifying-a-custom-credential-provider"><a class="header" href="#specifying-a-custom-credential-provider">Specifying a custom credential provider</a></h3>
<p>If you have your own source of credentials, you may opt-out of the standard credential provider chain.</p>
<p>To do this, implement the <code>ProvideCredentials</code> trait.</p>
<blockquote>
<p>NOTE: <code>aws_types::Credentials</code> already implements <code>ProvideCredentials</code>. If you want to use the SDK with static credentials, you're already done!</p>
</blockquote>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use aws_types::credentials::{ProvideCredentials, provide_credentials::future, Result};

struct MyCustomProvider;

impl MyCustomProvider {
    pub async fn load_credentials(&amp;self) -&gt; Result {
        todo!() // A regular async function
    }
}

impl ProvideCredentials for MyCustomProvider {
    fn provide_credentials&lt;'a&gt;(&amp;'a self) -&gt; future::ProvideCredentials&lt;'a&gt;
        where
            Self: 'a,
    {
        future::ProvideCredentials::new(self.load_credentials())
    }
}
<span class="boring">}
</span></code></pre></pre>
<blockquote>
<p>Hint: If your credential provider is not asynchronous, you can use <code>ProvideCredentials::ready</code> instead to save an allocation.</p>
</blockquote>
<p>After writing your custom provider, you'll use it in when constructing the configuration:</p>
<pre><pre class="playground"><code class="language-rust">#[tokio::main]
async fn main() {
    let config = aws_config::from_env().credentials_provider(MyCustomProvider).load().await;
    let dynamodb = dynamodb::new(&amp;config);
}
</code></pre></pre>
<h2 id="proposed-design"><a class="header" href="#proposed-design">Proposed Design</a></h2>
<p>Achieving this design consists of three major changes:</p>
<ol>
<li>Add a <code>Config</code> struct to <code>aws-types</code>. This contains a config, but with no logic to <em>construct</em> it. This represents
what configuration SDKS need, but <strong>not</strong> how to load the information from the environment.</li>
<li>Create the <code>aws-config</code> crate. <code>aws-config</code> contains the logic to load configuration from the environment. No
generated service clients will depend on <code>aws-config</code>. This is critical to avoid circular dependencies and to
allow <code>aws-config</code> to depend on other AWS services. <code>aws-config</code> contains individual providers as well as a
pre-assembled default provider chain for region and credentials. It will also contain crate features to automatically
bring in HTTPS and async-sleep implementations.</li>
<li>Remove all &quot;business logic&quot; from <code>aws-types</code>. <code>aws-types</code> should be an interface-only crate that is extremely stable.
The ProvideCredentials trait should move into <code>aws-types</code>. The region provider trait which only exists to support
region-chaining will move out of aws-types into aws-config.</li>
</ol>
<p>Services will continue to generate their own <code>Config</code> structs. These will continue to be customizable as they are today,
however, they won't have any default resolvers built in. Each AWS config will implement <code>From&lt;&amp;aws_types::SharedConfig&gt;</code>
. A convenience method to <code>new()</code> a fluent client directly from a shared config will also be generated.</p>
<h3 id="shared-config-implementation"><a class="header" href="#shared-config-implementation">Shared Config Implementation</a></h3>
<p>This RFC proposes adding region and credentials providers support to the shared config. A future RFC will propose
integration with HTTP settings, HTTPs connectors, and async sleep.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct Config {
    // private fields
    ...
}

impl Config {
    pub fn region(&amp;self) -&gt; Option&lt;&amp;Region&gt; {
        self.region.as_ref()
    }

    pub fn credentials_provider(&amp;self) -&gt; Option&lt;SharedCredentialsProvider&gt; {
        self.credentials_provider.clone()
    }

    pub fn builder() -&gt; Builder {
        Builder::default()
    }
}

<span class="boring">}
</span></code></pre></pre>
<p>The <code>Builder</code> for <code>Config</code> allows customers to provide individual overrides and handles the insertion of the default
chain for regions and credentials.</p>
<h3 id="sleep--connectors"><a class="header" href="#sleep--connectors">Sleep + Connectors</a></h3>
<p>Sleep and Connector are both runtime dependent features. <code>aws-config</code> will define <code>rt-tokio</code> and <code>rustls</code>
and <code>native-tls</code> optional features. <strong>This centralizes the Tokio/Hyper dependency</strong> eventually removing the need for
each service to maintain their own Tokio/Hyper features.</p>
<p>Although not proposed in this RFC, shared config will eventually gain support for creating an HTTPs client from HTTP
settings.</p>
<h2 id="the-build-method-on-config"><a class="header" href="#the-build-method-on-config">The <code>.build()</code> method on <service>::Config</a></h2>
<p>Currently, the <code>.build()</code> method on service config will fill in defaults. As part of this change, <code>.build()</code> called on
the service config with missing properties will fill in &quot;empty&quot; defaults. If no credentials provider is given,
a <code>NoCredentials</code> provider will be set, and <code>Region</code> will remain as <code>None</code>.</p>
<h2 id="stability-and-versioning"><a class="header" href="#stability-and-versioning">Stability and Versioning</a></h2>
<p>The introduction of <code>Config</code> to aws-types is not without risks. If a customer depends on a version aws-config that
uses <code>Config</code> that is incompatible, they will get confusing compiler errors.</p>
<p>An example of a problematic set of dependent versions:</p>
<pre><code>┌─────────────────┐                 ┌───────────────┐
│ aws-types = 0.1 │                 │aws-types= 0.2 │
└─────────────────┘                 └───────────────┘
           ▲                                 ▲
           │                                 │
           │                                 │
           │                                 │
 ┌─────────┴─────────────┐          ┌────────┴───────┐
 │aws-sdk-dynamodb = 0.5 │          │aws-config = 0.6│
 └───────────┬───────────┘          └───────┬────────┘
             │                              │
             │                              │
             │                              │
             │                              │
             │                              │
             ├─────────────────────┬────────┘
             │ my-lambda-function  │
             └─────────────────────┘
</code></pre>
<p>To mitigate this risk, we will need to make <code>aws-types</code> essentially permanently stable. Changes to <code>aws-types</code> need to
be made with extreme care. This will ensure that two versions of <code>aws-types</code> never end up in a customer's dependency
tree.</p>
<p>We will dramatically reduce the surface area of <code>aws-types</code> to contain only interfaces.</p>
<p>Several breaking changes will be made as part of this, notably, the profile file parsing will be moved out of aws-types.</p>
<p>Finally, to mitigate this risk even further, services will <code>pub use</code> items from <code>aws-types</code> directly which means that
even if a dependency mismatch exists, it is still possible for customers to work around it.</p>
<h2 id="changes-checklist"><a class="header" href="#changes-checklist">Changes Checklist</a></h2>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
ProvideRegion becomes async using a newtype'd future.</li>
<li><input disabled="" type="checkbox" checked=""/>
AsyncProvideCredentials is removed. ProvideCredentials becomes async using a newtype'd future.</li>
<li><input disabled="" type="checkbox" checked=""/>
ProvideCredentials moved into <code>aws-types</code>. <code>Credentials</code> moved into <code>aws-types</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Create <code>aws-config</code>.</li>
<li><input disabled="" type="checkbox" checked=""/>
Profile-file parsing moved into <code>aws-config</code>, region chain &amp; region environment loaders moved to <code>aws-config</code>.</li>
<li><input disabled="" type="checkbox"/>
os_shim_internal moved to ??? <code>aws-smithy-types</code>?</li>
<li><input disabled="" type="checkbox" checked=""/>
Add <code>Config</code> to <code>aws-types</code>. Ensure that it's set up to add new members while remaining backwards
compatible.</li>
<li><input disabled="" type="checkbox" checked=""/>
Code generate <code>From&lt;&amp;SharedConfig&gt; for &lt;everyservice&gt;::Config</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Code generate <code>&lt;everservice&gt;::Client::new(&amp;shared_config)</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Remove <code>&lt;everyservice&gt;::from_env</code></li>
</ul>
<h2 id="open-issues"><a class="header" href="#open-issues">Open Issues</a></h2>
<ul>
<li><input disabled="" type="checkbox"/>
Connector construction needs to be a function of HTTP settings</li>
<li><input disabled="" type="checkbox"/>
An AsyncSleep should be added to <code>aws-types::Config</code></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-supporting-multiple-http-versions-for-sdks-that-use-event-stream"><a class="header" href="#rfc-supporting-multiple-http-versions-for-sdks-that-use-event-stream">RFC: Supporting multiple HTTP versions for SDKs that use Event Stream</a></h1>
<blockquote>
<p>Status: Accepted</p>
</blockquote>
<p>For a summarized list of proposed changes, see the <a href="rfcs/rfc0002_http_versions.html#changes-checklist">Changes Checklist</a> section.</p>
<p>Most AWS SDK operations use HTTP/1.1, but bi-directional streaming operations that use the Event Stream
message framing format need to use HTTP/2 (h2).</p>
<p>Smithy models can also customize which HTTP versions are used in each individual protocol trait.
For example,
<a href="https://awslabs.github.io/smithy/1.0/spec/aws/aws-restjson1-protocol.html#aws-protocols-restjson1-trait"><code>@restJson1</code> has attributes <code>http</code> and <code>eventStreamHttp</code></a>
to list out the versions that should be used in a priority order.</p>
<p>There are two problems in play that this doc attempts to solve:</p>
<ol>
<li><strong>Connector Creation</strong>: Customers need to be able to create connectors with the HTTP settings they desire,
and these custom connectors must align with what the Smithy model requires.</li>
<li><strong>Connector Selection</strong>: The generated code must be able to select the connector that best matches the requirements
from the Smithy model.</li>
</ol>
<h2 id="terminology"><a class="header" href="#terminology">Terminology</a></h2>
<p>Today, there are three layers of <code>Client</code> that are easy to confuse, so to make the following easier to follow,
the following terms will be used:</p>
<ul>
<li><strong>Connector</strong>: An implementor of Tower's <code>Service</code> trait that converts a request into a response. This is typically
a thin wrapper around a Hyper client.</li>
<li><strong>Smithy Client</strong>: A <code>aws_smithy_client::Client&lt;C, M, R&gt;</code> struct that is responsible for gluing together
the connector, middleware, and retry policy. This isn't intended to be used directly.</li>
<li><strong>Fluent Client</strong>: A code generated <code>Client&lt;C, M, R&gt;</code> that has methods for each service operation on it.
A fluent builder is generated alongside it to make construction easier.</li>
<li><strong>AWS Client</strong>: A specialized Fluent Client that uses a <code>DynConnector</code>, <code>DefaultMiddleware</code>,
and <code>Standard</code> retry policy.</li>
</ul>
<p>All of these are just called <code>Client</code> in code today. This is something that could be clarified in a separate refactor.</p>
<h2 id="how-clients-work-today"><a class="header" href="#how-clients-work-today">How Clients Work Today</a></h2>
<p>Fluent clients currently keep a handle to a single Smithy client, which is a wrapper
around the underlying connector. When constructing operation builders, this handle is <code>Arc</code> cloned and
given to the new builder instances so that their <code>send()</code> calls can initiate a request.</p>
<p>The generated fluent client code ends up looking like this:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct Handle&lt;C, M, R&gt; {
    client: aws_smithy_client::Client&lt;C, M, R&gt;,
    conf: crate::Config,
}

pub struct Client&lt;C, M, R = Standard&gt; {
    handle: Arc&lt;Handle&lt;C, M, R&gt;&gt;,
}
<span class="boring">}
</span></code></pre></pre>
<p>Functions are generated per operation on the fluent client to gain access to the individual operation builders.
For example:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn assume_role(&amp;self) -&gt; fluent_builders::AssumeRole&lt;C, M, R&gt; {
    fluent_builders::AssumeRole::new(self.handle.clone())
}
<span class="boring">}
</span></code></pre></pre>
<p>The fluent operation builders ultimately implement <code>send()</code>, which chooses the one and only Smithy client out
of the handle to make the request with:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct AssumeRole&lt;C, M, R&gt; {
    handle: std::sync::Arc&lt;super::Handle&lt;C, M, R&gt;&gt;,
    inner: crate::input::assume_role_input::Builder,
}

impl&lt;C, M, R&gt; AssumeRole&lt;C, M, R&gt; where ...{
    pub async fn send(self) -&gt; Result&lt;AssumeRoleOutput, SdkError&lt;AssumeRoleError&gt;&gt; where ... {
        // Setup code omitted ...

        // Make the actual request
        self.handle.client.call(op).await
    }
}
<span class="boring">}
</span></code></pre></pre>
<p>Smithy clients are constructed from a connector, as shown:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let connector = Builder::new()
    .https()
    .middleware(...)
    .build();
let client = Client::with_config(connector, Config::builder().build());
<span class="boring">}
</span></code></pre></pre>
<p>The <code>https()</code> method on the Builder constructs the actual Hyper client, and is driven off Cargo features to
select the correct TLS implementation. For example:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(feature = &quot;rustls&quot;)]
pub fn https() -&gt; Https {
    let https = hyper_rustls::HttpsConnector::with_native_roots();
    let client = hyper::Client::builder().build::&lt;_, SdkBody&gt;(https);
    // HyperAdapter is a Tower `Service` request -&gt; response connector that just calls the Hyper client
    crate::hyper_impls::HyperAdapter::from(client)
}
<span class="boring">}
</span></code></pre></pre>
<h2 id="solving-the-connector-creation-problem"><a class="header" href="#solving-the-connector-creation-problem">Solving the Connector Creation Problem</a></h2>
<p>Customers need to be able to provide HTTP settings, such as timeouts, for all connectors that the clients use.
These should come out of the <code>SharedConfig</code> when it is used. Connector creation also needs to be customizable
so that alternate HTTP implementations can be used, or so that a fake implementation can be used for tests.</p>
<p>To accomplish this, <code>SharedConfig</code> will have a <code>make_connector</code> member. A customer would configure
it as such:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let config = some_shared_config_loader()
    .with_http_settings(my_http_settings)
    .with_make_connector(|reqs: &amp;MakeConnectorRequirements| {
        Some(MyCustomConnector::new(reqs))
    })
    .await;
<span class="boring">}
</span></code></pre></pre>
<p>The passed in <code>MakeConnectorRequirements</code> will hold the customer-provided <code>HttpSettings</code> as well
as any Smithy-modeled requirements, which will just be <code>HttpVersion</code> for now. The <code>MakeConnectorRequirements</code>
struct will be marked <code>non_exhaustive</code> so that new requirements can be added to it as the SDK evolves.</p>
<p>A default <code>make_connector</code> implementation would be provided that creates a Hyper connector based on the
Cargo feature flags. This might look something like this:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(feature = &quot;rustls&quot;)]
pub fn default_connector(reqs: &amp;HttpRequirements) -&gt; HyperAdapter {
    let https = hyper_rustls::HttpsConnector::with_native_roots();
    let mut builder = hyper::Client::builder();
    builder = configure_settings(builder, &amp;reqs.http_settings);
    if let Http2 = &amp;reqs.http_version {
        builder = builder.http2_only(true);
    }
    HyperAdapter::from(builder.build::&lt;_, SdkBody&gt;(https))
}
<span class="boring">}
</span></code></pre></pre>
<p>For any given service, <code>make_connector</code> could be called multiple times to create connectors
for all required HTTP versions and settings.</p>
<p><strong>Note:</strong> the <code>make_connector</code> returns an <code>Option</code> since an HTTP version may not be required, but rather, preferred
according to a Smithy model. For operations that list out <code>[&quot;h2&quot;, &quot;HTTP/1.1&quot;]</code> as the desired versions,
a customer could choose to provide only an HTTP 1 connector, and the operation should still succeed.</p>
<h2 id="solving-the-connector-selection-problem"><a class="header" href="#solving-the-connector-selection-problem">Solving the Connector Selection Problem</a></h2>
<p>Each service operation needs to be able to select a connector that meets its requirements best
from the customer provided connectors. Initially, the only selection criteria will be the HTTP version,
but later when per-operation HTTP settings are implemented, the connector will also need to be keyed off of those
settings. Since connector creation is not a cheap process, connectors will need to be cached after they are
created.</p>
<p>This caching is currently handled by the <code>Handle</code> in the fluent client, which holds on to the
Smithy client. This cache needs to be adjusted to:</p>
<ul>
<li>Support multiple connectors, keyed off of the customer provided <code>HttpSettings</code>, and also off of the Smithy modeled requirements.</li>
<li>Be lazy initialized. Services that have a mix of Event Stream and non-streaming operations shouldn't create
an HTTP/2 client if the customer doesn't intend to use the Event Stream operations that require it.</li>
</ul>
<p>To accomplish this, the <code>Handle</code> will hold a cache that is optimized for many reads and few writes:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[derive(Debug, Hash, Eq, PartialEq)]
struct ConnectorKey {
    http_settings: HttpSettings,
    http_version: HttpVersion,
}

struct Handle&lt;C, M, R&gt; {
    clients: RwLock&lt;HashMap&lt;HttpRequirements&lt;'static&gt;, aws_smithy_client::Client&lt;C, M, R&gt;&gt;&gt;,
    conf: crate::Config,
}

pub struct Client&lt;C, M, R = Standard&gt; {
    handle: Arc&lt;Handle&lt;C, M, R&gt;&gt;,
}
<span class="boring">}
</span></code></pre></pre>
<p>With how the generics are organized, the connector type will have to be the same between HTTP implementations,
but this should be fine since it is generally a thin wrapper around a separate HTTP implementor.
For cases where it is not, the custom connector type can host its own <code>dyn Trait</code> solution.</p>
<p>The <code>HttpRequirements</code> struct will hold <code>HttpSettings</code> as copy-on-write so that it can be used
for cache lookup without having to clone <code>HttpSettings</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct HttpRequirements&lt;'a&gt; {
    http_settings: Cow&lt;'a, HttpSettings&gt;,
    http_version: HttpVersion,
}

impl&lt;'a&gt; HttpRequirements&lt;'a&gt; {
    // Needed for converting a borrowed HttpRequirements into an owned cache key for cache population
    pub fn into_owned(self) -&gt; HttpRequirements&lt;'static&gt; {
        Self {
            http_settings: Cow::Owned(self.http_settings.into_owned()),
            http_version: self.http_version,
        }
    }
}
<span class="boring">}
</span></code></pre></pre>
<p>With the cache established, each operation needs to be aware of its requirements. The code generator will be
updated to store a prioritized list of <code>HttpVersion</code> in the property bag in an input's <code>make_operation()</code> method.
This prioritized list will come from the Smithy protocol trait's <code>http</code> or <code>eventStreamHttp</code> attribute, depending
on the operation. The fluent client will then pull this list out of the property bag so that it can determine which
connector to use. This indirection is necessary so that an operation still holds all information
needed to make a service call from the Smithy client directly.</p>
<p><strong>Note:</strong> This may be extended in the future to be more than just <code>HttpVersion</code>, for example, when per-operation
HTTP setting overrides are implemented. This doc is not attempting to solve that problem.</p>
<p>In the fluent client, this will look as follows:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl&lt;C, M, R&gt; AssumeRole&lt;C, M, R&gt; where ... {
    pub async fn send(self) -&gt; Result&lt;AssumeRoleOutput, SdkError&lt;AssumeRoleError&gt;&gt; where ... {
        let input = self.create_input()?;
        let op = input.make_operation(&amp;self.handle.conf)?;

        // Grab the `make_connector` implementation
        let make_connector = self.config.make_connector();

        // Acquire the prioritized HttpVersion list
        let http_versions = op.properties().get::&lt;HttpVersionList&gt;();

        // Make the actual request (using default HttpSettings until modifying those is implemented)
        let client = self.handle
            .get_or_create_client(make_connector, &amp;default_http_settings(), &amp;http_versions)
            .await?;
        client.call(op).await
    }
}
<span class="boring">}
</span></code></pre></pre>
<p>If an operation requires a specific protocol version, and if the <code>make_connection</code> implementation can't
provide that it, then the <code>get_or_create_client()</code> function will return <code>SdkError::ConstructionFailure</code>
indicating the error.</p>
<h2 id="changes-checklist-1"><a class="header" href="#changes-checklist-1">Changes Checklist</a></h2>
<ul>
<li><input disabled="" type="checkbox"/>
Create <code>HttpVersion</code> in <code>aws-smithy-http</code> with <code>Http1_1</code> and <code>Http2</code></li>
<li><input disabled="" type="checkbox"/>
Refactor existing <code>https()</code> connector creation functions to take <code>HttpVersion</code></li>
<li><input disabled="" type="checkbox"/>
Add <code>make_connector</code> to <code>SharedConfig</code>, and wire up the <code>https()</code> functions as a default</li>
<li><input disabled="" type="checkbox"/>
Create <code>HttpRequirements</code> in <code>aws-smithy-http</code></li>
<li><input disabled="" type="checkbox"/>
Implement the connector cache on <code>Handle</code></li>
<li><input disabled="" type="checkbox"/>
Implement function to calculate a minimum required set of HTTP versions from a Smithy model in the code generator</li>
<li><input disabled="" type="checkbox"/>
Update the <code>make_operation</code> code gen to put an <code>HttpVersionList</code> into the operation property bag</li>
<li><input disabled="" type="checkbox"/>
Update the fluent client <code>send()</code> function code gen grab the HTTP version list and acquire the correct connector with it</li>
<li><input disabled="" type="checkbox"/>
Add required defaulting for models that don't set the optional <code>http</code> and <code>eventStreamHttp</code> protocol trait attributes</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-api-for-presigned-urls"><a class="header" href="#rfc-api-for-presigned-urls">RFC: API for Presigned URLs</a></h1>
<blockquote>
<p>Status: Implemented</p>
</blockquote>
<p>For a summarized list of proposed changes, see the <a href="rfcs/rfc0003_presigning_api.html#changes-checklist">Changes Checklist</a> section.</p>
<p>Several AWS services allow for presigned requests in URL form, which is described well by
<a href="https://docs.aws.amazon.com/AmazonS3/latest/API/sigv4-query-string-auth.html">S3's documentation on authenticating requests using query parameters</a>.</p>
<p>This doc establishes the customer-facing API for creating these presigned URLs and how they will
be implemented in a generic fashion in the SDK codegen.</p>
<h2 id="terminology-1"><a class="header" href="#terminology-1">Terminology</a></h2>
<p>To differentiate between the clients that are present in the generated SDK today, the following
terms will be used throughout this doc:</p>
<ul>
<li><strong>Smithy Client</strong>: A <code>aws_smithy_client::Client&lt;C, M, R&gt;</code> struct that is responsible for gluing together
the connector, middleware, and retry policy. This is not generated and lives in the <code>aws-smithy-client</code> crate.</li>
<li><strong>Fluent Client</strong>: A code-generated <code>Client&lt;C, M, R&gt;</code> that has methods for each service operation on it.
A fluent builder is generated alongside it to make construction easier.</li>
</ul>
<h2 id="presigned-url-config"><a class="header" href="#presigned-url-config">Presigned URL config</a></h2>
<p>Today, presigned URLs take an expiration time that's not part of the service API.
The SDK will make this configurable as a separate struct so that there's no chance of name collisions, and so
that additional fields can be added in the future. Fields added later will require defaulting for
backwards compatibility.</p>
<p>Customers should also be able to set a start time on the presigned URL's expiration so that they can
generate URLs that become active in the future. An optional <code>start_time</code> option will be available and
default to <code>SystemTime::now()</code>.</p>
<p>Construction <code>PresigningConfig</code> can be done with a builder, but a <code>PresigningConfig::expires_in</code>
convenience function will be provided to bypass the builder for the most frequent use-case.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[non_exhaustive]
#[derive(Debug, Clone)]
pub struct PresigningConfig {
    start_time: SystemTime,
    expires_in: Duration,
}

#[non_exhaustive]
#[derive(Debug)]
pub struct Builder {
    start_time: Option&lt;SystemTime&gt;,
    expires_in: Option&lt;Duration&gt;,
}

impl Builder {
    pub fn start_time(self, start_time: SystemTime) -&gt; Self { ... }
    pub fn set_start_time(&amp;mut self, start_time: Option&lt;SystemTime&gt;) { ... }

    pub fn expires_in(self, expires_in: Duration) -&gt; Self { ... }
    pub fn set_expires_in(&amp;mut self, expires_in: Option&lt;Duration&gt;) { ... }

    // Validates `expires_in` is no greater than one week
    pub fn build(self) -&gt; Result&lt;PresigningConfig, Error&gt; { ... }
}

impl PresigningConfig {
    pub fn expires_in(expires_in: Duration) -&gt; PresigningConfig {
        Self::builder().expires(expires).build().unwrap()
    }

    pub fn builder() -&gt; Builder { ... }
}
<span class="boring">}
</span></code></pre></pre>
<p>Construction of <code>PresigningConfig</code> will validate that <code>expires_in</code> is no greater than one week, as this
is the longest supported expiration time for SigV4. This validation will result in a panic.</p>
<p>It's not inconceivable that <code>PresigningConfig</code> will need additional service-specific parameters as customizations,
so it will be code generated with each service rather than living a shared location.</p>
<h2 id="fluent-presigned-url-api"><a class="header" href="#fluent-presigned-url-api">Fluent Presigned URL API</a></h2>
<p>The generated fluent builders for operations that support presigning will have a <code>presigned()</code> method
in addition to <code>send()</code> that will return a presigned URL rather than sending the request. For S3's GetObject,
the usage of this will look as follows:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let config = aws_config::load_config_from_environment().await;
let client = s3::Client::new(&amp;config);
let presigning_config = PresigningConfig::expires_in(Duration::from_secs(86400));
let presigned: PresignedRequest = client.get_object()
    .bucket(&quot;example-bucket&quot;)
    .key(&quot;example-object&quot;)
    .presigned(presigning_config)
    .await?;
<span class="boring">}
</span></code></pre></pre>
<p>This API requires a client, and for use-cases where no actual service calls need to be made,
customers should be able to create presigned URLs without the overhead of an HTTP client.
Once the <a href="rfcs/./rfc0002_http_versions.html">HTTP Versions RFC</a> is implemented, the underlying HTTP client
won't be created until the first service call, so there will be no HTTP client overhead to
this approach.</p>
<p>In a step away from the general pattern of keeping fluent client capabilities in line with Smithy client capabilities,
creating presigned URLs directly from the Smithy client will not be supported. This is for two reasons:</p>
<ul>
<li>The Smithy client is not code generated, so adding a method to do presigning would apply to all operations,
but not all operations can be presigned.</li>
<li>Presigned URLs are not currently a Smithy concept (<a href="https://github.com/awslabs/smithy/pull/897">although this may change soon</a>).</li>
</ul>
<p>The result of calling <code>presigned()</code> is a <code>PresignedRequest</code>, which is a wrapper with delegating functions
around <code>http::Request&lt;()&gt;</code> so that the request method and additional signing headers are also made available.
This is necessary since there are some presignable POST operations that require the signature to be in the
headers rather than the query.</p>
<p><strong>Note:</strong> Presigning <em>needs</em> to be <code>async</code> because the underlying credentials provider used to sign the
request <em>may</em> need to make service calls to acquire the credentials.</p>
<h2 id="input-presigned-url-api"><a class="header" href="#input-presigned-url-api">Input Presigned URL API</a></h2>
<p>Even though generating a presigned URL through the fluent client doesn't necessitate an HTTP client,
it will be clearer that this is the case by allowing the creation of presigned URLs directly from an input.
This would look as follows:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let config = aws_config::load_config_from_environment().await;
let presigning_config = PresigningConfig::expires_in(Duration::from_secs(86400));
let presigned: PresignedRequest = GetObjectInput::builder()
    .bucket(&quot;example-bucket&quot;)
    .key(&quot;example-bucket&quot;)
    .presigned(&amp;config, presigning_config)
    .await?;
<span class="boring">}
</span></code></pre></pre>
<p>Creating the URL through the input will exercise the same code path as creating it through the client,
but it will be more apparent that the overhead of a client isn't present.</p>
<h2 id="behind-the-scenes"><a class="header" href="#behind-the-scenes">Behind the scenes</a></h2>
<p>From an SDK's perspective, the following are required to make a presigned URL:</p>
<ul>
<li>Valid request input</li>
<li>Endpoint</li>
<li>Credentials to sign with</li>
<li>Signing implementation</li>
</ul>
<p>The AWS middleware provides everything except the request, and the request is provided as part
of the fluent builder API. The generated code needs to be able to run the middleware to fully populate
a request property bag, but not actually dispatch it.  The <code>expires_in</code> value from the presigning config
needs to be piped all the way through to the signer. Additionally, the SigV4 signing needs to adjusted
to do query param signing, which is slightly different than its header signing.</p>
<p>Today, request dispatch looks as follows:</p>
<ol>
<li>The customer creates a new fluent builder by calling <code>client.operation_name()</code>, fills in inputs, and then calls <code>send()</code>.</li>
<li><code>send()</code>:
<ol>
<li>Builds the final input struct, and then calls its <code>make_operation()</code> method with the stored config to create a Smithy <code>Operation</code>.</li>
<li>Calls the underlying Smithy client with the operation.</li>
</ol>
</li>
<li>The Smithy client constructs a Tower Service with AWS middleware and a dispatcher at the bottom, and then executes it.</li>
<li>The middleware acquire and add required signing parameters (region, credentials, endpoint, etc) to the request property bag.</li>
<li>The SigV4 signing middleware signs the request by adding HTTP headers to it.</li>
<li>The dispatcher makes the actual HTTP request and returns the response all the way back up the Tower.</li>
</ol>
<p>Presigning will take advantage of a lot of these same steps, but will cut out the <code>Operation</code> and
replace the dispatcher with a presigned URL generator:</p>
<ol>
<li>The customer creates a new fluent builder by calling <code>client.operation_name()</code>, fills in inputs, and then calls <code>presigned()</code>.</li>
<li><code>presigned()</code>:
<ol>
<li>Builds the final input struct, calls the <code>make_operation()</code> method with the stored config, and then extracts
the request from the operation (discarding the rest).</li>
<li>Mutates the <code>OperationSigningConfig</code> in the property bag to:
<ul>
<li>Change the <code>signature_type</code> to <code>HttpRequestQueryParams</code> so that the signer runs the correct signing logic.</li>
<li>Set <code>expires_in</code> to the value given by the customer in the presigning config.</li>
</ul>
</li>
<li>Constructs a Tower Service with <code>AwsMiddleware</code> layered in, and a <code>PresignedUrlGeneratorLayer</code> at the bottom.</li>
<li>Calls the Tower Service and returns its result</li>
</ol>
</li>
<li>The <code>AwsMiddleware</code> will sign the request.</li>
<li>The <code>PresignedUrlGeneratorLayer</code> directly returns the request since all of the work is done by the middleware.</li>
</ol>
<p>It should be noted that the <code>presigned()</code> function above is on the generated input struct, so implementing this for
the input API is identical to implementing it for the fluent client.</p>
<p>All the code for the new <code>make_request()</code> is already in the existing <code>make_operation()</code> and will just need to be split out.</p>
<h3 id="modeling-presigning"><a class="header" href="#modeling-presigning">Modeling Presigning</a></h3>
<p>AWS models don't currently have any information about which operations can be presigned.
To work around this, the Rust SDK will create a synthetic trait to model presigning with, and
apply this trait to known presigned operations via customization. The code generator will
look for this synthetic trait when creating the fluent builders and inputs to know if a
<code>presigned()</code> method should be added.</p>
<h3 id="avoiding-name-collision"><a class="header" href="#avoiding-name-collision">Avoiding name collision</a></h3>
<p>If a presignable operation input has a member named <code>presigned</code>, then there will be a name collision with
the function to generate a presigned URL. To mitigate this, <code>RustReservedWords</code> will be updated
to rename the <code>presigned</code> member to <code>presigned_value</code>
<a href="https://github.com/awslabs/smithy-rs/blob/3d61226b5d446f4cc20bf4969f0e56d106cf478b/codegen/src/main/kotlin/software/amazon/smithy/rust/codegen/rustlang/RustReservedWords.kt#L28">similar to how <code>send</code> is renamed</a>.</p>
<h2 id="changes-checklist-2"><a class="header" href="#changes-checklist-2">Changes Checklist</a></h2>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Update <code>aws-sigv4</code> to support query param signing</li>
<li><input disabled="" type="checkbox" checked=""/>
Create <code>PresignedOperationSyntheticTrait</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Customize models for known presigned operations</li>
<li><input disabled="" type="checkbox" checked=""/>
Create <code>PresigningConfig</code> and its builder</li>
<li><input disabled="" type="checkbox" checked=""/>
Implement <code>PresignedUrlGeneratorLayer</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Create new AWS codegen decorator to:
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Add new <code>presigned()</code> method to input code generator</li>
<li><input disabled="" type="checkbox" checked=""/>
Add new <code>presigned()</code> method to fluent client generator</li>
</ul>
</li>
<li><input disabled="" type="checkbox" checked=""/>
Update <code>RustReservedWords</code> to reserve <code>presigned()</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Add integration test to S3</li>
<li><input disabled="" type="checkbox" checked=""/>
Add integration test to Polly</li>
<li><input disabled="" type="checkbox" checked=""/>
Add examples for using presigning for:
<ul>
<li><input disabled="" type="checkbox" checked=""/>
S3 GetObject and PutObject</li>
<li><input disabled="" type="checkbox" checked=""/>
Polly SynthesizeSpeech</li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-retry-behavior"><a class="header" href="#rfc-retry-behavior">RFC: Retry Behavior</a></h1>
<blockquote>
<p>Status: Implemented</p>
</blockquote>
<p>For a summarized list of proposed changes, see the <a href="rfcs/rfc0004_retry_behavior.html#changes-checklist">Changes Checklist</a> section.</p>
<p>It is not currently possible for users of the SDK to configure a client's maximum number of retry attempts. This RFC establishes a method for users to set the number of retries to attempt when calling a service and would allow users to disable retries entirely. This RFC would introduce breaking changes to the <code>retry</code> module of the <code>aws-smithy-client</code> crate.</p>
<h2 id="terminology-2"><a class="header" href="#terminology-2">Terminology</a></h2>
<ul>
<li><strong>Smithy Client</strong>: A <code>aws_smithy_client::Client&lt;C, M, R&gt;</code> struct that is responsible for gluing together
the connector, middleware, and retry policy. This is not generated and lives in the <code>aws-smithy-client</code> crate.</li>
<li><strong>Fluent Client</strong>: A code-generated <code>Client&lt;C, M, R&gt;</code> that has methods for each service operation on it.
A fluent builder is generated alongside it to make construction easier.</li>
<li><strong>AWS Client</strong>: A specialized Fluent Client that defaults to using a <code>DynConnector</code>, <code>AwsMiddleware</code>,
and <code>Standard</code> retry policy.</li>
<li><strong>Shared Config</strong>: An <code>aws_types::Config</code> struct that is responsible for storing shared configuration data that is used across all services. This is not generated and lives in the <code>aws-types</code> crate.</li>
<li><strong>Service-specific Config</strong>: A code-generated <code>Config</code> that has methods for setting service-specific configuration. Each <code>Config</code> is defined in the <code>config</code> module of its parent service. For example, the S3-specific config struct is <code>use</code>able from <code>aws_sdk_s3::config::Config</code> and re-exported as <code>aws_sdk_s3::Config</code>.</li>
<li><strong>Standard retry behavior</strong>: The standard set of retry rules across AWS SDKs. This mode includes a standard set of errors that are retried, and support for retry quotas. The default maximum number of attempts with this mode is three, unless <code>max_attempts</code> is explicitly configured.</li>
<li><strong>Adaptive retry behavior</strong>: Adaptive retry mode dynamically limits the rate of AWS requests to maximize success rate. This may be at the expense of request latency. Adaptive retry mode is not recommended when predictable latency is important.
<ul>
<li><em>Note: supporting the &quot;adaptive&quot; retry behavior is considered outside the scope of this RFC</em></li>
</ul>
</li>
</ul>
<h2 id="configuring-the-maximum-number-of-retries"><a class="header" href="#configuring-the-maximum-number-of-retries">Configuring the maximum number of retries</a></h2>
<p>This RFC will demonstrate <em>(with examples)</em> the following ways that Users can set the maximum number of retry attempts:</p>
<ul>
<li>By calling the <code>Config::retry_config(..)</code> or <code>Config::disable_retries()</code> methods when building a service-specific config</li>
<li>By calling the <code>Config::retry_config(..)</code> or <code>Config::disable_retries()</code> methods when building a shared config</li>
<li>By setting the <code>AWS_MAX_ATTEMPTS</code> environment variable</li>
</ul>
<p>The above list is in order of decreasing precedence e.g. setting maximum retry attempts with the <code>max_attempts</code> builder method will override a value set by <code>AWS_MAX_ATTEMPTS</code>.</p>
<p><em>The default number of retries is 3 as specified in the <a href="https://docs.aws.amazon.com/sdkref/latest/guide/setting-global-max_attempts.html">AWS SDKs and Tools Reference Guide</a>.</em></p>
<h3 id="setting-an-environment-variable"><a class="header" href="#setting-an-environment-variable">Setting an environment variable</a></h3>
<p>Here's an example app that logs your AWS user's identity</p>
<pre><pre class="playground"><code class="language-rust">use aws_sdk_sts as sts;

#[tokio::main]
async fn main() -&gt; Result&lt;(), sts::Error&gt; {
    let config = aws_config::load_from_env().await;

    let sts = sts::Client::new(&amp;config);
    let resp = sts.get_caller_identity().send().await?;
    println!(&quot;your user id: {}&quot;, resp.user_id.unwrap_or_default());
    Ok(())
}
</code></pre></pre>
<p>Then, in your terminal:</p>
<pre><code class="language-sh"># Set the env var before running the example program
export AWS_MAX_ATTEMPTS=5
# Run the example program
cargo run
</code></pre>
<h3 id="calling-a-method-on-an-aws-shared-config"><a class="header" href="#calling-a-method-on-an-aws-shared-config">Calling a method on an AWS shared config</a></h3>
<p>Here's an example app that creates a shared config with custom retry behavior and then logs your AWS user's identity</p>
<pre><pre class="playground"><code class="language-rust">use aws_sdk_sts as sts;
use aws_types::retry_config::StandardRetryConfig;

#[tokio::main]
async fn main() -&gt; Result&lt;(), sts::Error&gt; {
    let retry_config = StandardRetryConfig::builder().max_attempts(5).build();
    let config = aws_config::from_env().retry_config(retry_config).load().await;

    let sts = sts::Client::new(&amp;config);
    let resp = sts.get_caller_identity().send().await?;
    println!(&quot;your user id: {}&quot;, resp.user_id.unwrap_or_default());
    Ok(())
}
</code></pre></pre>
<h3 id="calling-a-method-on-service-specific-config"><a class="header" href="#calling-a-method-on-service-specific-config">Calling a method on service-specific config</a></h3>
<p>Here's an example app that creates a service-specific config with custom retry behavior and then logs your AWS user's identity</p>
<pre><pre class="playground"><code class="language-rust">use aws_sdk_sts as sts;
use aws_types::retry_config::StandardRetryConfig;

#[tokio::main]
async fn main() -&gt; Result&lt;(), sts::Error&gt; {
    let config = aws_config::load_from_env().await;
    let retry_config = StandardRetryConfig::builder().max_attempts(5).build();
    let sts_config = sts::config::Config::from(&amp;config).retry_config(retry_config).build();

    let sts = sts::Client::new(&amp;sts_config);
    let resp = sts.get_caller_identity().send().await?;
    println!(&quot;your user id: {}&quot;, resp.user_id.unwrap_or_default());
    Ok(())
}
</code></pre></pre>
<h3 id="disabling-retries"><a class="header" href="#disabling-retries">Disabling retries</a></h3>
<p>Here's an example app that creates a shared config that disables retries and then logs your AWS user's identity</p>
<pre><pre class="playground"><code class="language-rust">use aws_sdk_sts as sts;
use aws_types::config::Config;

#[tokio::main]
async fn main() -&gt; Result&lt;(), sts::Error&gt; {
    let config = aws_config::from_env().disable_retries().load().await;
    let sts_config = sts::config::Config::from(&amp;config).build();

    let sts = sts::Client::new(&amp;sts_config);
    let resp = sts.get_caller_identity().send().await?;
    println!(&quot;your user id: {}&quot;, resp.user_id.unwrap_or_default());
    Ok(())
}
</code></pre></pre>
<p>Retries can also be disabled by explicitly passing the <code>RetryConfig::NoRetries</code> enum variant to the <code>retry_config</code> builder method:</p>
<pre><pre class="playground"><code class="language-rust">use aws_sdk_sts as sts;
use aws_types::retry_config::RetryConfig;

#[tokio::main]
async fn main() -&gt; Result&lt;(), sts::Error&gt; {
    let config = aws_config::load_from_env().await;
    let sts_config = sts::config::Config::from(&amp;config).retry_config(RetryConfig::NoRetries).build();

    let sts = sts::Client::new(&amp;sts_config);
    let resp = sts.get_caller_identity().send().await?;
    println!(&quot;your user id: {}&quot;, resp.user_id.unwrap_or_default());
    Ok(())
}
</code></pre></pre>
<h2 id="behind-the-scenes-1"><a class="header" href="#behind-the-scenes-1">Behind the scenes</a></h2>
<p>Currently, when users want to send a request, the following occurs:</p>
<ol>
<li>The user creates either a shared config or a service-specific config</li>
<li>The user creates a fluent client for the service they want to interact with and passes the config they created. Internally, this creates an AWS client with a default retry policy</li>
<li>The user calls an operation builder method on the client which constructs a request</li>
<li>The user sends the request by awaiting the <code>send()</code> method</li>
<li>The smithy client creates a new <code>Service</code> and attaches a copy of its retry policy</li>
<li>The <code>Service</code> is <code>call</code>ed, sending out the request and retrying it according to the retry policy</li>
</ol>
<p>After this change, the process will work like this:</p>
<ol>
<li>The user creates either a shared config or a service-specific config
<ul>
<li>If <code>AWS_MAX_ATTEMPTS</code> is set to zero, this is invalid and we will log it with <code>tracing::warn</code>. However, this will not error until a request is made</li>
<li>If <code>AWS_MAX_ATTEMPTS</code> is 1, retries will be disabled</li>
<li>If <code>AWS_MAX_ATTEMPTS</code> is greater than 1, retries will be attempted at most as many times as is specified</li>
<li>If the user creates the config with the <code>.disable_retries</code> builder method, retries will be disabled</li>
<li>If the user creates the config with the <code>retry_config</code> builder method, retry behavior will be set according to the <code>RetryConfig</code> they passed</li>
</ul>
</li>
<li>The user creates a fluent client for the service they want to interact with and passes the config they created
<ul>
<li>Provider precedence will determine what retry behavior is actually set, working like how <code>Region</code> is set</li>
</ul>
</li>
<li>The user calls an operation builder method on the client which constructs a request</li>
<li>The user sends the request by awaiting the <code>send()</code> method</li>
<li>The smithy client creates a new <code>Service</code> and attaches a copy of its retry policy</li>
<li>The <code>Service</code> is <code>call</code>ed, sending out the request and retrying it according to the retry policy</li>
</ol>
<p>These changes will be made in such a way that they enable us to add the &quot;adaptive&quot; retry behavior at a later date without introducing a breaking change.</p>
<h2 id="changes-checklist-3"><a class="header" href="#changes-checklist-3">Changes checklist</a></h2>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Create new Kotlin decorator <code>RetryConfigDecorator</code>
<ul>
<li>Based on <a href="https://github.com/awslabs/smithy-rs/blob/main/aws/sdk-codegen/src/main/kotlin/software/amazon/smithy/rustsdk/RegionDecorator.kt">RegionDecorator.kt</a></li>
<li>This decorator will live in the <code>codegen</code> project because it has relevance outside the SDK</li>
</ul>
</li>
<li><input disabled="" type="checkbox" checked=""/>
<strong>Breaking changes:</strong>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Rename <code>aws_smithy_client::retry::Config</code> to <code>StandardRetryConfig</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Rename <code>aws_smithy_client::retry::Config::with_max_retries</code> method to <code>with_max_attempts</code> in order to follow AWS convention</li>
<li><input disabled="" type="checkbox" checked=""/>
Passing 0 to <code>with_max_attempts</code> will panic with a helpful, descriptive error message</li>
</ul>
</li>
<li><input disabled="" type="checkbox" checked=""/>
Create non-exhaustive <code>aws_types::retry_config::RetryConfig</code> enum wrapping structs that represent specific retry behaviors
<ul>
<li><input disabled="" type="checkbox" checked=""/>
A <code>NoRetry</code> variant that disables retries. Doesn't wrap a struct since it doesn't need to contain any data</li>
<li><input disabled="" type="checkbox" checked=""/>
A <code>Standard</code> variant that enables the standard retry behavior. Wraps a <code>StandardRetryConfig</code> struct.</li>
</ul>
</li>
<li><input disabled="" type="checkbox" checked=""/>
Create <code>aws_config::meta::retry_config::RetryConfigProviderChain</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Create <code>aws_config::meta::retry_config::ProvideRetryConfig</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Create <code>EnvironmentVariableMaxAttemptsProvider</code> struct
<ul>
<li>Setting AWS_MAX_ATTEMPTS=0 and trying to load from env will panic with a helpful, descriptive error message</li>
</ul>
</li>
<li><input disabled="" type="checkbox" checked=""/>
Add <code>retry_config</code> method to <code>aws_config::ConfigLoader</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Update <code>AwsFluentClientDecorator</code> to correctly configure the max retry attempts of its inner <code>aws_hyper::Client</code> based on the passed-in <code>Config</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Add tests
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Test that setting retry_config to 1 disables retries</li>
<li><input disabled="" type="checkbox" checked=""/>
Test that setting retry_config to <code>n</code> limits retries to <code>n</code> where <code>n</code> is a non-zero integer</li>
<li><input disabled="" type="checkbox" checked=""/>
Test that correct precedence is respected when overriding retry behavior in a service-specific config</li>
<li><input disabled="" type="checkbox" checked=""/>
Test that correct precedence is respected when overriding retry behavior in a shared config</li>
<li><input disabled="" type="checkbox" checked=""/>
Test that creating a config from env if AWS_MAX_ATTEMPTS=0 will panic with a helpful, descriptive error message</li>
<li><input disabled="" type="checkbox" checked=""/>
Test that setting invalid <code>max_attempts=0</code> with a <code>StandardRetryConfig</code> will panic with a helpful, descriptive error message</li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-smithy-rust-service-framework"><a class="header" href="#rfc-smithy-rust-service-framework">RFC: Smithy Rust Service Framework</a></h1>
<blockquote>
<p>Status: RFC</p>
</blockquote>
<p>The Rust Smithy Framework is a full-fledged service framework whose main
responsibility is to handle request lifecycles from beginning to end. It takes
care of input de-serialization, operation execution, output serialization,
error handling, and provides facilities to fulfill the requirements below.</p>
<h2 id="requirements-1"><a class="header" href="#requirements-1">Requirements</a></h2>
<h3 id="smithy-model-driven-code-generation"><a class="header" href="#smithy-model-driven-code-generation">Smithy model-driven code generation</a></h3>
<p>Server side code is generated from Smithy models and implements operations,
input and output structures, and errors defined in the service model.</p>
<h3 id="performance"><a class="header" href="#performance">Performance</a></h3>
<p>This new framework is built with performance in mind. It refrains from
allocating memory when not needed and tries to use a majority of
<a href="https://doc.rust-lang.org/std/borrow/trait.Borrow.html">borrowed</a> types,
handling their memory lifetimes so that a request body can be stored in memory
only once and not
<a href="https://doc.rust-lang.org/std/clone/trait.Clone.html">cloned</a> if possible.</p>
<p>The code is implemented on solid and widely used foundations. It uses
<a href="https://hyper.rs/">Hyper</a> to handle the HTTP requests, the
<a href="https://tokio.rs/">Tokio</a> ecosystem for asynchronous (non-blocking) operations
and <a href="https://docs.rs/tower/">Tower</a> to implement middleware such as timeouts,
rate limiting, retries, and more. CPU intensive operations are scheduled on a
separated thread-pool to avoid blocking the event loop.</p>
<p>It uses Tokio <a href="https://tokio.rs/blog/2021-07-announcing-axum">axum</a>, an HTTP
framework built on top of the technologies mentioned above which handles
routing, request extraction, response building, and workers lifecycle. Axum is
a relatively thin layer on top of Hyper and adds very little overhead, so its
<a href="https://github.com/programatik29/rust-web-benchmarks/blob/master/results/hello-world.md">performance is comparable</a>
to Hyper.</p>
<p>The framework should allow customers to use the built-in HTTP server or
select other transport implementations that can be more performant or better
suited than HTTP for their use case.</p>
<h3 id="extensibility"><a class="header" href="#extensibility">Extensibility</a></h3>
<p>We want to deliver an extensible framework that can plugin components possibly
during code generation and at runtime for specific scenarios that cannot be
covered during generation. These components are developed using a standard
<a href="https://doc.rust-lang.org/book/ch10-02-traits.html">interface</a> provided by the
framework itself.</p>
<h3 id="observability"><a class="header" href="#observability">Observability</a></h3>
<p>Being able to report and trace the status of the service is vital for the
success of any product. The framework is integrated with tracing and allows
non-blocking I/O through the asynchronous
<a href="https://tracing.rs/tracing_appender/index.html#non-blocking-writer">tracing appender</a>.</p>
<p>Metrics and logging are built with extensibility in mind, allowing customers to
plug their own handlers following a well defined interface provided by the
framework.</p>
<h3 id="client-generation"><a class="header" href="#client-generation">Client generation</a></h3>
<p>Client generation is deferred to the various Smithy implementations.</p>
<h3 id="benchmarking"><a class="header" href="#benchmarking">Benchmarking</a></h3>
<p>Benchmarking the framework is key and customers can't use anything that
compromises the fundamental business objectives of latency and performance.</p>
<h3 id="model-validation"><a class="header" href="#model-validation">Model validation</a></h3>
<p>The generated service code is responsible for validating the model constraints of input structures.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-service-specific-middleware"><a class="header" href="#rfc-service-specific-middleware">RFC: Service-specific middleware</a></h1>
<blockquote>
<p>Status: <a href="https://github.com/awslabs/smithy-rs/pull/959">Implemented</a></p>
</blockquote>
<p>For a summarized list of proposed changes, see the <a href="rfcs/rfc0006_service_specific_middleware.html#changes-checklist">Changes Checklist</a> section.</p>
<p>Currently, all services use a centralized <code>AwsMiddleware</code> that is defined in the (poorly named) <code>aws-hyper</code> crate. This
poses a number of long term risks and limitations:</p>
<ol>
<li>When creating a Smithy Client directly for a given service, customers are forced to implicitly assume that the
service uses stock <code>AwsMiddleware</code>. This prevents us from <em>ever</em> changing the middleware stack for a service in the
future.</li>
<li>It is impossible / impractical in the current situation to alter the middleware stack for a given service. For
services like S3, we will almost certainly want to customize endpoint middleware in a way that is currently
impossible.</li>
</ol>
<p>In light of these limitations, this RFC proposes moving middleware into each generated service. <code>aws-inlineable</code> will be
used to host and test the middleware stack. Each service will then define a public <code>middleware</code> module containing their
middleware stack.</p>
<h2 id="terminology-3"><a class="header" href="#terminology-3">Terminology</a></h2>
<ul>
<li><strong>Middleware</strong>: A tower layer that augments <code>operation::Request -&gt; operation::Response</code> for things like signing and
endpoint resolution.</li>
<li><strong>Aws Middleware</strong>: A specific middleware stack that meets the requirements for AWS services.</li>
<li><strong>Smithy Client</strong>: A <code>aws_smithy_client::Client&lt;C, M, R&gt;</code> struct that is responsible for gluing together the
connector, middleware, and retry policy. This is not generated and lives in the <code>aws-smithy-client</code> crate.</li>
<li><strong>Fluent Client</strong>: A code-generated <code>Client&lt;C, M, R&gt;</code> that has methods for each service operation on it. A fluent
builder is generated alongside it to make construction easier.</li>
<li><strong>AWS Client</strong>: A specialized Fluent Client that defaults to using a <code>DynConnector</code>, <code>AwsMiddleware</code>, and <code>Standard</code>
retry policy.</li>
<li><strong>Shared Config</strong>: An <code>aws_types::Config</code> struct that is responsible for storing shared configuration data that is
used across all services. This is not generated and lives in the <code>aws-types</code> crate.</li>
<li><strong>Service-specific Config</strong>: A code-generated <code>Config</code> that has methods for setting service-specific configuration.
Each <code>Config</code> is defined in the <code>config</code> module of its parent service. For example, the S3-specific config struct
is <code>use</code>able from <code>aws_sdk_s3::config::Config</code> and re-exported as <code>aws_sdk_s3::Config</code>.</li>
</ul>
<h1 id="detailed-design"><a class="header" href="#detailed-design">Detailed Design</a></h1>
<p>Currently, <code>AwsMiddleware</code> is defined in <code>aws-hyper</code>. As part of this change, an <code>aws-inlineable</code> dependency will be
added containing code that is largely identical. This will be exposed in a public <code>middleware</code> module in all generated
services. At some future point, we could even expose a baseline set of default middleware for whitelabel Smithy services
to make them easier to use out-of-the-box.</p>
<p>The <code>ClientGenerics</code> parameter of the <code>AwsFluentClientGenerator</code> will be updated to become a <code>RuntimeType</code>, enabling
loading the type directly. This has the advantage of making it fairly easy to do per-service middleware stacks since we
can easily configure <code>AwsFluentClientGenerator</code> to insert different types based on the service id.</p>
<h1 id="changes-checklist-4"><a class="header" href="#changes-checklist-4">Changes Checklist</a></h1>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Move aws-hyper into aws-inlineable. Update comments as needed including with a usage example about how customers can augment it.</li>
<li><input disabled="" type="checkbox" checked=""/>
Refactor <code>ClientGenerics</code> to contain a RuntimeType instead of a string and configure. Update <code>AwsFluentClientDecorator</code>.</li>
<li><input disabled="" type="checkbox" checked=""/>
Update all code and examples that use <code>aws-hyper</code> to use service-specific middleware.</li>
<li><input disabled="" type="checkbox" checked=""/>
Push an updated README to aws-hyper deprecating the package, explaining what happened. Do <em>not</em> yank previous versions since those will be relied on by older SDK versions.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-split-release-process"><a class="header" href="#rfc-split-release-process">RFC: Split Release Process</a></h1>
<blockquote>
<p>Status: Implemented in <a href="https://github.com/awslabs/smithy-rs/pull/986">smithy-rs#986</a> and <a href="https://github.com/awslabs/aws-sdk-rust/pull/351">aws-sdk-rust#351</a></p>
</blockquote>
<p>At the time of writing, the <code>aws-sdk-rust</code> repository is used exclusively
for the entire release process of both the Rust runtime crates from <code>smithy-rs</code> as
well as the AWS runtime crates and the AWS SDK. This worked well when <code>smithy-rs</code> was
only used for the AWS SDK, but now that it's also used for server codegen, there
are issues around publishing the server-specific runtime crates since they don't
belong to the SDK.</p>
<p>This RFC proposes a new split-release process so that the entire <code>smithy-rs</code> runtime
can be published separately before the AWS SDK is published.</p>
<h2 id="terminology-4"><a class="header" href="#terminology-4">Terminology</a></h2>
<ul>
<li><strong>Smithy Runtime Crate</strong>: A crate that gets published to crates.io and supports
the code generated by <code>smithy-rs</code>. These crates don't provide any SDK-only functionality.
These crates can support client and/or server code, and clients or servers may use
only a subset of them.</li>
<li><strong>AWS Runtime Crate</strong>: A crate of SDK-specific code that supports the code generated
by the <code>aws/codegen</code> module in <code>smithy-rs</code>. These also get published to crates.io.</li>
<li><strong>Publish-ready Bundle</strong>: A build artifact that is ready to publish to crates.io without
additional steps (such as running the publisher tool's <code>fix-manifests</code> subcommand). Publishing
one group of crates before another is not considered an additional step for this definition.</li>
<li><strong>Releaser</strong>: A developer, automated process, or combination of the two that performs the actual release.</li>
</ul>
<h2 id="requirements-2"><a class="header" href="#requirements-2">Requirements</a></h2>
<p>At a high level, the requirements are: publish from both <code>smithy-rs</code> and <code>aws-sdk-rust</code>
while preserving our current level of confidence in the quality of the release. This
can be enumerated as:</p>
<ol>
<li>All Smithy runtime crates must be published together from <code>smithy-rs</code></li>
<li>AWS runtime crates and the SDK must be published together from <code>aws-sdk-rust</code></li>
<li>CI on <code>smithy-rs</code> must give confidence that the Smithy runtime crates,
AWS runtime crates, and SDK are all at the right quality bar for publish.</li>
<li>CI on the <code>aws-sdk-rust</code> repository must give confidence that the AWS SDK and its
runtime crates are at the right quality bar for publish. To do this successfully,
it must run against the exact versions of the Smithy runtime crates the code was
generated against <em>both before AND after they have been published to crates.io</em>.</li>
</ol>
<h2 id="background-how-publishing-worked-before"><a class="header" href="#background-how-publishing-worked-before">Background: How Publishing Worked Before</a></h2>
<p>The publish process to crates.io relied on copying all the Smithy runtime crates
into the final <code>aws-sdk-rust</code> repository. Overall, the process looked as follows:</p>
<ol>
<li><code>smithy-rs</code> generates a complete <code>aws-sdk-rust</code> source bundle at CI time</li>
<li>The releaser copies the generated bundle over to <code>aws-sdk-rust</code></li>
<li>The releaser runs the <code>publisher fix-manifests</code> subcommand to correct the
<code>Cargo.toml</code> files generated by <code>smithy-rs</code></li>
<li>The <code>aws-sdk-rust</code> CI performs one last pass on the code to verify it's sound</li>
<li>The releaser runs the <code>publisher publish</code> subcommand to push all the crates up to crates.io</li>
</ol>
<h2 id="proposed-solution"><a class="header" href="#proposed-solution">Proposed Solution</a></h2>
<p>CI in <code>smithy-rs</code> will be revised to generate two separate build artifacts where it generates
just an SDK artifact previously. Now, it will have two build targets that get executed from CI
to generate these artifacts:</p>
<ul>
<li><code>rust-runtime:assemble</code> - Generates a publish-ready bundle of Smithy runtime crates.</li>
<li><code>aws:sdk:assemble</code> - Generates a publish-ready bundle of AWS runtime crates, SDK crates,
and just the Smithy runtime crates that are used by the SDK.</li>
</ul>
<p>The <code>aws-sdk-rust</code> repository will have a new <code>next</code> branch that has its own set of CI workflows
and branch protection rules. The releaser will take the <code>aws:sdk:assemble</code> artifact and apply it
directly to this <code>next</code> branch as would have previously been done against the <code>main</code> branch.
The <code>main</code> branch will continue to have the same CI as <code>next</code>.</p>
<p>When it's time to cut a release, the releaser will do the following:</p>
<ol>
<li>Tag <code>smithy-rs</code> with the desired version number</li>
<li>Wait for CI to build artifacts for the tagged release</li>
<li>Pull-request the SDK artifacts over to <code>aws-sdk-rust/next</code> (this will be automated in the future)</li>
<li>Pull-request merge <code>aws-sdk-rust/next</code> into <code>aws-sdk-rust/main</code></li>
<li>Wait for successful CI in <code>main</code></li>
<li>Tag release for <code>main</code></li>
<li>Publish SDK with publisher tool</li>
</ol>
<p>The server team can then download the <code>rust-runtime:assemble</code> build artifact for the tagged release
in <code>smithy-rs</code>, and publish the <code>aws-smithy-http-server</code> crate from there.</p>
<h3 id="avoiding-mistakes-by-disallowing-creation-of-publish-ready-bundles-outside-of-ci"><a class="header" href="#avoiding-mistakes-by-disallowing-creation-of-publish-ready-bundles-outside-of-ci">Avoiding mistakes by disallowing creation of publish-ready bundles outside of CI</a></h3>
<p>It should be difficult to accidentally publish a locally built set of crates. To add friction to this,
the <code>smithy-rs</code> build process will look for the existence of the <code>GITHUB_ACTIONS=true</code> environment variable.
If this environment variable is not set, then it will pass a flag to the Rust codegen plugin that tells it to
emit a <code>publish = false</code> under <code>[package]</code> in the generated <code>Cargo.toml</code>.</p>
<p>This could be easily circumvented, but the goal is to reduce the chances of accidentally publishing
crates rather than making it impossible.</p>
<h2 id="alternatives-considered"><a class="header" href="#alternatives-considered">Alternatives Considered</a></h2>
<h3 id="publish-smithy-runtime-crates-from-smithy-rs-build-artifacts"><a class="header" href="#publish-smithy-runtime-crates-from-smithy-rs-build-artifacts">Publish Smithy runtime crates from <code>smithy-rs</code> build artifacts</a></h3>
<p>This approach is similar to the proposed solution, except that the SDK would not publish
the Smithy runtime crates. The <code>aws-sdk-rust/main</code> branch would have a small tweak to its CI
so that the SDK is tested against the Smithy runtime crates that are published to crates.io
This CI process would look as follows:</p>
<ol>
<li>Shallow clone <code>aws-sdk-rust</code> with the revision being tested</li>
<li>Run a script to remove the <code>path</code> argument for the Smithy runtime crate dependencies for every crate
in <code>aws-sdk-rust</code>. For example,</li>
</ol>
<pre><code class="language-toml">aws-smithy-types = { version = &quot;0.33.0&quot;, path = &quot;../aws-smithy-types&quot; }
</code></pre>
<p>Would become:</p>
<pre><code class="language-toml">aws-smithy-types = { version = &quot;0.33.0&quot; }
</code></pre>
<ol start="3">
<li>Run the tests as usual</li>
</ol>
<p>When it's time to cut a release, the releaser will do the following:</p>
<ol>
<li>Tag <code>smithy-rs</code> with the desired version number</li>
<li>Wait for CI to build artifacts for the tagged release</li>
<li>Pull-request the SDK artifacts over to <code>aws-sdk-rust/next</code></li>
<li>Wait for successful CI in <code>aws-sdk-rust/next</code></li>
<li>Download the Smithy runtime crates build artifact and publish it to crates.io</li>
<li>Pull-request merge <code>aws-sdk-rust/next</code> into <code>aws-sdk-rust/main</code></li>
<li>Wait for successful CI in <code>main</code> (this time actually running against the crates.io Smithy runtime crates)</li>
<li>Tag release for <code>main</code></li>
<li>Publish SDK with publisher tool</li>
</ol>
<h3 id="keep-smithy-runtime-crates-in-smithy-rs"><a class="header" href="#keep-smithy-runtime-crates-in-smithy-rs">Keep Smithy runtime crates in <code>smithy-rs</code></a></h3>
<p>This approach is similar to the previous alternative, except that the <code>aws-sdk-rust</code> repository
won't have a snapshot of the Smithy runtime crates, and an additional step needs to be performed
during CI for the <code>next</code> branch so that it looks as follows:</p>
<ol>
<li>Make a shallow clone of <code>aws-sdk-rust/next</code></li>
<li>Retrieve the <code>smithy-rs</code> commit hash that was used to generate the SDK from a file
that was generated alongside the rest of the build artifacts from <code>smithy-rs</code> and
copied into <code>aws-sdk-rust</code>.</li>
<li>Make a shallow clone of <code>smithy-rs</code> at the correct commit hash</li>
<li>Use a script to add a <code>[patch]</code> section to all the AWS SDK crates to point to the
Smithy runtime crates from the local clone of <code>smithy-rs</code>.
For example:</li>
</ol>
<pre><code class="language-toml"># The dependencies section is left alone, but is here for context
[dependencies]
# Some version of aws-smithy-types that isn't on crates.io yet, referred to as `&lt;unreleased&gt;` below
aws-smithy-types = &quot;&lt;unreleased&gt;&quot;

# This patch section gets added by the script
[patch.crates-io]
aws-smithy-types = { version = &quot;&lt;unreleased&gt;&quot;, path = &quot;path/to/local/smithy-rs/rust-runtime/aws-smithy-types&quot;}
</code></pre>
<ol start="5">
<li>Run CI as normal.</li>
</ol>
<p><strong>Note:</strong> <code>smithy-rs</code> would need to do the same patching in CI as <code>aws-sdk-rust/next</code> since the generated
SDK would not have path dependencies for the Smithy runtime crates (since they are a publish-ready bundle
intended for landing in <code>aws-sdk-rust</code>). The script that does this patching could live in <code>smithy-rs</code> and be
reused by <code>aws-sdk-rust</code>.</p>
<p>The disadvantage of this approach is that a customer having an issue with the current release wouldn't be able
to get a fix sooner by patching their own project's crate manifest to use the <code>aws-sdk-rust/next</code> branch before
a release is cut since their project wouldn't be able to find the unreleased Smithy runtime crates.</p>
<h2 id="changes-checklist-5"><a class="header" href="#changes-checklist-5">Changes Checklist</a></h2>
<ul>
<li>In <code>smithy-rs</code>:
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Move publisher tool from <code>aws-sdk-rust</code> into <code>smithy-rs</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Modify <code>aws:sdk:assemble</code> target to run the publisher <code>fix-manifests</code> subcommand</li>
<li><input disabled="" type="checkbox" checked=""/>
Add <code>rust-runtime:assemble</code> target that generates publish-ready Smithy runtime crates</li>
<li><input disabled="" type="checkbox" checked=""/>
Add CI step to create Smithy runtime bundle artifact</li>
<li><input disabled="" type="checkbox" checked=""/>
Add <code>GITHUB_ACTIONS=true</code> env var check for setting the <code>publish</code> flag in generated AND runtime manifests</li>
<li><input disabled="" type="checkbox" checked=""/>
Revise publisher tool to publish from an arbitrary directory</li>
</ul>
</li>
<li>In <code>aws-sdk-rust</code>:
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Implement CI for the <code>aws-sdk-rust/next</code> branch</li>
<li><input disabled="" type="checkbox" checked=""/>
Remove the publisher tool</li>
</ul>
</li>
<li><input disabled="" type="checkbox" checked=""/>
Update release process documentation</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="summary-1"><a class="header" href="#summary-1">Summary</a></h2>
<blockquote>
<p>Status: Implemented</p>
</blockquote>
<p>Smithy <a href="https://awslabs.github.io/smithy/1.0/spec/core/behavior-traits.html#paginated-trait">models paginated responses</a>
. Customers of Smithy generated code &amp; the Rust SDK will have an improved user experience if code is generated to
support this. Fundamentally, paginators are a way to automatically make a series of requests with the SDK, where subsequent
requests automatically forward output from the previous responses. There is nothing a paginator does that a user could not do manually,
they merely simplify the common task of interacting with paginated APIs. **Specifically, a paginator will resend the orginal request
but with <code>inputToken</code> updated to the value of the previous <code>outputToken</code>.</p>
<p>In this RFC, we propose modeling paginated data as
a  <a href="https://docs.rs/tokio-stream/0.1.5/tokio_stream/#traits"><code>Stream</code></a> of output shapes.</p>
<ul>
<li>When an output is paginated, a <code>paginate()</code> method will be added to the high level builder</li>
<li>An <code>&lt;OperationName&gt;Paginator</code> struct will be generated into the <code>paginator</code> module.</li>
<li>If <code>items</code> is modeled, <code>paginate().items()</code> will be added to produce the paginated
items. <code>&lt;OperationName&gt;PaginatorItems</code> will be generated into the <code>paginator</code> module.</li>
</ul>
<p>The <a href="https://docs.rs/tokio-stream/latest/tokio_stream/index.html"><code>Stream</code></a> trait enables customers to use a number of
abstractions including simple looping, and <code>collect()</code>ing all data in a single call. A paginator will resend the
original input, but with the field marked <code>inputToken</code> to the value of <code>outputToken</code> in the previous output.</p>
<p>Usage example:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let paginator = client
    .list_tables()
    .paginate()
    .items()
    .page_size(10)
    .send()
    .await;
let tables: Result&lt;Vec&lt;_ &gt;, _ &gt; = paginator.collect().await;
<span class="boring">}
</span></code></pre></pre>
<p>Paginators are lazy and only retrieve pages when polled by a client.</p>
<h3 id="details"><a class="header" href="#details">Details</a></h3>
<p>Paginators will be generated into the <code>paginator</code> module of service crates. Currently, paginators are <em>not</em> feature gated, but this
could be considered in the future. A <code>paginator</code> struct captures 2 pieces of data:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// dynamodb/src/paginator.rs
struct ListTablesPaginator&lt;C, M, R&gt; {
    // holds the low-level client and configuration
    handle: Arc&lt;Handle&lt;C, M, R&gt;&gt;,

    // input builder to construct the actual input on demand
    input: ListTablesInputBuilder
}
<span class="boring">}
</span></code></pre></pre>
<p>In addition to the basic usage example above, when <code>pageSize</code> is modeled, customers can specify the page size during
pagination:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let mut tables = vec![];
let mut pages = client
    .list_tables()
    .paginate()
    .page_size(20)
    .send();
while let Some(next_page) = pages.try_next().await? {
    // pages of 20 items requested from DynamoDb
    tables.extend(next_page.table_names.unwrap_or_default().into_iter());
}
<span class="boring">}
</span></code></pre></pre>
<p>Paginators define a public method <code>send()</code>. This method
returns <code>impl Stream&lt;Item=Result&lt;OperationOutput, OperationError&gt;</code>. This uses <code>FnStream</code> defined in the <code>aws-smithy-async</code> crate which
enables demand driven execution of a closure. A rendezvous channel is used which will block on <code>send</code> until demand exists.</p>
<p>When modeled by Smithy, <code>page_size</code> which automatically sets the appropriate page_size parameter and <code>items()</code> which returns an
automatically flattened paginator are also generated. <strong>Note</strong>: <code>page_size</code> directly sets the modeled parameter on the internal builder.
This means that a value set for page size will override any previously set value for that field.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Generated paginator for ListTables
impl&lt;C, M, R&gt; ListTablesPaginator&lt;C, M, R&gt;
{
  /// Set the page size
  pub fn page_size(mut self, limit: i32) -&gt; Self {
    self.builder.limit = Some(limit);
    self
  }

  /// Create a flattened paginator
  ///
  /// This paginator automatically flattens results using `table_names`. Queries to the underlying service
  /// are dispatched lazily.
  pub fn items(self) -&gt; crate::paginator::ListTablesPaginatorItems&lt;C, M, R&gt; {
    crate::paginator::ListTablesPaginatorItems(self)
  }

  /// Create the pagination stream
  ///
  /// _Note:_ No requests will be dispatched until the stream is used (eg. with [`.next().await`](tokio_stream::StreamExt::next)).
  pub async fn send(
    self,
  ) -&gt; impl tokio_stream::Stream&lt;
    Item = std::result::Result&lt;
      crate::output::ListTablesOutput,
      aws_smithy_http::result::SdkError&lt;crate::error::ListTablesError&gt;,
    &gt;,
  &gt; + Unpin
  {
    // Move individual fields out of self for the borrow checker
    let builder = self.builder;
    let handle = self.handle;
    fn_stream::FnStream::new(move |tx| {
      Box::pin(async move {
        // Build the input for the first time. If required fields are missing, this is where we'll produce an early error.
        let mut input = match builder.build().map_err(|err| {
          SdkError::ConstructionFailure(err.into())
        }) {
          Ok(input) =&gt; input,
          Err(e) =&gt; {
            let _ = tx.send(Err(e)).await;
            return;
          }
        };
        loop {
          let op = match input.make_operation(&amp;handle.conf).await.map_err(|err| {
            SdkError::ConstructionFailure(err.into())
          }) {
            Ok(op) =&gt; op,
            Err(e) =&gt; {
              let _ = tx.send(Err(e)).await;
              return;
            }
          };
          let resp = handle.client.call(op).await;
          // If the input member is None or it was an error
          let done = match resp {
            Ok(ref resp) =&gt; {
              input.exclusive_start_table_name = crate::lens::reflens_structure_crate_output_list_tables_output_last_evaluated_table_name(resp).cloned();
              input.exclusive_start_table_name.is_none()
            }
            Err(_) =&gt; true,
          };
          if let Err(_) = tx.send(resp).await {
            // receiving end was dropped
            return;
          }
          if done {
            return;
          }
        }
      })
    })
  }
}
<span class="boring">}
</span></code></pre></pre>
<p><strong>On Box::pin</strong>: The stream returned by <code>AsyncStream</code> does not implement <code>Unpin</code>. Unfortunately, this makes iteration
require an invocation of <code>pin_mut!</code> and generates several hundred lines of compiler errors. Box::pin seems a worthwhile
trade off to improve the user experience.</p>
<p><strong>On the <code>+ Unpin</code> bound</strong>: Because auto-traits leak across <code>impl Trait</code> boundaries, <code>+ Unpin</code> prevents accidental
regressions in the generated code which would break users.</p>
<p><strong>On the crate::reflens::...</strong>: We use <code>LensGenerator.kt</code> to generate potentially complex accessors to deeply nested fields.</p>
<h3 id="updates-to-ergonomic-clients"><a class="header" href="#updates-to-ergonomic-clients">Updates to ergonomic clients</a></h3>
<p>The <code>builders</code> generated by ergonomic clients will gain the following method, if they represent an operation that implements the <code>Paginated</code> trait:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// Create a paginator for this request
///
/// Paginators are used by calling [`send().await`](crate::paginator::ListTablesPaginator::send) which returns a [`Stream`](tokio_stream::Stream).
pub fn paginate(self) -&gt; crate::paginator::ListTablesPaginator&lt;C, M, R&gt; {
  crate::paginator::ListTablesPaginator::new(self.handle, self.inner)
}
<span class="boring">}
</span></code></pre></pre>
<h2 id="discussion-areas"><a class="header" href="#discussion-areas">Discussion Areas</a></h2>
<h3 id="on-sendawait"><a class="header" href="#on-sendawait">On <code>send().await</code></a></h3>
<p>Calling <code>send().await</code> is not necessary from an API perspective—we could have the paginators impl-stream directly. However,
it enables using <code>impl Trait</code> syntax and also makes the API consistent with other SDK APIs.</p>
<h3 id="on-tokio_streamstream"><a class="header" href="#on-tokio_streamstream">On <code>tokio_stream::Stream</code></a></h3>
<p>Currently, the core trait we use is <code>tokio_stream::Stream</code>. This is a re-export from futures-util. There are a few other choices:</p>
<ol>
<li>Re-export <code>Stream</code> from tokio_stream.</li>
<li>Use <code>futures_util</code> directly</li>
</ol>
<h3 id="on-generics"><a class="header" href="#on-generics">On Generics</a></h3>
<p>Currently, the paginators forward the generics from the client (<code>C, M, R</code>) along with their fairly annoying bounds.
However, if we wanted to we <em>could</em> simplify this and erase all the generics when the paginator was created. Since everything
is code generated, there isn't actually much duplicated code in the generator, just in the generated code.</p>
<h2 id="changes-checklist-6"><a class="header" href="#changes-checklist-6">Changes Checklist</a></h2>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Create and test <code>FnStream</code> abstraction</li>
<li><input disabled="" type="checkbox" checked=""/>
Generate page-level paginators</li>
<li><input disabled="" type="checkbox" checked=""/>
Generate <code>.items()</code> paginators</li>
<li><input disabled="" type="checkbox" checked=""/>
Generate doc hints pointing people to paginators</li>
<li><input disabled="" type="checkbox" checked=""/>
Integration test using mocked HTTP traffic against a generated paginator for a real service</li>
<li><input disabled="" type="checkbox"/>
Integration test using real traffic</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-examples-consolidation"><a class="header" href="#rfc-examples-consolidation">RFC: Examples Consolidation</a></h1>
<blockquote>
<p>Status: Implemented</p>
</blockquote>
<p>Currently, the AWS Rust SDK's examples are duplicated across
<a href="https://github.com/awslabs/aws-sdk-rust"><code>awslabs/aws-sdk-rust</code></a>,
<a href="https://github.com/awslabs/smithy-rs"><code>awslabs/smithy-rs</code></a>,
and <a href="https://github.com/awsdocs/aws-doc-sdk-examples"><code>awsdocs/aws-doc-sdk-examples</code></a>.
The <code>smithy-rs</code> repository was formerly the source of truth for examples,
with the examples being copied over to <code>aws-sdk-rust</code> as part of the release
process, and examples were manually copied over to <code>aws-doc-sdk-examples</code> so that
they could be included in the developer guide.</p>
<p>Now that the SDK is more stable with less frequent breaking changes,
the <code>aws-doc-sdk-examples</code> repository can become the source of truth
so long as the examples are tested against <code>smithy-rs</code> and continue to be
copied into <code>aws-sdk-rust</code>.</p>
<h2 id="requirements-3"><a class="header" href="#requirements-3">Requirements</a></h2>
<ol>
<li>Examples are authored and maintained in <code>aws-doc-sdk-examples</code></li>
<li>Examples are no longer present in <code>smithy-rs</code></li>
<li>CI in <code>smithy-rs</code> checks out examples from <code>aws-doc-sdk-examples</code> and
builds them against the generated SDK. Success for this CI job is optional for merging
since there can be a time lag between identifying that examples are broken and fixing them.</li>
<li>Examples must be copied into <code>aws-sdk-rust</code> so that the examples for a specific
version of the SDK can be easily referenced.</li>
<li>Examples must be verified in <code>aws-sdk-rust</code> prior to merging into the <code>main</code> branch.</li>
</ol>
<h2 id="example-ci-in-smithy-rs"><a class="header" href="#example-ci-in-smithy-rs">Example CI in <code>smithy-rs</code></a></h2>
<p>A CI job will be added to <code>smithy-rs</code> that:</p>
<ol>
<li>Depends on the CI job that generates the full AWS SDK</li>
<li>Checks out the <code>aws-doc-sdk-examples</code> repository</li>
<li>Modifies example <strong>Cargo.toml</strong> files to point to the newly generated AWS SDK crates</li>
<li>Runs <code>cargo check</code> on each example</li>
</ol>
<p>This job will not be required to pass for branch protection, but will
let us know that examples need to be updated before the next release.</p>
<h2 id="auto-sync-to-aws-sdk-rust-from-smithy-rs-changes"><a class="header" href="#auto-sync-to-aws-sdk-rust-from-smithy-rs-changes">Auto-sync to <code>aws-sdk-rust</code> from <code>smithy-rs</code> changes</a></h2>
<p>The auto-sync job that copies generated code from <code>smithy-rs</code> into the
<code>aws-sdk-rust/next</code> branch will be updated to check out the <code>aws-doc-sdk-examples</code>
repository and copy the examples into <code>aws-sdk-rust</code>. The example <strong>Cargo.toml</strong> files
will also be updated to point to the local crate paths as part of this process.</p>
<p>The <code>aws-sdk-rust</code> CI already requires examples to compile, so merging <code>next</code> into <code>main</code>,
the step required to perform a release, will be blocked until the examples are fixed.</p>
<p>In the event the examples don't work on the <code>next</code> branch, developers and example writers
will need to be able to point the examples in <code>aws-doc-sdk-examples</code> to the generated
SDK in <code>next</code> so that they can verify their fixes. This can be done by hand, or a tool
can be written to automate it if a significant number of examples need to be fixed.</p>
<h2 id="process-risks"><a class="header" href="#process-risks">Process Risks</a></h2>
<p>There are a couple of risks with this approach:</p>
<ol>
<li>
<p><strong>Risk:</strong> Examples are broken and an urgent fix needs to be released.</p>
<p><strong>Possible mitigations:</strong></p>
<ol>
<li>Revert the change that broke the examples and then add the urgent fix</li>
<li>Create a patch branch in <code>aws-sdk-rust</code>, apply the fix to that based off an older
version of <code>smithy-rs</code> with the fix applied, and merge that into <code>main</code>.</li>
</ol>
</li>
<li>
<p><strong>Risk:</strong> A larger project requires changes to examples prior to GA, but multiple releases
need to occur before the project completion.</p>
<p><strong>Possible mitigations:</strong></p>
<ol>
<li>If the required changes compile against the older SDK, then just make the changes
to the examples.</li>
<li>Feature gate any incremental new functionality in <code>smithy-rs</code>, and work on example
changes on a branch in <code>aws-doc-sdk-examples</code>. When wrapping up the project,
remove the feature gating and merge the examples into the <code>main</code> branch.</li>
</ol>
</li>
</ol>
<h2 id="alternatives"><a class="header" href="#alternatives">Alternatives</a></h2>
<h3 id="aws-sdk-rust-as-the-source-of-truth"><a class="header" href="#aws-sdk-rust-as-the-source-of-truth"><code>aws-sdk-rust</code> as the source of truth</a></h3>
<p>Alternatively, the examples could reside in <code>aws-sdk-rust</code>, be referenced
from <code>smithy-rs</code> CI, and get copied into <code>aws-doc-sdk-examples</code> for inclusion
in the user guide.</p>
<p><strong>Pros:</strong></p>
<ul>
<li>Prior to GA, fixing examples after making breaking changes to the SDK would be easier.
Otherwise, <strong>Cargo.toml</strong> files have to be temporarily modified to point to the
<code>aws-sdk-rust/next</code> branch in order to make fixes.</li>
<li>If a customer discovers examples via the <code>aws-sdk-rust</code> repository rather than via the
SDK user guide, then it would be more obvious how to make changes to examples. At time
of writing, the examples in the user guide link to the <code>aws-doc-sdk-examples</code> repository,
so if the examples are discovered that way, then updating them should already be clear.</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>Tooling would need to be built to sync examples from <code>aws-sdk-rust</code> into
<code>aws-doc-sdk-examples</code> so that they could be incorporated into the user guide.</li>
<li>Creates a circular dependency between the <code>aws-sdk-rust</code> and <code>smithy-rs</code> repositories.
CI in <code>smithy-rs</code> needs to exercise examples, which would be in <code>aws-sdk-rust</code>, and
<code>aws-sdk-rust</code> has its code generated by <code>smithy-rs</code>. This is workable, but may lead
to problems later on.</li>
</ul>
<p>The tooling to auto-sync from <code>aws-sdk-rust</code> into <code>aws-doc-sdk-examples</code> will likely cost
more than tooling to temporarily update <strong>Cargo.toml</strong> files to make example fixes (if
that tooling is even necessary).</p>
<h2 id="changes-checklist-7"><a class="header" href="#changes-checklist-7">Changes Checklist</a></h2>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Add example CI job to <code>smithy-rs</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Diff examples in <code>smithy-rs</code> and <code>aws-doc-sdk-examples</code> and move desired differences into <code>aws-doc-sdk-examples</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Apply example fix PRs from <code>aws-sdk-rust</code> into <code>aws-doc-sdk-examples</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Update <code>smithy-rs</code> CI to copy examples from <code>aws-doc-sdk-examples</code> rather than from smithy-rs</li>
<li><input disabled="" type="checkbox" checked=""/>
Delete examples from <code>smithy-rs</code></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-waiters"><a class="header" href="#rfc-waiters">RFC: Waiters</a></h1>
<blockquote>
<p>Status: Accepted</p>
</blockquote>
<p>Waiters are a convenient polling mechanism to wait for a resource to become available or to
be deleted. For example, a waiter could be used to wait for a S3 bucket to be created after
a call to the <code>CreateBucket</code> API, and this would only require a small amount of code rather
than building out an entire polling mechanism manually.</p>
<p>At the highest level, a waiter is a simple polling loop (pseudo-Rust):</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Track state that contains the number of attempts made and the previous delay
let mut state = initial_state();

loop {
    // Poll the service
    let result = poll_service().await;

    // Classify the action that needs to be taken based on the Smithy model
    match classify(result) {
        // If max attempts hasn't been exceeded, then retry after a delay. Otherwise, error.
        Retry =&gt; if state.should_retry() {
            let delay = state.next_retry();
            sleep(delay).await;
        } else {
            return error_max_attempts();
        }
        // Otherwise, if the termination condition was met, return the output
        Terminate(result) =&gt; return result,
    }
}
<span class="boring">}
</span></code></pre></pre>
<p>In the AWS SDK for Rust, waiters can be added without making any backwards breaking changes
to the current API. This doc outlines the approach to add them in this fashion, but does <em>NOT</em>
examine code generating response classification from JMESPath expressions, which can be left
to the implementer without concern for the overall API.</p>
<h2 id="terminology-5"><a class="header" href="#terminology-5">Terminology</a></h2>
<p>Today, there are three layers of <code>Client</code> that are easy to confuse, so to make the following easier to follow,
the following terms will be used:</p>
<ul>
<li><strong>Connector</strong>: An implementor of Tower's <code>Service</code> trait that converts a request into a response. This is typically
a thin wrapper around a Hyper client.</li>
<li><strong>Smithy Client</strong>: A <code>aws_smithy_client::Client&lt;C, M, R&gt;</code> struct that is responsible for gluing together
the connector, middleware, and retry policy. This isn't intended to be used directly.</li>
<li><strong>Fluent Client</strong>: A code generated <code>Client&lt;C, M, R&gt;</code> that has methods for each service operation on it.
A fluent builder is generated alongside it to make construction easier.</li>
<li><strong>AWS Client</strong>: A specialized Fluent Client that uses a <code>DynConnector</code>, <code>DefaultMiddleware</code>,
and <code>Standard</code> retry policy.</li>
</ul>
<p>All of these are just called <code>Client</code> in code today. This is something that could be clarified in a separate refactor.</p>
<h2 id="requirements-4"><a class="header" href="#requirements-4">Requirements</a></h2>
<p>Waiters must adhere to the <a href="https://awslabs.github.io/smithy/1.0/spec/waiters.html">Smithy waiter specification</a>. To summarize:</p>
<ol>
<li>Waiters are specified by the Smithy <code>@waitable</code> trait</li>
<li>Retry during polling must be exponential backoff with jitter, with the min/max delay times and
max attempts configured by the <code>@waitable</code> trait</li>
<li>The SDK's built-in retry needs to be replaced by the waiter's retry since the Smithy model
can specify retry conditions that are contrary to the defaults. For example, an error that
would otherwise be retried by default might be the termination condition for the waiter.</li>
<li>Classification of the response must be code generated based on the JMESPath expression in the model.</li>
</ol>
<h2 id="waiter-api"><a class="header" href="#waiter-api">Waiter API</a></h2>
<p>To invoke a waiter, customers will only need to invoke a single function on the AWS Client. For example,
if waiting for a S3 bucket to exist, it would look like the following:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Request bucket creation
client.create_bucket()
    .bucket_name(&quot;my-bucket&quot;)
    .send()
    .await()?;

// Wait for it to be created
client.wait_until_bucket_exists()
    .bucket_name(&quot;my-bucket&quot;)
    .send()
    .await?;
<span class="boring">}
</span></code></pre></pre>
<p>The call to <code>wait_until_bucket_exists()</code> will return a waiter-specific fluent builder with a <code>send()</code> function
that will start the polling and return a future.</p>
<p>To avoid name conflicts with other API methods, the waiter functions can be added to the client via trait:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub trait WaitUntilBucketExists {
    fn wait_until_bucket_exists(&amp;self) -&gt; crate::waiter::bucket_exists::Builder;
}
<span class="boring">}
</span></code></pre></pre>
<p>This trait would be implemented for the service's fluent client (which will necessitate making the fluent client's
<code>handle</code> field <code>pub(crate)</code>).</p>
<h2 id="waiter-implementation"><a class="header" href="#waiter-implementation">Waiter Implementation</a></h2>
<p>A waiter trait implementation will merely return a fluent builder:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl WaitUntilBucketExists for Client {
    fn wait_until_bucket_exists(&amp;self) -&gt; crate::waiter::bucket_exists::Builder {
        crate::waiter::bucket_exists::Builder::new()
    }
}
<span class="boring">}
</span></code></pre></pre>
<p>This builder will have a short <code>send()</code> function to kick off the actual waiter implementation:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl Builder {
    // ... existing fluent builder codegen can be reused to create all the setters and constructor

    pub async fn send(self) -&gt; Result&lt;HeadBucketOutput, SdkError&lt;HeadBucketError&gt;&gt; {
        // Builds an input from this builder
        let input = self.inner.build().map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
        // Passes in the client's handle, which contains a Smithy client and client config
        crate::waiter::bucket_exists::wait(self.handle, input).await
    }
}
<span class="boring">}
</span></code></pre></pre>
<p>This wait function needs to, in a loop similar to the pseudo-code in the beginning,
convert the given input into an operation, replace the default response classifier on it
with a no-retry classifier, and then determine what to do next based on that classification:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub async fn wait(
    handle: Arc&lt;Handle&lt;DynConnector, DynMiddleware&lt;DynConnector&gt;, retry::Standard&gt;&gt;,
    input: HeadBucketInput,
) -&gt; Result&lt;HeadBucketOutput, SdkError&lt;HeadBucketError&gt;&gt; {
    loop {
        let operation = input
            .make_operation(&amp;handle.conf)
            .await
            .map_err(|err| {
                aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
            })?;
        // The `ClassifyResponse` trait is implemented for `()` as never retry,
        // so this disables the default retry for the operation
        let operation = operation.with_retry_policy(());

        let result = handle.client.call(operation).await;
        match classify_result(&amp;input, result) {
            AcceptorState::Retry =&gt; {
                // The sleep implementation is available here from `handle.conf.sleep_impl`
                unimplemented!(&quot;Check if another attempt should be made and calculate delay time if so&quot;)
            }
            AcceptorState::Terminate(output) =&gt; return output,
        }
    }
}

fn classify_result(
    input: &amp;HeadBucketInput,
    result: Result&lt;HeadBucketOutput, SdkError&lt;HeadBucketError&gt;&gt;,
) -&gt; AcceptorState&lt;HeadBucketOutput, SdkError&lt;HeadBucketError&gt;&gt; {
    unimplemented!(
        &quot;The Smithy model would dictate conditions to check here to produce an `AcceptorState`&quot;
    )
}
<span class="boring">}
</span></code></pre></pre>
<p>The retry delay time should be calculated by the same exponential backoff with jitter code that the
<a href="https://github.com/awslabs/smithy-rs/blob/main/rust-runtime/aws-smithy-client/src/retry.rs#L252-L292">default <code>RetryHandler</code> uses in <code>aws-smithy-client</code></a>. This function will need to be split up and made
available to the waiter implementations so that just the delay can be calculated.</p>
<h2 id="changes-checklist-8"><a class="header" href="#changes-checklist-8">Changes Checklist</a></h2>
<ul>
<li><input disabled="" type="checkbox"/>
Codegen fluent builders for waiter input and their <code>send()</code> functions</li>
<li><input disabled="" type="checkbox"/>
Codegen waiter invocation traits</li>
<li><input disabled="" type="checkbox"/>
Commonize exponential backoff with jitter delay calculation</li>
<li><input disabled="" type="checkbox"/>
Codegen <code>wait()</code> functions with delay and max attempts configuration from Smithy model</li>
<li><input disabled="" type="checkbox"/>
Codegen <code>classify_result()</code> functions based on JMESPath expressions in Smithy model</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-publishing-the-alpha-sdk-to-cratesio"><a class="header" href="#rfc-publishing-the-alpha-sdk-to-cratesio">RFC: Publishing the Alpha SDK to Crates.io</a></h1>
<blockquote>
<p>Status: Implemented</p>
</blockquote>
<p>The AWS SDK for Rust and its supporting Smithy crates need to be published to <a href="https://crates.io/">crates.io</a>
so that customers can include them in their projects and also publish crates of their own that depend on them.</p>
<p>This doc proposes a short-term solution for publishing to crates.io. This approach is intended to be executed
manually by a developer using scripts and an SOP no more than once per week, and should require less than a
dev week to implement.</p>
<h2 id="terminology-6"><a class="header" href="#terminology-6">Terminology</a></h2>
<ul>
<li><strong>AWS SDK Crate</strong>: A crate that provides a client for calling a given AWS service, such as <code>aws-sdk-s3</code> for calling S3.</li>
<li><strong>AWS Runtime Crate</strong>: Any runtime crate that the AWS SDK generated code relies on, such as <code>aws-types</code>.</li>
<li><strong>Smithy Runtime Crate</strong>: Any runtime crate that the smithy-rs generated code relies on, such as <code>smithy-types</code>.</li>
</ul>
<h2 id="requirements-5"><a class="header" href="#requirements-5">Requirements</a></h2>
<h3 id="versioning"><a class="header" href="#versioning">Versioning</a></h3>
<p>Cargo uses <a href="https://github.com/dtolnay/semver#requirements">semver</a> for versioning,
with a <code>major.minor.patch-pre</code> format:</p>
<ul>
<li><code>major</code>: Incompatible API changes</li>
<li><code>minor</code>: Added functionality in backwards compatible manner</li>
<li><code>patch</code>: Backwards compatible bug fixes</li>
<li><code>pre</code>: Pre-release version tag (omitted for normal releases)</li>
</ul>
<p>For now, AWS SDK crates (including <code>aws-config</code>) will maintain a consistent <code>major</code> and <code>minor</code> version number
across all services. The latest version of <code>aws-sdk-s3</code> will always have the same <code>major.minor</code> version as the
latest <code>aws-sdk-dynamodb</code>, for example. The <code>patch</code> version is allowed to be different between service crates,
but it is unlikely that we will make use of <code>patch</code> versions throughout alpha and dev preview.
Smithy runtime crates will have different version numbers from the AWS SDK crates, but will also maintain
a consistent <code>major.minor</code>.</p>
<p>The <code>pre</code> version tag will be <code>alpha</code> during the Rust SDK alpha, and will be removed once the SDK is in
dev preview.</p>
<p>During alpha, the <code>major</code> version will always be 0, and the <code>minor</code> will be bumped for all published
crates for every release. A later RFC may change the process during dev preview.</p>
<h3 id="yanking"><a class="header" href="#yanking">Yanking</a></h3>
<p>Mistakes will inevitably be made, and a mechanism is needed to yank packages while keeping the latest version
of the SDK successfully consumable from crates.io. To keep this simple, the entire published batch of crates
will be yanked if any crate in that batch needs to be yanked. For example, if 260 crates were published in a batch,
and it turns out there's a problem that requires yanking one of them, then all 260 will be yanked. Attempting to do
partial yanking will require a lot of effort and be difficult to get right. Yanking should be a last resort.</p>
<h2 id="concrete-scenarios"><a class="header" href="#concrete-scenarios">Concrete Scenarios</a></h2>
<p>The following changes will be bundled together as a <code>minor</code> version bump during weekly releases:</p>
<ul>
<li>AWS model updates</li>
<li>New features</li>
<li>Bug fixes in runtime crates or codegen</li>
</ul>
<p>In exceptional circumstances, a <code>patch</code> version will be issued if the fix doesn't require API breaking changes:</p>
<ul>
<li>CVE discovered in a runtime crate</li>
<li>Buggy update to a runtime crate</li>
</ul>
<p>In the event of a CVE being discovered in an external dependency, if the external dependency is
internal to a crate, then a <code>patch</code> revision can be issued for that crate to correct it. Otherwise if the CVE
is in a dependency that is part of the public API, a <code>minor</code> revision will be issued with an expedited release.</p>
<p>For a CVE in generated code, a <code>minor</code> revision will be issued with an expedited release.</p>
<h2 id="proposal"><a class="header" href="#proposal">Proposal</a></h2>
<p>The short-term approach builds off our pre-crates.io weekly release process. That process was the following:</p>
<ol>
<li>Run script to update AWS models</li>
<li>Manually update AWS SDK version in <code>aws/sdk/gradle.properties</code> in smithy-rs</li>
<li>Tag smithy-rs</li>
<li>Wait for GitHub actions to generate AWS SDK using newly released smithy-rs</li>
<li>Check out aws-sdk-rust, delete existing SDK code, unzip generated SDK in place, and update readme</li>
<li>Tag aws-sdk-rust</li>
</ol>
<p>To keep things simple:</p>
<ul>
<li>The Smithy runtime crates will have the same smithy-rs version</li>
<li>All AWS crates will have the same AWS SDK version</li>
<li><code>patch</code> revisions are exceptional and will be one-off manually published by a developer</li>
</ul>
<p>All runtime crate version numbers in smithy-rs will be locked at <code>0.0.0-smithy-rs-head</code>. This is a fake
version number that gets replaced when generating the SDK.</p>
<p>The SDK generator script in smithy-rs will be updated to:</p>
<ul>
<li>Replace Smithy runtime crate versions with the smithy-rs version from <code>aws/sdk/gradle.properties</code></li>
<li>Replace AWS runtime crate versions with AWS SDK version from <code>aws/sdk/gradle.properties</code></li>
<li>Add correct version numbers to all path dependencies in all the final crates that end up in the build artifacts</li>
</ul>
<p>This will result in all the crates having the correct version and manifests when imported into aws-sdk-rust.
From there, a script needs to be written to determine crate dependency order, and publish crates (preferably
with throttling and retry) in the correct order. This script needs to be able to recover from an interruption
part way through publishing all the crates, and it also needs to output a list of all crate versions published
together. This crate list will be commented on the release issue so that yanking the batch can be done if
necessary.</p>
<p>The new release process would be:</p>
<ol>
<li>Run script to update AWS models</li>
<li>Manually update <em>both</em> the AWS SDK version <em>and</em> the smithy-rs version in <code>aws/sdk/gradle.properties</code> in smithy-rs</li>
<li>Tag smithy-rs</li>
<li>Wait for automation to sync changes to <code>aws-sdk-rust/next</code></li>
<li>Cut a PR to merge <code>aws-sdk-rust/next</code> into <code>aws-sdk-rust/main</code></li>
<li>Tag aws-sdk-rust</li>
<li>Run publish script</li>
</ol>
<h3 id="short-term-changes-checklist"><a class="header" href="#short-term-changes-checklist">Short-term Changes Checklist</a></h3>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Prepare runtime crate manifests for publication to crates.io (https://github.com/awslabs/smithy-rs/pull/755)</li>
<li><input disabled="" type="checkbox" checked=""/>
Update SDK generator to set correct crate versions (https://github.com/awslabs/smithy-rs/pull/755)</li>
<li><input disabled="" type="checkbox" checked=""/>
Write bulk publish script</li>
<li><input disabled="" type="checkbox" checked=""/>
Write bulk yank script</li>
<li><input disabled="" type="checkbox" checked=""/>
Write automation to sync smithy-rs to aws-sdk-rust</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-independent-crate-versioning"><a class="header" href="#rfc-independent-crate-versioning">RFC: Independent Crate Versioning</a></h1>
<blockquote>
<p>Status: RFC</p>
</blockquote>
<p>During its alpha and dev preview releases, the AWS SDK for Rust adopted <a href="rfcs/./rfc0011_crates_io_alpha_publishing.html">a short-term solution
for versioning and publishing to crates.io</a>.
This doc proposes a long-term versioning strategy that will carry the SDK from dev preview
into general availability.</p>
<p>This strategy will be implemented in two phases:</p>
<ol>
<li><strong>Dev Preview</strong>: The SDK will break with its current version strategy
of maintaining consistent <code>major.minor</code> version numbers.</li>
<li><strong>Stability and 1.x</strong>: This phase begins when the SDK becomes generally available. The
major version will be bumped to 1, and backwards breaking changes will no longer be allowed
without a major version bump to all crates in the SDK.</li>
</ol>
<h2 id="terminology-7"><a class="header" href="#terminology-7">Terminology</a></h2>
<ul>
<li><strong>AWS SDK Crate</strong>: A crate that provides a client for calling a given AWS service, such as <code>aws-sdk-s3</code> for calling S3.</li>
<li><strong>AWS Runtime Crate</strong>: Any runtime crate that the AWS SDK generated code relies on, such as <code>aws-types</code>.</li>
<li><strong>Smithy Runtime Crate</strong>: Any runtime crate that the <a href="https://github.com/awslabs/smithy-rs">smithy-rs</a> generated code relies on, such as <code>smithy-types</code>.</li>
</ul>
<h2 id="requirements-6"><a class="header" href="#requirements-6">Requirements</a></h2>
<h3 id="versioning-1"><a class="header" href="#versioning-1">Versioning</a></h3>
<p>Cargo uses <a href="https://semver.org/">semver</a> for versioning, with a <code>major.minor.patch-pre</code> format:</p>
<ul>
<li><code>major</code>: Incompatible API changes</li>
<li><code>minor</code>: Added functionality in backwards compatible manner</li>
<li><code>patch</code>: Backwards compatible bug fixes</li>
<li><code>pre</code>: Pre-release version tag (omitted for normal releases)</li>
</ul>
<p>In the new versioning strategy, the <code>minor</code> version number will no longer be coordinated across
all SDK and Smithy runtime crates.</p>
<p>During phases 1 and 2, the <code>major</code> version will always be 0, and the following scheme will be used:</p>
<ul>
<li><code>minor</code>:
<ul>
<li>New features</li>
<li>Breaking changes</li>
<li>Dependency updates for dependencies that are part of the public API</li>
<li>Model updates with API changes</li>
<li>For code-generated crates: when a newer version of <a href="https://github.com/awslabs/smithy-rs">smithy-rs</a> is used to generate the crate</li>
</ul>
</li>
<li><code>patch</code>:
<ul>
<li>Bug fixes that do not break backwards compatibility</li>
<li>Model updates that <em>only</em> have documentation changes</li>
</ul>
</li>
</ul>
<p>During phase 3:</p>
<ul>
<li><code>major</code>: Breaking changes</li>
<li><code>minor</code>:
<ul>
<li>Changes that aren't breaking</li>
<li>Dependency updates for dependencies that are part of the public API</li>
<li>Model updates with API changes</li>
<li>For code-generated crates: when a newer version of <a href="https://github.com/awslabs/smithy-rs">smithy-rs</a> is used to generate the crate</li>
</ul>
</li>
<li><code>patch</code>:
<ul>
<li>Bug fixes that do not break backwards compatibility</li>
<li>Model updates that <em>only</em> have documentation changes</li>
</ul>
</li>
</ul>
<p>During phase 3, bumps to the <code>major</code> version must be coordinated across all SDK and runtime crates.</p>
<h3 id="release-identification"><a class="header" href="#release-identification">Release Identification</a></h3>
<p>Since there will no longer be one SDK &quot;version&quot;, release tags will be dates in <code>YYYY-MM-DD</code> format
rather than version numbers. Additionally, the SDK's user agent string will need to include a separate
service version number (this requirement has already been implemented).</p>
<h3 id="yanking-1"><a class="header" href="#yanking-1">Yanking</a></h3>
<p>It must be possible to yank an entire release with a single action. The publisher tool must
be updated to understand which crate versions were released with a given release tag, and be able to
yank all the crates published from that tag.</p>
<h2 id="phase-1-dev-preview"><a class="header" href="#phase-1-dev-preview">Phase 1: Dev Preview</a></h2>
<p>Phase 1 will address the following challenges introduced by uncoordinating the <code>major.minor</code> versions:</p>
<ul>
<li>Tracking of versions associated with a release tag</li>
<li>Creation of version bump process for code generated crates</li>
<li>Enforcement of version bump process in runtime crates</li>
<li>Yanking of versions associated with a release tag</li>
</ul>
<h3 id="version-tracking"><a class="header" href="#version-tracking">Version Tracking</a></h3>
<p>A new manifest file will be introduced in the root of <a href="https://github.com/awslabs/aws-sdk-rust">aws-sdk-rust</a> named <code>versions.toml</code> that describes
all versioning information for any given commit in the repository. In the main branch, the <code>versions.toml</code>
in tagged commits will become the source of truth for which crate versions belong to that release, as well
as additional metadata that's required for maintaining version process in the future.</p>
<p>The special <code>0.0.0-smithy-rs-head</code> version that is used prior to Phase 1 for maintaining the runtime crate
versions will no longer be used (as detailed in <a href="rfcs/rfc0012_independent_crate_versioning.html#versioning-for-runtime-crates">Versioning for Runtime Crates</a>).</p>
<p>This format will look as follows:</p>
<pre><code class="language-toml">smithy_rs_version = &quot;&lt;release-tag|commit-hash&gt;&quot;

[aws-smithy-types]
version = &quot;0.50.1&quot;

[aws-config]
version = &quot;0.40.0&quot;

[aws-sdk-s3]
version = &quot;0.89.0&quot;
model_hash = &quot;&lt;hash&gt;&quot;

# ...
</code></pre>
<p>The auto-sync tool is responsible for maintaining this file. When it generates a new SDK, it will take
the version numbers from runtime crates directly, and it will use the rules from the next section to determine
the version numbers for the generated crates.</p>
<h3 id="versioning-for-code-generated-sdk-service-crates"><a class="header" href="#versioning-for-code-generated-sdk-service-crates">Versioning for Code Generated (SDK Service) Crates</a></h3>
<p>Code generated crates will have their <code>minor</code> version bumped when the version of <a href="https://github.com/awslabs/smithy-rs">smithy-rs</a> used to generate
them changes, or when model updates with API changes are made. Three pieces of information are required to
handle this process: the previously released version number, the <a href="https://github.com/awslabs/smithy-rs">smithy-rs</a> version used to generate the code,
and the level of model updates being applied. For this last one, if there are multiple model updates that
affect only documentation, but then one model update that affects an API, then as a whole they will be
considered as affecting an API and require a <code>minor</code> version bump.</p>
<p>The previously released version number will be retrieved from crates.io using its API. The <a href="https://github.com/awslabs/smithy-rs">smithy-rs</a> version
used during code generation will become a build artifact that is saved to <code>versions.toml</code> in <a href="https://github.com/awslabs/aws-sdk-rust">aws-sdk-rust</a>.
During phase 1, the tooling required to know if a model is a documentation-only change will not be available,
so all model changes will result in a <code>minor</code> version bump during this phase.</p>
<p>Overall, determining a generated crate's version number looks as follows:</p>
<pre class="mermaid">flowchart TD
    start[Generate crate version] --&gt; smithyrschanged{A. smithy-rs changed?}
    smithyrschanged -- Yes --&gt; minor1[Minor version bump]
    smithyrschanged -- No --&gt; modelchanged{B. model changed?}
    modelchanged -- Yes --&gt; minor2[Minor version bump]
    modelchanged -- No --&gt; keep[Keep current version]
</pre>
<ul>
<li><strong>A: smithy-rs changed?</strong>: Compare the <code>smithy_rs_version</code> in the previous <code>versions.toml</code> with the
next <code>versions.toml</code> file, and if the values are different, consider <a href="https://github.com/awslabs/smithy-rs">smithy-rs</a> to have changed.</li>
<li><strong>B: model changed?</strong>: Similarly, compare the <code>model_hash</code> for the crate in <code>versions.toml</code>.</li>
</ul>
<h3 id="versioning-for-runtime-crates"><a class="header" href="#versioning-for-runtime-crates">Versioning for Runtime Crates</a></h3>
<p>The old scheme of all runtime crates in <a href="https://github.com/awslabs/smithy-rs">smithy-rs</a> having a fake <code>0.0.0-smithy-rs-head</code> version number with
a build step to replace those with a consistent <code>major.minor</code> will be removed. These runtime crates will begin
having their actual next version number in the Cargo.toml file in smithy-rs.</p>
<p>This introduces a new problem where a developer can forget to bump a runtime crate version, so a method of
process enforcement needs to be introduced. This will be done through CI when merging into <code>smithy-rs/main</code>
and repeated when merging into <code>aws-sdk-rust/main</code>.</p>
<p>The following checks need to be run for runtime crates:</p>
<pre class="mermaid">flowchart TD
    A[Check runtime crate] --&gt; B{A. Crate has changed?}
    B -- Yes --&gt; C{B. Minor bumped?}
    B -- No --&gt; H{C. Version changed?}
    C -- Yes --&gt; K[Pass]
    C -- No --&gt; E{D. Patch bumped?}
    E -- Yes --&gt; F{E. Semverver passes?}
    E -- No --&gt; L[Fail]
    F -- Yes --&gt; D[Pass]
    F -- No --&gt; G[Fail]
    H -- Yes --&gt; I[Fail]
    H -- No --&gt; J[Pass]
</pre>
<ul>
<li><strong>A: Crate has changed?</strong> The crate's source files and manifest will be hashed for the previous version
and the next version. If these hashes match, then the crate is considered unchanged.</li>
<li><strong>B: Minor bumped?</strong> The previous version is compared against the next version to see if the minor version
number was bumped.</li>
<li><strong>C: Version changed?</strong> The previous version is compared against the next version to see if it changed.</li>
<li><strong>D: Patch bumped?</strong> The previous version is compared against the next version to see if the patch version
number was bumped.</li>
<li><strong>E: Semverver passes?</strong> Runs <a href="https://github.com/rust-lang/rust-semverver">rust-semverver</a> against the old and new versions of the crate.
<ul>
<li>If semverver fails to run (for example, if it needs to be updated to the latest nightly to succeed),
then fail CI saying that either semverver needs maintenance, or that a minor version bump is required.</li>
<li>If semverver results in errors, fail CI indicating a minor version bump is required.</li>
<li>If semverver passes, then pass CI.</li>
</ul>
</li>
</ul>
<p>When running semverver, the path dependencies of the crate under examination should be updated to be crates.io
references if there were no changes in those crates since the last public to crates.io. Otherwise, the types
referenced from those crates in the public API will always result in breaking changes since, as far as the Rust
compiler is concerned, they are different types originating from separate path-dependency crates.</p>
<p>For CI, the <code>aws-sdk-rust/main</code> branch's <code>versions.toml</code> file is the source of truth for the previous release's
crate versions and source code.</p>
<h3 id="yanking-2"><a class="header" href="#yanking-2">Yanking</a></h3>
<p>The publisher tool will be updated to read the <code>versions.toml</code> to yank all versions published in a release.
This process will look as follows:</p>
<ol>
<li>Take a path to a local clone of the <a href="https://github.com/awslabs/aws-sdk-rust">aws-sdk-rust</a> repository</li>
<li>Confirm the working tree is currently unmodified and on a release tag.</li>
<li>Read <code>versions.toml</code> and print out summary of crates to yank</li>
<li>Confirm with user before proceeding</li>
<li>Yank crates</li>
</ol>
<h3 id="changes-checklist-9"><a class="header" href="#changes-checklist-9">Changes Checklist</a></h3>
<ul>
<li><input disabled="" type="checkbox"/>
Update <code>rust-semverver</code> to a newer nightly that can compile <code>aws-smithy-client</code></li>
<li><input disabled="" type="checkbox"/>
Establish initial <code>versions.toml</code> in <code>aws-sdk-rust/main</code></li>
<li><input disabled="" type="checkbox"/>
Set version numbers in runtime crates in <a href="https://github.com/awslabs/smithy-rs">smithy-rs</a></li>
<li><input disabled="" type="checkbox"/>
Update the auto-sync tool to generate <code>versions.toml</code></li>
<li><input disabled="" type="checkbox"/>
Create CI tool to check runtime crate version
<ul>
<li><input disabled="" type="checkbox"/>
Integrate with <code>smithy-rs/main</code> CI</li>
<li><input disabled="" type="checkbox"/>
Integrate with <code>aws-sdk-rust/main</code> CI</li>
</ul>
</li>
<li><input disabled="" type="checkbox"/>
Update CI to verify no older runtime crates are used. For example, if <code>aws-smithy-client</code> is bumped to
<code>0.50.0</code>, then verify no crates (generated or runtime) depend on <code>0.49.0</code> or lower.</li>
</ul>
<p><strong>Estimate:</strong> 2-4 dev weeks</p>
<h2 id="phase-2-stability-and-1x"><a class="header" href="#phase-2-stability-and-1x">Phase 2: Stability and 1.x</a></h2>
<p>When stabilizing to 1.x, the version process will stay the same, but the minor version bumps caused by version
bumping runtime crates, updating models, or changing the code generator will be candidate for automatic upgrade
per semver. At that point, no further API breaking changes can be made without a major version bump.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-callback-apis-for-bytestream-and-sdkbody"><a class="header" href="#rfc-callback-apis-for-bytestream-and-sdkbody">RFC: Callback APIs for <code>ByteStream</code> and <code>SdkBody</code></a></h1>
<blockquote>
<p>Status: RFC</p>
</blockquote>
<p>Adding a callback API to <code>ByteStream</code> and <code>SdkBody</code> will enable developers using the SDK to implement things like checksum validations and 'read progress' callbacks.</p>
<h2 id="the-implementation"><a class="header" href="#the-implementation">The Implementation</a></h2>
<p><em>Note that comments starting with '//' are not necessarily going to be included in the actual implementation and are intended as clarifying comments for the purposes of this RFC.</em></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// in aws_smithy_http::callbacks...

/// A callback that, when inserted into a request body, will be called for corresponding lifecycle events.
trait BodyCallback: Send {
   /// This lifecycle function is called for each chunk **successfully** read. If an error occurs while reading a chunk,
   /// this method will not be called. This method takes `&amp;mut self` so that implementors may modify an implementing
   /// struct/enum's internal state. Implementors may return an error.
   fn update(&amp;mut self, #[allow(unused_variables)] bytes: &amp;[u8]) -&gt; Result&lt;(), BoxError&gt; { Ok(()) }

   /// This callback is called once all chunks have been read. If the callback encountered one or more errors
   /// while running `update`s, this is how those errors are raised. Implementors may return a [`HeaderMap`][HeaderMap]
   /// that will be appended to the HTTP body as a trailer. This is only useful to do for streaming requests.
   fn trailers(&amp;self) -&gt; Result&lt;Option&lt;HeaderMap&lt;HeaderValue&gt;&gt;, BoxError&gt; { Ok(None) }

   /// Create a new `BodyCallback` from an existing one. This is called when a `BodyCallback` needs to be
   /// re-initialized with default state. For example: when a request has a body that needs to be
   /// rebuilt, all callbacks for that body need to be run again but with a fresh internal state.
   fn make_new(&amp;self) -&gt; Box&lt;dyn BodyCallback&gt;;
}

impl BodyCallback for Box&lt;dyn BodyCallback&gt; {
   fn update(&amp;mut self, bytes: &amp;[u8]) -&gt; Result&lt;(), BoxError&gt; { BodyCallback::update(self, bytes) }
   fn trailers(&amp;self) -&gt; Result&lt;Option&lt;HeaderMap&lt;HeaderValue&gt;&gt;, BoxError&gt; { BodyCallback::trailers(self) }
   fn make_new(&amp;self) -&gt; Box&lt;dyn SendCallback&gt; { BodyCallback::make_new(self) }
}
<span class="boring">}
</span></code></pre></pre>
<p>The changes we need to make to <code>ByteStream</code>:</p>
<p><em>(The current version of <code>ByteStream</code> and <code>Inner</code> can be seen <a href="https://github.com/awslabs/smithy-rs/blob/f76bc159bf16510a0873f5fba691cb05816f4192/rust-runtime/aws-smithy-http/src/byte_stream.rs#L205">here</a>.)</em></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// in `aws_smithy_http::byte_stream`...

// We add a new method to `ByteStream` for inserting callbacks
impl ByteStream {
    // ...other impls omitted

    // A &quot;builder-style&quot; method for setting callbacks
    pub fn with_body_callback(&amp;mut self, body_callback: Box&lt;dyn BodyCallback&gt;) -&gt; &amp;mut Self {
        self.inner.with_body_callback(body_callback);
        self
    }
}

impl Inner&lt;SdkBody&gt; {
    // `Inner` wraps an `SdkBody` which has a &quot;builder-style&quot; function for adding callbacks.
    pub fn with_body_callback(&amp;mut self, body_callback: Box&lt;dyn BodyCallback&gt;) -&gt; &amp;mut Self {
        self.body.with_body_callback(body_callback);
        self
    }
}
<span class="boring">}
</span></code></pre></pre>
<p>The changes we need to make to <code>SdkBody</code>:</p>
<p><em>(The current version of <code>SdkBody</code> can be seen <a href="https://github.com/awslabs/smithy-rs/blob/f76bc159bf16510a0873f5fba691cb05816f4192/rust-runtime/aws-smithy-http/src/body.rs#L71">here</a>.)</em></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// In aws_smithy_http::body...

#[pin_project]
pub struct SdkBody {
    #[pin]
    inner: Inner,
    rebuild: Option&lt;Arc&lt;dyn (Fn() -&gt; Inner) + Send + Sync&gt;&gt;,
    // We add a `Vec` to store the callbacks
    #[pin]
    callbacks: Vec&lt;Box&lt;dyn BodyCallback&gt;&gt;,
}

impl SdkBody {
    // We update the various fns that create `SdkBody`s to create an empty `Vec` to store callbacks.
    // Those updates are very simple so I've omitted them from this code example.

    fn poll_inner(
        self: Pin&lt;&amp;mut Self&gt;,
        cx: &amp;mut Context&lt;'_&gt;,
    ) -&gt; Poll&lt;Option&lt;Result&lt;Bytes, Error&gt;&gt;&gt; {
        let mut this = self.project();
        // This block is old. I've included for context.
        let polling_result = match this.inner.project() {
            InnerProj::Once(ref mut opt) =&gt; {
                let data = opt.take();
                match data {
                    Some(bytes) if bytes.is_empty() =&gt; Poll::Ready(None),
                    Some(bytes) =&gt; Poll::Ready(Some(Ok(bytes))),
                    None =&gt; Poll::Ready(None),
                }
            }
            InnerProj::Streaming(body) =&gt; body.poll_data(cx).map_err(|e| e.into()),
            InnerProj::Dyn(box_body) =&gt; box_body.poll_data(cx),
            InnerProj::Taken =&gt; {
                Poll::Ready(Some(Err(&quot;A `Taken` body should never be polled&quot;.into())))
            }
        };

        // This block is new.
        match &amp;polling_result {
            // When we get some bytes back from polling, pass those bytes to each callback in turn
            Poll::Ready(Some(Ok(bytes))) =&gt; {
               for callback in this.callbacks.iter_mut() {
                  // Callbacks can run into errors when reading bytes. They'll be surfaced here
                  callback.update(bytes)?;
               }
            }
            // When we're done polling for bytes, run each callback's `trailers()` method. If any calls to
            // `trailers()` return an error, propagate that error up. Otherwise, continue.
            Poll::Ready(None) =&gt; {
                for callback_result in this.callbacks.iter().map(BodyCallback::trailers) {
                    if let Err(e) = callback_result {
                        return Poll::Ready(Some(Err(e)));
                    }
                }
            }
            _ =&gt; (),
        }

        // Now that we've inspected the polling result, all that's left to do is to return it.
        polling_result
    }

    // This function now has the added responsibility of cloning callback functions (but with fresh state)
    // in the case that the `SdkBody` needs to be rebuilt.
    pub fn try_clone(&amp;self) -&gt; Option&lt;Self&gt; {
        self.rebuild.as_ref().map(|rebuild| {
            let next = rebuild();
            let callbacks = self
                .callbacks
                .iter()
                .map(Callback::make_new)
                .collect();

            Self {
                inner: next,
                rebuild: self.rebuild.clone(),
                callbacks,
            }
        })
    }

    pub fn with_callback(&amp;mut self, callback: BodyCallback) -&gt; &amp;mut Self {
        self.callbacks.push(callback);
        self
    }
}

/// Given two [`HeaderMap`][HeaderMap]s, merge them together and return the merged `HeaderMap`. If the
/// two `HeaderMap`s share any keys, values from the right `HeaderMap` be appended to the left `HeaderMap`.
///
/// # Example
///
/// ```rust
/// let header_name = HeaderName::from_static(&quot;some_key&quot;);
///
/// let mut left_hand_side_headers = HeaderMap::new();
/// left_hand_side_headers.insert(
///     header_name.clone(),
///     HeaderValue::from_str(&quot;lhs value&quot;).unwrap(),
/// );
///
/// let mut right_hand_side_headers = HeaderMap::new();
/// right_hand_side_headers.insert(
///     header_name.clone(),
///     HeaderValue::from_str(&quot;rhs value&quot;).unwrap(),
/// );
///
/// let merged_header_map =
///     append_merge_header_maps(left_hand_side_headers, right_hand_side_headers);
/// let merged_values: Vec&lt;_&gt; = merged_header_map
///     .get_all(header_name.clone())
///     .into_iter()
///     .collect();
///
/// // Will print 'some_key: [&quot;lhs value&quot;, &quot;rhs value&quot;]'
/// println!(&quot;{}: {:?}&quot;, header_name.as_str(), merged_values);
/// ```
fn append_merge_header_maps(
    mut lhs: HeaderMap&lt;HeaderValue&gt;,
    rhs: HeaderMap&lt;HeaderValue&gt;,
) -&gt; HeaderMap&lt;HeaderValue&gt; {
    let mut last_header_name_seen = None;
    for (header_name, header_value) in rhs.into_iter() {
        // For each yielded item that has None provided for the `HeaderName`,
        // then the associated header name is the same as that of the previously
        // yielded item. The first yielded item will have `HeaderName` set.
        // https://docs.rs/http/latest/http/header/struct.HeaderMap.html#method.into_iter-2
        match (&amp;mut last_header_name_seen, header_name) {
            (_, Some(header_name)) =&gt; {
                lhs.append(header_name.clone(), header_value);
                last_header_name_seen = Some(header_name);
            }
            (Some(header_name), None) =&gt; {
                lhs.append(header_name.clone(), header_value);
            }
            (None, None) =&gt; unreachable!(),
        };
    }

    lhs
}

impl http_body::Body for SdkBody {
    // The other methods have been omitted because they haven't changed

    fn poll_trailers(
        self: Pin&lt;&amp;mut Self&gt;,
        _cx: &amp;mut Context&lt;'_&gt;,
    ) -&gt; Poll&lt;Result&lt;Option&lt;HeaderMap&lt;HeaderValue&gt;&gt;, Self::Error&gt;&gt; {
        let header_map = self
            .callbacks
            .iter()
            .filter_map(|callback| {
                match callback.trailers() {
                    Ok(optional_header_map) =&gt; optional_header_map,
                    // early return if a callback encountered an error
                    Err(e) =&gt; { return e },
                }
            })
            // Merge any `HeaderMap`s from the last step together, one by one.
            .reduce(append_merge_header_maps);

        Poll::Ready(Ok(header_map))
    }
}
<span class="boring">}
</span></code></pre></pre>
<h2 id="implementing-checksums"><a class="header" href="#implementing-checksums">Implementing Checksums</a></h2>
<p>What follows is a simplified example of how this API could be used to introduce checksum validation for outgoing request payloads. In this example, the checksum calculation is fallible and no validation takes place. All it does it calculate
the checksum of some data and then returns the checksum of that data when <code>trailers</code> is called. This is fine because it's
being used to calculate the checksum of a streaming body for a request.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[derive(Default)]
struct Crc32cChecksumCallback {
    state: Option&lt;u32&gt;,
}

impl ReadCallback for Crc32cChecksumCallback {
    fn update(&amp;mut self, bytes: &amp;[u8]) -&gt; Result&lt;(), BoxError&gt; {
        self.state = match self.state {
            Some(crc) =&gt; { self.state = Some(crc32c_append(crc, bytes)) }
            None =&gt; { Some(crc32c(&amp;bytes)) }
        };

       Ok(())
    }

    fn trailers(&amp;self) -&gt;
    Result&lt;Option&lt;HeaderMap&lt;HeaderValue&gt;&gt;,
          Box&lt;dyn std::error::Error + Send + Sync&gt;&gt;
    {
        let mut header_map = HeaderMap::new();
        // This checksum name is an Amazon standard and would be a `const` in the real implementation
        let key = HeaderName::from_static(&quot;x-amz-checksum-crc32c&quot;);
        // If no data was provided to this callback and no CRC was ever calculated, we return zero as the checksum.
        let crc = self.state.unwrap_or_default();
        // Convert the CRC to a string, base 64 encode it, and then convert it into a `HeaderValue`.
        let value = HeaderValue::from_str(&amp;base64::encode(crc.to_string())).expect(&quot;base64 will always produce valid header values&quot;);

        header_map.insert(key, value);

        Some(header_map)
    }

    fn make_new(&amp;self) -&gt; Box&lt;dyn ReadCallback&gt; {
        Box::new(Crc32cChecksumCallback::default())
    }
}
<span class="boring">}
</span></code></pre></pre>
<p><em>NOTE: If <code>Crc32cChecksumCallback</code> needed to validate a response, then we could modify it to check its internal state against a target checksum value and calling <code>trailers</code> would produce an error if the values didn't match.</em></p>
<p>In order to use this in a request, we'd modify codegen for that request's service.</p>
<ol>
<li>We'd check if the user had requested validation and also check if they'd pre-calculated a checksum.</li>
<li>If validation was requested but no pre-calculated checksum was given, we'd create a callback similar to the one above</li>
<li>Then, we'd create a new checksum callback and:
<ul>
<li>(if streaming) we'd set the checksum callback on the request body object</li>
<li>(if non-streaming) we'd immediately read the body and call <code>BodyCallback::update</code> manually. Once all data was read, we'd get the checksum by calling <code>trailers</code> and insert that data as a request header.</li>
</ul>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-fine-grained-timeout-configuration"><a class="header" href="#rfc-fine-grained-timeout-configuration">RFC: Fine-grained timeout configuration</a></h1>
<blockquote>
<p>Status: Implemented</p>
</blockquote>
<p>For a summarized list of proposed changes, see the <a href="rfcs/rfc0014_timeout_config.html#changes-checklist">Changes Checklist</a> section.</p>
<p>While it is currently possible for users to implement request timeouts by racing operation send futures against timeout futures, this RFC proposes a more ergonomic solution that would also enable users to set timeouts for things like TLS negotiation and &quot;time to first byte&quot;.</p>
<h2 id="terminology-8"><a class="header" href="#terminology-8">Terminology</a></h2>
<p>There's a lot of terminology to define, so I've broken it up into three sections.</p>
<h3 id="general-terms"><a class="header" href="#general-terms">General terms</a></h3>
<ul>
<li><strong>Smithy Client</strong>: A <code>aws_smithy_client::Client&lt;C, M, R&gt;</code> struct that is responsible for gluing together the connector, middleware, and retry policy. This is not generated and lives in the <code>aws-smithy-client</code> crate.</li>
<li><strong>Fluent Client</strong>: A code-generated <code>Client&lt;C, M, R&gt;</code> that has methods for each service operation on it. A fluent builder is generated alongside it to make construction easier.</li>
<li><strong>AWS Client</strong>: A specialized Fluent Client that defaults to using a <code>DynConnector</code>, <code>AwsMiddleware</code>, and <code>Standard</code> retry policy.</li>
<li><strong>Shared Config</strong>: An <code>aws_types::Config</code> struct that is responsible for storing shared configuration data that is used across all services. This is not generated and lives in the <code>aws-types</code> crate.</li>
<li><strong>Service-specific Config</strong>: A code-generated <code>Config</code> that has methods for setting service-specific configuration. Each <code>Config</code> is defined in the <code>config</code> module of its parent service. For example, the S3-specific config struct  is <code>use</code>able from <code>aws_sdk_s3::config::Config</code> and re-exported as <code>aws_sdk_s3::Config</code>. In this case, &quot;service&quot; refers to an AWS offering like S3.</li>
</ul>
<h3 id="http-stack-terms"><a class="header" href="#http-stack-terms">HTTP stack terms</a></h3>
<ul>
<li><strong>Service</strong>: A trait defined in the <a href="https://docs.rs/tower-service/0.3.1/tower_service/trait.Service.html"><code>tower-service</code> crate</a>. The lowest level of abstraction we deal with when making HTTP requests. Services act directly on data to transform and modify that data. A Service is what eventually turns a request into a response.</li>
<li><strong>Layer</strong>: Layers are a higher-order abstraction over services that is used to compose multiple services together, creating a new service from that combination. Nothing prevents us from manually wrapping services within services, but Layers allow us to do it in a flexible and generic manner. Layers don't directly act on data but instead can wrap an existing service with additional functionality, creating a new service. Layers can be thought of as middleware. <em>NOTE: The use of <a href="https://github.com/awslabs/smithy-rs/issues/634">Layers can produce compiler errors</a> that are difficult to interpret and defining a layer requires a large amount of boilerplate code.</em></li>
<li><strong>Middleware</strong>: a term with several meanings,
<ul>
<li>Generically speaking, middleware are similar to Services and Layers in that they modify requests and responses.</li>
<li>In the SDK, &quot;Middleware&quot; refers to a layer that can be wrapped around a <code>DispatchService</code>. In practice, this means that the resulting <code>Service</code> (and the inner service) must meet the bound <code>T: where T: Service&lt;operation::Request, Response=operation::Response, Error=SendOperationError&gt;</code>.
<ul>
<li><em>Note: This doesn't apply to the middlewares we use when generating presigned request because those don't wrap a <code>DispatchService</code>.</em></li>
</ul>
</li>
<li>The most notable example of a Middleware is the <a href="https://github.com/awslabs/smithy-rs/blob/1aa59693eed10713dec0f3774a8a25ca271dbf39/aws/rust-runtime/aws-hyper/src/lib.rs#L29">AwsMiddleware</a>. Other notable examples include <a href="https://github.com/awslabs/smithy-rs/blob/841f51113fb14e2922793951ce16bda3e16cb51f/rust-runtime/aws-smithy-http-tower/src/map_request.rs#L122">MapRequest</a>, <a href="https://github.com/awslabs/smithy-rs/blob/841f51113fb14e2922793951ce16bda3e16cb51f/rust-runtime/aws-smithy-http-tower/src/map_request.rs#L42">AsyncMapRequest</a>, and <a href="https://github.com/awslabs/smithy-rs/blob/841f51113fb14e2922793951ce16bda3e16cb51f/rust-runtime/aws-smithy-http-tower/src/parse_response.rs#L27">ParseResponse</a>.</li>
</ul>
</li>
<li><strong>DispatchService</strong>: The innermost part of a group of nested services. The Service that actually makes an HTTP call on behalf of a request. Responsible for parsing success and error responses.</li>
<li><strong>Connector</strong>: a term with several meanings,
<ul>
<li>DynConnectors (a struct that implements <a href="https://github.com/awslabs/smithy-rs/blob/1aa59693eed10713dec0f3774a8a25ca271dbf39/rust-runtime/aws-smithy-client/src/erase.rs#L139">DynConnect</a>) are Services with their specific type erased so that we can do dynamic dispatch.</li>
<li>A term from <code>hyper</code> for any object that implements the <a href="https://docs.rs/hyper/0.14.14/hyper/client/connect/trait.Connect.html">Connect</a> trait. Really just an alias for <a href="https://docs.rs/tower-service/0.3.1/tower_service/trait.Service.html">tower_service::Service</a>. Sometimes referred to as a <code>Connection</code>.</li>
</ul>
</li>
<li><strong>Stage</strong>: A form of middleware that's not related to <code>tower</code>. These currently function as a way of transforming requests and don't have the ability to transform responses.</li>
<li><strong>Stack</strong>: higher order abstraction over Layers defined in the <a href="https://docs.rs/tower/0.4.10/tower/layer/util/struct.Stack.html">tower crate</a> e.g. Layers wrap services in one another and Stacks wrap layers within one another.</li>
</ul>
<h3 id="timeout-terms"><a class="header" href="#timeout-terms">Timeout terms</a></h3>
<ul>
<li><strong>Connect Timeout</strong>: A limit on the amount of time after making an initial connect attempt on a socket to complete the
connect-handshake.
<ul>
<li><em>TODO: the runtime is based on Hyper which reuses connection and doesn't currently have a way of guaranteeing that
a fresh connection will be use for a given request.</em></li>
</ul>
</li>
<li><strong>TLS Negotiation Timeout</strong>: A limit on the amount of time a TLS handshake takes from when the CLIENT HELLO message is
sent to the time the client and server have fully negotiated ciphers and exchanged keys.</li>
<li><strong>Time to First Byte Timeout</strong>: <em>Sometimes referred to as a &quot;read timeout.&quot;</em> A limit on the amount of time an application takes to attempt to read the first byte over
an established, open connection after write request.</li>
<li><strong>HTTP Request Timeout For A Single Attempt</strong>: A limit on the amount of time it takes for the first byte to be sent over
an established, open connection and when the last byte is received from the service.</li>
<li><strong>HTTP Request Timeout For Multiple Attempts</strong>: This timeout acts like the previous timeout but constrains the total time
it takes to make a request plus any retries.
<ul>
<li><em>NOTE: In a way, this is already possible in that users are free to race requests against timer futures with
the <a href="https://docs.rs/futures/0.3.17/futures/future/fn.select.html">futures::future::select</a> macro or to use <a href="https://docs.rs/tokio/1.12.0/tokio/time/fn.timeout.html">tokio::time::timeout</a>. See relevant discussion in <a href="https://github.com/hyperium/hyper/issues/1097">hyper#1097</a></em></li>
</ul>
</li>
</ul>
<h2 id="configuring-timeouts"><a class="header" href="#configuring-timeouts">Configuring timeouts</a></h2>
<p>Just like with <a href="rfcs/./rfc0004_retry_behavior.html">Retry Behavior Configuration</a>, these settings can be configured in several places and have the same
precedence rules <em>(paraphrased here for clarity)</em>.</p>
<ol>
<li>Service-specific config builders</li>
<li>Shared config builders</li>
<li>Environment variables</li>
<li>Profile config file (e.g., <code>~/.aws/credentials</code>)</li>
</ol>
<p>The above list is in order of decreasing precedence e.g. configuration set in an app will override values from
environment variables.</p>
<h3 id="configuration-options"><a class="header" href="#configuration-options">Configuration options</a></h3>
<p>The table below details the specific ways each timeout can be configured. In all cases, valid values are non-negative floats representing the number of seconds before a timeout is triggered.</p>
<div class="table-wrapper"><table><thead><tr><th>Timeout</th><th>Environment Variable</th><th>AWS Config Variable</th><th>Builder Method</th></tr></thead><tbody>
<tr><td>Connect</td><td>AWS_CONNECT_TIMEOUT</td><td>connect_timeout</td><td>connect_timeout</td></tr>
<tr><td>TLS Negotiation</td><td>AWS_TLS_NEGOTIATION_TIMEOUT</td><td>tls_negotiation_timeout</td><td>tls_negotiation_timeout</td></tr>
<tr><td>Time To First Byte</td><td>AWS_READ_TIMEOUT</td><td>read_timeout</td><td>read_timeout</td></tr>
<tr><td>HTTP Request - single attempt</td><td>AWS_API_CALL_ATTEMPT_TIMEOUT</td><td>api_call_attempt_timeout</td><td>api_call_attempt_timeout</td></tr>
<tr><td>HTTP Request - all attempts</td><td>AWS_API_CALL_TIMEOUT</td><td>api_call_timeout</td><td>api_call_timeout</td></tr>
</tbody></table>
</div>
<h3 id="sdk-specific-defaults-set-by-aws-service-teams"><a class="header" href="#sdk-specific-defaults-set-by-aws-service-teams">SDK-specific defaults set by AWS service teams</a></h3>
<p><em>QUESTION: How does the SDK currently handle these defaults?</em></p>
<h2 id="prior-art"><a class="header" href="#prior-art">Prior Art</a></h2>
<ul>
<li><a href="https://github.com/hjr3/hyper-timeout">hjr3/hyper-timeout</a> is a <code>Connector</code> for hyper that enables setting connect, read, and write timeouts</li>
<li><a href="https://github.com/sfackler/tokio-io-timeout">sfackler/tokio-io-timeout</a> provides timeouts for tokio IO operations. Used within <code>hyper-timeout</code>.</li>
<li>[tokio::time::sleep_until] creates a <code>Future</code> that completes after some time has elapsed. Used within <code>tokio-io-timeout</code>.</li>
</ul>
<h2 id="behind-the-scenes-2"><a class="header" href="#behind-the-scenes-2">Behind the scenes</a></h2>
<p>Timeouts are achieved by racing a future against a <code>tokio::time::Sleep</code> future. The question, then, is &quot;how can I create a future that represents a condition I want to watch for?&quot;. For example, in the case of a <code>ConnectTimeout</code>, how do we watch an ongoing request to see if it's completed the connect-handshake? Our current stack of Middleware acts on requests at different levels of granularity. The timeout Middlewares will be no different.</p>
<h3 id="middlewares-for-aws-client-requests"><a class="header" href="#middlewares-for-aws-client-requests">Middlewares for AWS Client requests</a></h3>
<p><em>View <a href="https://github.com/awslabs/smithy-rs/blob/1aa59693eed10713dec0f3774a8a25ca271dbf39/aws/rust-runtime/aws-hyper/src/lib.rs#L29">AwsMiddleware</a> in GitHub</em></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[derive(Debug, Default)]
#[non_exhaustive]
pub struct AwsMiddleware;
impl&lt;S&gt; tower::Layer&lt;S&gt; for AwsMiddleware {
  type Service = &lt;AwsMiddlewareStack as tower::Layer&lt;S&gt;&gt;::Service;

  fn layer(&amp;self, inner: S) -&gt; Self::Service {
    let credential_provider = AsyncMapRequestLayer::for_mapper(CredentialsStage::new());
    let signer = MapRequestLayer::for_mapper(SigV4SigningStage::new(SigV4Signer::new()));
    let endpoint_resolver = MapRequestLayer::for_mapper(AwsEndpointStage);
    let user_agent = MapRequestLayer::for_mapper(UserAgentStage::new());
    ServiceBuilder::new()
            .layer(endpoint_resolver)
            .layer(user_agent)
            .layer(credential_provider)
            .layer(signer)
            .service(inner)
  }
}
<span class="boring">}
</span></code></pre></pre>
<p>The above code is only included for context. This RFC doesn't define any timeouts specific to AWS so <code>AwsMiddleware</code> won't require any changes.</p>
<h3 id="middlewares-for-smithy-client-requests"><a class="header" href="#middlewares-for-smithy-client-requests">Middlewares for Smithy Client requests</a></h3>
<p><em>View <a href="https://github.com/awslabs/smithy-rs/blob/841f51113fb14e2922793951ce16bda3e16cb51f/rust-runtime/aws-smithy-client/src/lib.rs#L175">aws_smithy_client::Client::call_raw</a> in GitHub</em></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl&lt;C, M, R&gt; Client&lt;C, M, R&gt;
  where
          C: bounds::SmithyConnector,
          M: bounds::SmithyMiddleware&lt;C&gt;,
          R: retry::NewRequestPolicy,
{
  // ...other methods omitted
  pub async fn call_raw&lt;O, T, E, Retry&gt;(
    &amp;self,
    input: Operation&lt;O, Retry&gt;,
  ) -&gt; Result&lt;SdkSuccess&lt;T&gt;, SdkError&lt;E&gt;&gt;
    where
            R::Policy: bounds::SmithyRetryPolicy&lt;O, T, E, Retry&gt;,
            bounds::Parsed&lt;&lt;M as bounds::SmithyMiddleware&lt;C&gt;&gt;::Service, O, Retry&gt;:
            Service&lt;Operation&lt;O, Retry&gt;, Response=SdkSuccess&lt;T&gt;, Error=SdkError&lt;E&gt;&gt; + Clone,
  {
    let connector = self.connector.clone();

    let mut svc = ServiceBuilder::new()
            // Create a new request-scoped policy
            .retry(self.retry_policy.new_request_policy())
            .layer(ParseResponseLayer::&lt;O, Retry&gt;::new())
            // These layers can be considered as occurring in order. That is, first invoke the
            // customer-provided middleware, then dispatch dispatch over the wire.
            .layer(&amp;self.middleware)
            .layer(DispatchLayer::new())
            .service(connector);

    svc.ready().await?.call(input).await
  }
}
<span class="boring">}
</span></code></pre></pre>
<p>The Smithy Client creates a new <code>Stack</code> of services to handle each request it sends. Specifically:</p>
<ul>
<li>A method <code>retry</code> is used set the retry handler. The configuration for this was set during creation of the <code>Client</code>.</li>
<li><code>ParseResponseLayer</code> inserts a service for transforming responses into operation-specific outputs or errors. The <code>O</code> generic parameter of <code>input</code> is what decides exactly how the transformation is implemented.</li>
<li>A middleware stack that was included during <code>Client</code> creation is inserted into the stack. In the case of the AWS SDK, this would be <code>AwsMiddleware</code>.</li>
<li><code>DispatchLayer</code> inserts a service for transforming an <code>http::Request</code> into an <code>operation::Request</code>. It's also responsible for re-attaching the property bag from the Operation that triggered the request.</li>
<li>The innermost <code>Service</code> is a <code>DynConnector</code> wrapping a <code>hyper</code> client (which one depends on the TLS implementation was enabled by cargo features.)</li>
</ul>
<p>The <strong>HTTP Request Timeout For A Single Attempt</strong> and <strong>HTTP Request Timeout For Multiple Attempts</strong> can be implemented at this level. The same <code>Layer</code> can be used to create both <code>TimeoutService</code>s. The <code>TimeoutLayer</code> would require two inputs:</p>
<ul>
<li><code>sleep_fn</code>: A runtime-specific implementation of <code>sleep</code>. The SDK is currently <code>tokio</code>-based and would default to <code>tokio::time::sleep</code> (this default is set in the <code>aws_smithy_async::rt::sleep</code> module.)</li>
<li>The duration of the timeout as a <code>std::time::Duration</code></li>
</ul>
<p>The resulting code would look like this:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl&lt;C, M, R&gt; Client&lt;C, M, R&gt;
  where
          C: bounds::SmithyConnector,
          M: bounds::SmithyMiddleware&lt;C&gt;,
          R: retry::NewRequestPolicy,
{
  // ...other methods omitted
  pub async fn call_raw&lt;O, T, E, Retry&gt;(
    &amp;self,
    input: Operation&lt;O, Retry&gt;,
  ) -&gt; Result&lt;SdkSuccess&lt;T&gt;, SdkError&lt;E&gt;&gt;
    where
            R::Policy: bounds::SmithyRetryPolicy&lt;O, T, E, Retry&gt;,
            bounds::Parsed&lt;&lt;M as bounds::SmithyMiddleware&lt;C&gt;&gt;::Service, O, Retry&gt;:
            Service&lt;Operation&lt;O, Retry&gt;, Response=SdkSuccess&lt;T&gt;, Error=SdkError&lt;E&gt;&gt; + Clone,
  {
    let connector = self.connector.clone();
    let sleep_fn = aws_smithy_async::rt::sleep::default_async_sleep();

    let mut svc = ServiceBuilder::new()
            .layer(TimeoutLayer::new(
              sleep_fn,
              self.timeout_config.api_call_timeout(),
            ))
            // Create a new request-scoped policy
            .retry(self.retry_policy.new_request_policy())
            .layer(TimeoutLayer::new(
              sleep_fn,
              self.timeout_config.api_call_attempt_timeout(),
            ))
            .layer(ParseResponseLayer::&lt;O, Retry&gt;::new())
            // These layers can be considered as occurring in order. That is, first invoke the
            // customer-provided middleware, then dispatch dispatch over the wire.
            .layer(&amp;self.middleware)
            .layer(DispatchLayer::new())
            .service(connector);

    svc.ready().await?.call(input).await
  }
}
<span class="boring">}
</span></code></pre></pre>
<!-- TODO where should this note live? -->
<p><em>Note: Our HTTP client supports multiple TLS implementations. We'll likely have to implement this feature once per library.</em></p>
<p>Timeouts will be implemented in the following places:</p>
<ul>
<li>HTTP request timeout for multiple requests will be implemented as the outermost Layer in <code>Client::call_raw</code>.</li>
<li>HTTP request timeout for a single request will be implemented within <code>RetryHandler::retry</code>.</li>
<li>Time to first byte, TLS negotiation, and connect timeouts will be implemented within the central <code>hyper</code> connector.</li>
</ul>
<h2 id="changes-checklist-10"><a class="header" href="#changes-checklist-10">Changes checklist</a></h2>
<p>Changes are broken into to sections:</p>
<ul>
<li>HTTP requests (single or multiple) are implementable as layers within our current stack</li>
<li>Other timeouts will require changes to our dependencies and may be slower to implement</li>
</ul>
<h3 id="implementing-http-request-timeouts"><a class="header" href="#implementing-http-request-timeouts">Implementing HTTP request timeouts</a></h3>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Add <code>TimeoutConfig</code> to <code>smithy-types</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Add <code>TimeoutConfigProvider</code> to <code>aws-config</code>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Add provider that fetches config from environment variables</li>
<li><input disabled="" type="checkbox" checked=""/>
Add provider that fetches config from profile</li>
</ul>
</li>
<li><input disabled="" type="checkbox" checked=""/>
Add <code>timeout</code> method to <code>aws_types::Config</code> for setting timeout configuration</li>
<li><input disabled="" type="checkbox" checked=""/>
Add <code>timeout</code> method to generated <code>Config</code>s too</li>
<li><input disabled="" type="checkbox" checked=""/>
Create a generic <code>TimeoutService</code> and accompanying <code>Layer</code>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
<code>TimeoutLayer</code> should accept a <code>sleep</code> function so that it doesn't have a hard dependency on <code>tokio</code></li>
</ul>
</li>
<li><input disabled="" type="checkbox" checked=""/>
insert a <code>TimeoutLayer</code> before the <code>RetryPolicy</code> to handle timeouts for multiple-attempt requests</li>
<li><input disabled="" type="checkbox" checked=""/>
insert a <code>TimeoutLayer</code> after the <code>RetryPolicy</code> to handle timeouts for single-attempt requests</li>
<li><input disabled="" type="checkbox" checked=""/>
Add tests for timeout behavior
<ul>
<li><input disabled="" type="checkbox" checked=""/>
test multi-request timeout triggers after 3 slow retries</li>
<li><input disabled="" type="checkbox" checked=""/>
test single-request timeout triggers correctly</li>
<li><input disabled="" type="checkbox" checked=""/>
test single-request timeout doesn't trigger if request completes in time</li>
</ul>
</li>
</ul>
<!--- Links -->
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-how-cargo-features-should-be-used-in-the-sdk-and-runtime-crates"><a class="header" href="#rfc-how-cargo-features-should-be-used-in-the-sdk-and-runtime-crates">RFC: How Cargo &quot;features&quot; should be used in the SDK and runtime crates</a></h1>
<blockquote>
<p>Status: RFC</p>
</blockquote>
<h2 id="some-background-on-features"><a class="header" href="#some-background-on-features">Some background on features</a></h2>
<p>What is a feature? Here's a definition from the <a href="https://doc.rust-lang.org/cargo/reference/features.html">Cargo Book section on features</a>:</p>
<blockquote>
<p>Cargo &quot;features&quot; provide a mechanism to express conditional compilation and optional dependencies. A package defines a set of named features in the <code>[features]</code> table of <code>Cargo.toml</code>, and each feature can either be enabled or disabled. Features for the package being built can be enabled on the command-line with flags such as <code>--features</code>. Features for dependencies can be enabled in the dependency declaration in <code>Cargo.toml</code>.</p>
</blockquote>
<p>We use features in a majority of our runtime crates and in all of our SDK crates. For example, <a href="https://github.com/awslabs/smithy-rs/blob/5a1990791d727652587df51b77df4d1df9058252/aws/rust-runtime/aws-sigv4/Cargo.toml">aws-sigv4</a> uses them to enable event streams. Another common use case is exhibited by <a href="https://github.com/awslabs/aws-sdk-rust/blob/f2b4361b004ee822960ea9791f566fd4eb6d1aba/sdk/s3/Cargo.toml">aws-sdk-s3</a> which uses them to enable the <code>tokio</code> runtime and the TLS implementation used when making requests.</p>
<h3 id="features-should-be-additive"><a class="header" href="#features-should-be-additive">Features should be additive</a></h3>
<p>The Cargo book has this to say:</p>
<blockquote>
<p>When a dependency is used by multiple packages, Cargo will use the union of all features enabled on that dependency when building it. This helps ensure that only a single copy of the dependency is used.</p>
</blockquote>
<blockquote>
<p>A consequence of this is that features should be <em>additive</em>. That is, enabling a feature should not disable functionality, and it should usually be safe to enable any combination of features. <strong>A feature should not introduce a <a href="https://doc.rust-lang.org/cargo/reference/features.html#semver-compatibility">SemVer-incompatible change</a>.</strong></p>
</blockquote>
<h2 id="what-does-this-mean-for-the-sdk"><a class="header" href="#what-does-this-mean-for-the-sdk">What does this mean for the SDK?</a></h2>
<p>Despite the constraints outlined above, we should use features in the SDKs because of the benefits they bring:</p>
<ul>
<li>Features enable users to avoid compiling code that they won't be using. Additionally, features allow both general and specific control of compiled code, serving the needs of both novice and expert users.</li>
<li>A single feature in a crate can activate or deactivate multiple features exposed by that crate's dependencies, freeing the user from having to specifically activate or deactivate them.</li>
<li>Features can help users understand what a crate is capable of in the same way that looking at a graph of a crate's modules can.</li>
</ul>
<p>When using features, we should adhere to the guidelines outlined below.</p>
<h3 id="avoid-writing-code-that-relies-on-only-activating-one-feature-from-a-set-of-mutually-exclusive-features"><a class="header" href="#avoid-writing-code-that-relies-on-only-activating-one-feature-from-a-set-of-mutually-exclusive-features">Avoid writing code that relies on only activating one feature from a set of mutually exclusive features.</a></h3>
<p>As noted earlier in an excerpt from the Cargo book:</p>
<blockquote>
<p>enabling a feature should not disable functionality, and it should usually be safe to enable any combination of features. A feature should not introduce a <a href="https://doc.rust-lang.org/cargo/reference/features.html#semver-compatibility">SemVer-incompatible change</a>.</p>
</blockquote>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(feature = &quot;rustls&quot;)]
impl&lt;M, R&gt; ClientBuilder&lt;(), M, R&gt; {
    /// Connect to the service over HTTPS using Rustls.
    pub fn tls_adapter(self) -&gt; ClientBuilder&lt;Adapter&lt;crate::conns::Https&gt;, M, R&gt; {
        self.connector(Adapter::builder().build(crate::conns::https()))
    }
}

#[cfg(feature = &quot;native-tls&quot;)]
impl&lt;M, R&gt; ClientBuilder&lt;(), M, R&gt; {
    /// Connect to the service over HTTPS using the native TLS library on your platform.
    pub fn tls_adapter(
        self,
    ) -&gt; ClientBuilder&lt;Adapter&lt;hyper_tls::HttpsConnector&lt;hyper::client::HttpConnector&gt;&gt;, M, R&gt; {
        self.connector(Adapter::builder().build(crate::conns::native_tls()))
    }
}
<span class="boring">}
</span></code></pre></pre>
<p>When the example code above is compiled with both features enabled, compilation will fail with a &quot;duplicate definitions with name <code>tls_adapter</code>&quot; error. Also, note that the return type of the function differs between the two versions. This is a SemVer-incompatible change.</p>
<p>Here's an updated version of the example that fixes these issues:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(feature = &quot;rustls&quot;)]
impl&lt;M, R&gt; ClientBuilder&lt;(), M, R&gt; {
    /// Connect to the service over HTTPS using Rustls.
    pub fn rustls(self) -&gt; ClientBuilder&lt;Adapter&lt;crate::conns::Https&gt;, M, R&gt; {
        self.connector(Adapter::builder().build(crate::conns::https()))
    }
}

#[cfg(feature = &quot;native-tls&quot;)]
impl&lt;M, R&gt; ClientBuilder&lt;(), M, R&gt; {
    /// Connect to the service over HTTPS using the native TLS library on your platform.
    pub fn native_tls(
        self,
    ) -&gt; ClientBuilder&lt;Adapter&lt;hyper_tls::HttpsConnector&lt;hyper::client::HttpConnector&gt;&gt;, M, R&gt; {
        self.connector(Adapter::builder().build(crate::conns::native_tls()))
    }
}
<span class="boring">}
</span></code></pre></pre>
<p>Both features can now be enabled at once without creating a conflict. Since both methods have different names, it's now Ok for them to have different return types.</p>
<p><a href="https://github.com/awslabs/smithy-rs/blob/2e7ed943513203f1472f2490866dc4fb8a392bd3/rust-runtime/aws-smithy-client/src/hyper_ext.rs#L303"><em>This is real code, see it in context</em></a></p>
<h3 id="we-should-avoid-using-cfgnotfeature--some-feature"><a class="header" href="#we-should-avoid-using-cfgnotfeature--some-feature">We should avoid using <code>#[cfg(not(feature = &quot;some-feature&quot;))]</code></a></h3>
<p>At the risk of seeming repetitive, the Cargo book says:</p>
<blockquote>
<p>enabling a feature should not disable functionality, and it should usually be safe to enable any combination of features</p>
</blockquote>
<p>Conditionally compiling code when a feature is <strong>not</strong> activated can make it hard for users and maintainers to reason about what will happen when they activate a feature. This is also a sign that a feature may not be &quot;additive&quot;.</p>
<p><em><strong>NOTE</strong></em>: It's ok to use <code>#[cfg(not())]</code> to conditionally compile code based on a user's OS. It's also useful when controlling what code gets rendered when testing or when generating docs.</p>
<p>One case where using <code>not</code> is acceptable is when providing a fallback when no features are set:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(feature = &quot;rt-tokio&quot;)]
pub fn default_async_sleep() -&gt; Option&lt;Arc&lt;dyn AsyncSleep&gt;&gt; {
    Some(sleep_tokio())
}

#[cfg(not(feature = &quot;rt-tokio&quot;))]
pub fn default_async_sleep() -&gt; Option&lt;Arc&lt;dyn AsyncSleep&gt;&gt; {
    None
}
<span class="boring">}
</span></code></pre></pre>
<h3 id="dont-default-to-defining-default-features"><a class="header" href="#dont-default-to-defining-default-features">Don't default to defining &quot;default features&quot;</a></h3>
<p>Because Cargo will use the union of all features enabled on a dependency when building it, we should be wary of marking features as default. Once we do mark features as default, users that want to exclude code and dependencies brought in by those features will have a difficult time doing so. One need look no further than <a href="https://github.com/awslabs/aws-sdk-rust/issues/304">this issue</a> submitted by a user that wanted to use Native TLS and struggled to make sure that Rustls was actually disabled <em>(This issue was resolved in <a href="https://github.com/awslabs/smithy-rs/pull/935">this PR</a> which removed default features from our runtime crates.)</em> This is not to say that we should never use them, as having defaults for the most common use cases means less work for those users.</p>
<h4 id="when-a-default-feature-providing-some-functionality-is-disabled-active-features-must-not-automatically-replace-that-functionality"><a class="header" href="#when-a-default-feature-providing-some-functionality-is-disabled-active-features-must-not-automatically-replace-that-functionality">When a default feature providing some functionality is disabled, active features must not automatically replace that functionality</a></h4>
<p>As the SDK is currently designed, the TLS implementation in use can change depending on what features are pulled in. Currently, if a user disables <code>default-features</code> (which include <code>rustls</code>) and activates the <code>native-tls</code> feature, then we automatically use <code>native-tls</code> when making requests. For an example of what this looks like from the user's perspective, <a href="https://github.com/awslabs/smithy-rs/tree/bc316a0b81b75a00c389f6281a66eb0f5357172a/aws/sdk/examples/using_native_tls_instead_of_rustls">see this example</a>.</p>
<p>This RFC proposes that we should have a single default for any configurable functionality and that that functionality depends on a corresponding default feature being active. If <code>default-features</code> are disabled, then so is the corresponding default functionality. In its place would be functionality that fails fast with a message describing why it failed <em>(a default was deactivated but the user didn't set a replacement)</em>, and what the user should do to fix it <em>(with links to documentation and examples where necessary)</em>. We should use <a href="https://doc.rust-lang.org/stable/std/macro.compile_error.html">compile-time errors</a> to communicate failures with users, or <code>panic</code>s for cases that can't be evaluated at compile-time.</p>
<p>For an example: Say you have a crate with features <code>a</code>, <code>b</code>, <code>c</code> that all provide some version of functionality <code>foo</code>. Feature <code>a</code> is part of <code>default-features</code>. When <code>no-default-features = true</code> but features <code>b</code> and <code>c</code> are active, don't automatically fall back to <code>b</code> or <code>c</code>. Instead, emit an error with a message like this:</p>
<blockquote>
<p>&quot;When default features are disabled, you must manually set <code>foo</code>. Features <code>b</code> and <code>c</code> active; You can use one of those. See an example of setting a custom <code>foo</code> here: <em>link-to-docs.amazon.com/setting-foo</em>&quot;</p>
</blockquote>
<h2 id="further-reading"><a class="header" href="#further-reading">Further reading</a></h2>
<ul>
<li><a href="https://stackoverflow.com/questions/59761045/how-to-tell-what-features-are-available-per-crate">How to tell what &quot;features&quot; are available per crate?</a></li>
<li><a href="https://stackoverflow.com/questions/40021555/how-do-i-pass-down-feature-flags-to-subdependencies-in-cargo">How do I 'pass down' feature flags to subdependencies in Cargo?</a></li>
<li>A small selection of feature-related GitHub issues submitted for popular crates
<ul>
<li><a href="https://github.com/chyh1990/yaml-rust/issues/44">The feature <code>preserve_order</code> is not &quot;purely additive,&quot; which makes it impossible to use <code>serde_yaml</code> 0.5.0 and <code>clap</code> in the same program</a></li>
<li><a href="https://github.com/Geal/nom/issues/544">cargo features (verbose-errors may be other?) should be additive</a></li>
<li><a href="https://github.com/aclysma/profiling/issues/32">Mutually exclusive features are present in profiling-procmacros</a></li>
<li><a href="https://github.com/KyleMayes/clang-sys/issues/128">Clang-sys features not additive</a></li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-supporting-flexible-checksums"><a class="header" href="#rfc-supporting-flexible-checksums">RFC: Supporting Flexible Checksums</a></h1>
<blockquote>
<p>Status: RFC</p>
</blockquote>
<p>We can't currently update the S3 SDK because we don't support the new &quot;Flexible Checksums&quot; feature. This RFC describes this new feature and details how we should implement it in <code>smithy-rs</code>.</p>
<h2 id="what-is-the-flexible-checksums-feature"><a class="header" href="#what-is-the-flexible-checksums-feature">What is the &quot;Flexible Checksums&quot; feature?</a></h2>
<p>S3 has previously supported MD5 checksum validation of data. Now, it supports more checksum algorithms like CRC32, CRC32C, SHA-1, and SHA-256. This validation is available when putting objects to S3 and when getting them from S3. For more information, see <a href="https://aws.amazon.com/blogs/aws/new-additional-checksum-algorithms-for-amazon-s3/">this AWS News Blog post</a>.</p>
<h2 id="implementing-checksums-1"><a class="header" href="#implementing-checksums-1">Implementing Checksums</a></h2>
<p>Checksum callbacks were introduced as a result of the acceptance of <a href="rfcs/./rfc0013_body_callback_apis.html">RFC0013</a> and this RFC proposes a refactor to those callbacks, as well as several new wrappers for <code>SdkBody</code> that will provide new functionality.</p>
<h3 id="refactoring-aws-smithy-checksums"><a class="header" href="#refactoring-aws-smithy-checksums">Refactoring aws-smithy-checksums</a></h3>
<p>TLDR; This refactor of aws-smithy-checksums:</p>
<ul>
<li>
<p><strong>Removes the &quot;callback&quot; terminology:</strong> As a word, &quot;callback&quot; doesn't carry any useful information, and doesn't aid in understanding.</p>
</li>
<li>
<p><strong>Removes support for the <code>BodyCallback</code> API:</strong> Instead of adding checksum callbacks to a body, we're going to use a &quot;body wrapping&quot; instead. &quot;Body wrapping&quot; is demonstrated in the <a href="rfcs/rfc0016_flexible_checksum_support.html#checksumbody"><code>ChecksumBody</code></a>, <a href="rfcs/rfc0016_flexible_checksum_support.html#awschunkedbody-and-awschunkedbodyoptions"><code>AwsChunkedBody</code></a>, and <a href="rfcs/rfc0016_flexible_checksum_support.html#checksumvalidatedbody"><code>ChecksumValidatedBody</code></a> sections.</p>
<p><em>NOTE: This doesn't remove the <code>BodyCallback</code> trait. That will still exist, we just won't use it.</em></p>
</li>
<li>
<p><strong>Updates terminology to focus on &quot;headers&quot; instead of &quot;trailers&quot;:</strong> Because the types we deal with in this module are named for HTTP headers, I chose to use that terminology instead. My hope is that this will be less strange to people reading this code.</p>
</li>
<li>
<p><strong>Adds <code>fn checksum_algorithm_to_checksum_header_name</code>:</strong> a function that's used in generated code to set a checksum request header.</p>
</li>
<li>
<p><strong>Adds <code>fn checksum_header_name_to_checksum_algorithm</code>:</strong> a function that's used in generated code when creating a checksum-validating response body.</p>
</li>
<li>
<p><strong>Add new checksum-related &quot;body wrapping&quot; HTTP body types</strong>: These are defined in the <code>body</code> module and will be shown later in this RFC.</p>
</li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// In aws-smithy-checksums/src/lib.rs
//! Checksum calculation and verification callbacks

use aws_smithy_types::base64;

use bytes::Bytes;
use http::header::{HeaderMap, HeaderName, HeaderValue};
use sha1::Digest;
use std::io::Write;

pub mod body;

// Valid checksum algorithm names
pub const CRC_32_NAME: &amp;str = &quot;crc32&quot;;
pub const CRC_32_C_NAME: &amp;str = &quot;crc32c&quot;;
pub const SHA_1_NAME: &amp;str = &quot;sha1&quot;;
pub const SHA_256_NAME: &amp;str = &quot;sha256&quot;;

pub const CRC_32_HEADER_NAME: HeaderName = HeaderName::from_static(&quot;x-amz-checksum-crc32&quot;);
pub const CRC_32_C_HEADER_NAME: HeaderName = HeaderName::from_static(&quot;x-amz-checksum-crc32c&quot;);
pub const SHA_1_HEADER_NAME: HeaderName = HeaderName::from_static(&quot;x-amz-checksum-sha1&quot;);
pub const SHA_256_HEADER_NAME: HeaderName = HeaderName::from_static(&quot;x-amz-checksum-sha256&quot;);

// Preserved for compatibility purposes. This should never be used by users, only within smithy-rs
const MD5_NAME: &amp;str = &quot;md5&quot;;
const MD5_HEADER_NAME: HeaderName = HeaderName::from_static(&quot;content-md5&quot;);

/// Given a `&amp;str` representing a checksum algorithm, return the corresponding `HeaderName`
/// for that checksum algorithm.
pub fn checksum_algorithm_to_checksum_header_name(checksum_algorithm: &amp;str) -&gt; HeaderName {
    if checksum_algorithm.eq_ignore_ascii_case(CRC_32_NAME) {
        CRC_32_HEADER_NAME
    } else if checksum_algorithm.eq_ignore_ascii_case(CRC_32_C_NAME) {
        CRC_32_C_HEADER_NAME
    } else if checksum_algorithm.eq_ignore_ascii_case(SHA_1_NAME) {
        SHA_1_HEADER_NAME
    } else if checksum_algorithm.eq_ignore_ascii_case(SHA_256_NAME) {
        SHA_256_HEADER_NAME
    } else if checksum_algorithm.eq_ignore_ascii_case(MD5_NAME) {
        MD5_HEADER_NAME
    } else {
        // TODO what's the best way to handle this case?
        HeaderName::from_static(&quot;x-amz-checksum-unknown&quot;)
    }
}

/// Given a `HeaderName` representing a checksum algorithm, return the name of that algorithm
/// as a `&amp;'static str`.
pub fn checksum_header_name_to_checksum_algorithm(
    checksum_header_name: &amp;HeaderName,
) -&gt; &amp;'static str {
    if checksum_header_name == CRC_32_HEADER_NAME {
        CRC_32_NAME
    } else if checksum_header_name == CRC_32_C_HEADER_NAME {
        CRC_32_C_NAME
    } else if checksum_header_name == SHA_1_HEADER_NAME {
        SHA_1_NAME
    } else if checksum_header_name == SHA_256_HEADER_NAME {
        SHA_256_NAME
    } else if checksum_header_name == MD5_HEADER_NAME {
        MD5_NAME
    } else {
        // TODO what's the best way to handle this case?
        &quot;unknown-checksum-algorithm&quot;
    }
}

/// When a response has to be checksum-verified, we have to check possible headers until we find the
/// header with the precalculated checksum. Because a service may send back multiple headers, we have
/// to check them in order based on how fast each checksum is to calculate.
pub const CHECKSUM_HEADERS_IN_PRIORITY_ORDER: [HeaderName; 4] = [
    CRC_32_C_HEADER_NAME,
    CRC_32_HEADER_NAME,
    SHA_1_HEADER_NAME,
    SHA_256_HEADER_NAME,
];

type BoxError = Box&lt;dyn std::error::Error + Send + Sync&gt;;

/// Checksum algorithms are use to validate the integrity of data. Structs that implement this trait
/// can be used as checksum calculators. This trait requires Send + Sync because these checksums are
/// often used in a threaded context.
pub trait Checksum: Send + Sync {
    /// Given a slice of bytes, update this checksum's internal state.
    fn update(&amp;mut self, bytes: &amp;[u8]) -&gt; Result&lt;(), BoxError&gt;;
    /// Either return this checksum as a `HeaderMap` containing one HTTP header, or return an error
    /// describing why checksum calculation failed.
    fn headers(&amp;self) -&gt; Result&lt;Option&lt;HeaderMap&lt;HeaderValue&gt;&gt;, BoxError&gt;;
    /// Return the `HeaderName` used to represent this checksum algorithm
    fn header_name(&amp;self) -&gt; HeaderName;
    /// &quot;Finalize&quot; this checksum, returning the calculated value as `Bytes` or an error that
    /// occurred during checksum calculation. To print this value in a human-readable hexadecimal
    /// format, you can print it using Rust's builtin [formatter].
    ///
    /// _**NOTE:** typically, &quot;finalizing&quot; a checksum in Rust will take ownership of the checksum
    /// struct. In this method, we clone the checksum's state before finalizing because checksums
    /// may be used in a situation where taking ownership is not possible._
    ///
    /// [formatter]: https://doc.rust-lang.org/std/fmt/trait.UpperHex.html
    fn finalize(&amp;self) -&gt; Result&lt;Bytes, BoxError&gt;;
    /// Return the size of this checksum algorithms resulting checksum, in bytes. For example, the
    /// CRC32 checksum algorithm calculates a 32 bit checksum, so a CRC32 checksum struct
    /// implementing this trait method would return 4.
    fn size(&amp;self) -&gt; u64;
}

/// Create a new `Box&lt;dyn Checksum&gt;` from an algorithm name. Valid algorithm names are defined as
/// `const`s in this module.
pub fn new_checksum(checksum_algorithm: &amp;str) -&gt; Box&lt;dyn Checksum&gt; {
    if checksum_algorithm.eq_ignore_ascii_case(CRC_32_NAME) {
        Box::new(Crc32::default())
    } else if checksum_algorithm.eq_ignore_ascii_case(CRC_32_C_NAME) {
        Box::new(Crc32c::default())
    } else if checksum_algorithm.eq_ignore_ascii_case(SHA_1_NAME) {
        Box::new(Sha1::default())
    } else if checksum_algorithm.eq_ignore_ascii_case(SHA_256_NAME) {
        Box::new(Sha256::default())
    } else if checksum_algorithm.eq_ignore_ascii_case(MD5_NAME) {
        // It's possible to create an MD5 and we do this in some situations for compatibility.
        // We deliberately hide this from users so that they don't go using it.
        Box::new(Md5::default())
    } else {
        panic!(&quot;unsupported checksum algorithm '{}'&quot;, checksum_algorithm)
    }
}

#[derive(Debug, Default)]
struct Crc32 {
    hasher: crc32fast::Hasher,
}

impl Crc32 {
    fn update(&amp;mut self, bytes: &amp;[u8]) -&gt; Result&lt;(), BoxError&gt; {
        self.hasher.update(bytes);

        Ok(())
    }

    fn headers(&amp;self) -&gt; Result&lt;Option&lt;HeaderMap&lt;HeaderValue&gt;&gt;, BoxError&gt; {
        let mut header_map = HeaderMap::new();
        header_map.insert(Self::header_name(), self.header_value());

        Ok(Some(header_map))
    }

    fn finalize(&amp;self) -&gt; Result&lt;Bytes, BoxError&gt; {
        Ok(Bytes::copy_from_slice(
            &amp;self.hasher.clone().finalize().to_be_bytes(),
        ))
    }

    // Size of the checksum in bytes
    fn size() -&gt; u64 {
        4
    }

    fn header_name() -&gt; HeaderName {
        CRC_32_HEADER_NAME
    }

    fn header_value(&amp;self) -&gt; HeaderValue {
        // We clone the hasher because `Hasher::finalize` consumes `self`
        let hash = self.hasher.clone().finalize();
        HeaderValue::from_str(&amp;base64::encode(u32::to_be_bytes(hash)))
            .expect(&quot;will always produce a valid header value from a CRC32 checksum&quot;)
    }
}

impl Checksum for Crc32 {
    fn update(
        &amp;mut self,
        bytes: &amp;[u8],
    ) -&gt; Result&lt;(), Box&lt;(dyn std::error::Error + Send + Sync + 'static)&gt;&gt; {
        Self::update(self, bytes)
    }
    fn headers(
        &amp;self,
    ) -&gt; Result&lt;Option&lt;HeaderMap&gt;, Box&lt;(dyn std::error::Error + Send + Sync + 'static)&gt;&gt; {
        Self::headers(self)
    }
    fn header_name(&amp;self) -&gt; HeaderName {
        Self::header_name()
    }
    fn finalize(&amp;self) -&gt; Result&lt;Bytes, BoxError&gt; {
        Self::finalize(self)
    }
    fn size(&amp;self) -&gt; u64 {
        Self::size()
    }
}

#[derive(Debug, Default)]
struct Crc32c {
    state: Option&lt;u32&gt;,
}

impl Crc32c {
    fn update(&amp;mut self, bytes: &amp;[u8]) -&gt; Result&lt;(), BoxError&gt; {
        self.state = match self.state {
            Some(crc) =&gt; Some(crc32c::crc32c_append(crc, bytes)),
            None =&gt; Some(crc32c::crc32c(bytes)),
        };

        Ok(())
    }

    fn headers(&amp;self) -&gt; Result&lt;Option&lt;HeaderMap&lt;HeaderValue&gt;&gt;, BoxError&gt; {
        let mut header_map = HeaderMap::new();
        header_map.insert(Self::header_name(), self.header_value());

        Ok(Some(header_map))
    }

    fn finalize(&amp;self) -&gt; Result&lt;Bytes, BoxError&gt; {
        Ok(Bytes::copy_from_slice(
            &amp;self.state.unwrap_or_default().to_be_bytes(),
        ))
    }

    // Size of the checksum in bytes
    fn size() -&gt; u64 {
        4
    }

    fn header_name() -&gt; HeaderName {
        CRC_32_C_HEADER_NAME
    }

    fn header_value(&amp;self) -&gt; HeaderValue {
        // If no data was provided to this callback and no CRC was ever calculated, return zero as the checksum.
        let hash = self.state.unwrap_or_default();
        HeaderValue::from_str(&amp;base64::encode(u32::to_be_bytes(hash)))
            .expect(&quot;will always produce a valid header value from a CRC32C checksum&quot;)
    }
}

impl Checksum for Crc32c {
    fn update(
        &amp;mut self,
        bytes: &amp;[u8],
    ) -&gt; Result&lt;(), Box&lt;(dyn std::error::Error + Send + Sync + 'static)&gt;&gt; {
        Self::update(self, bytes)
    }
    fn headers(
        &amp;self,
    ) -&gt; Result&lt;Option&lt;HeaderMap&gt;, Box&lt;(dyn std::error::Error + Send + Sync + 'static)&gt;&gt; {
        Self::headers(self)
    }
    fn header_name(&amp;self) -&gt; HeaderName {
        Self::header_name()
    }
    fn finalize(&amp;self) -&gt; Result&lt;Bytes, BoxError&gt; {
        Self::finalize(self)
    }
    fn size(&amp;self) -&gt; u64 {
        Self::size()
    }
}

#[derive(Debug, Default)]
struct Sha1 {
    hasher: sha1::Sha1,
}

impl Sha1 {
    fn update(&amp;mut self, bytes: &amp;[u8]) -&gt; Result&lt;(), BoxError&gt; {
        self.hasher.write_all(bytes)?;

        Ok(())
    }

    fn headers(&amp;self) -&gt; Result&lt;Option&lt;HeaderMap&lt;HeaderValue&gt;&gt;, BoxError&gt; {
        let mut header_map = HeaderMap::new();
        header_map.insert(Self::header_name(), self.header_value());

        Ok(Some(header_map))
    }

    fn finalize(&amp;self) -&gt; Result&lt;Bytes, BoxError&gt; {
        Ok(Bytes::copy_from_slice(
            self.hasher.clone().finalize().as_slice(),
        ))
    }

    // Size of the checksum in bytes
    fn size() -&gt; u64 {
        20
    }

    fn header_name() -&gt; HeaderName {
        SHA_1_HEADER_NAME
    }

    fn header_value(&amp;self) -&gt; HeaderValue {
        // We clone the hasher because `Hasher::finalize` consumes `self`
        let hash = self.hasher.clone().finalize();
        HeaderValue::from_str(&amp;base64::encode(&amp;hash[..]))
            .expect(&quot;will always produce a valid header value from a SHA-1 checksum&quot;)
    }
}

impl Checksum for Sha1 {
    fn update(
        &amp;mut self,
        bytes: &amp;[u8],
    ) -&gt; Result&lt;(), Box&lt;(dyn std::error::Error + Send + Sync + 'static)&gt;&gt; {
        Self::update(self, bytes)
    }
    fn headers(
        &amp;self,
    ) -&gt; Result&lt;Option&lt;HeaderMap&gt;, Box&lt;(dyn std::error::Error + Send + Sync + 'static)&gt;&gt; {
        Self::headers(self)
    }
    fn header_name(&amp;self) -&gt; HeaderName {
        Self::header_name()
    }
    fn finalize(&amp;self) -&gt; Result&lt;Bytes, BoxError&gt; {
        Self::finalize(self)
    }
    fn size(&amp;self) -&gt; u64 {
        Self::size()
    }
}

#[derive(Debug, Default)]
struct Sha256 {
    hasher: sha2::Sha256,
}

impl Sha256 {
    fn update(&amp;mut self, bytes: &amp;[u8]) -&gt; Result&lt;(), BoxError&gt; {
        self.hasher.write_all(bytes)?;

        Ok(())
    }

    fn headers(&amp;self) -&gt; Result&lt;Option&lt;HeaderMap&lt;HeaderValue&gt;&gt;, BoxError&gt; {
        let mut header_map = HeaderMap::new();
        header_map.insert(Self::header_name(), self.header_value());

        Ok(Some(header_map))
    }

    fn finalize(&amp;self) -&gt; Result&lt;Bytes, BoxError&gt; {
        Ok(Bytes::copy_from_slice(
            self.hasher.clone().finalize().as_slice(),
        ))
    }

    // Size of the checksum in bytes
    fn size() -&gt; u64 {
        32
    }

    fn header_name() -&gt; HeaderName {
        SHA_256_HEADER_NAME
    }

    fn header_value(&amp;self) -&gt; HeaderValue {
        // We clone the hasher because `Hasher::finalize` consumes `self`
        let hash = self.hasher.clone().finalize();
        HeaderValue::from_str(&amp;base64::encode(&amp;hash[..]))
            .expect(&quot;will always produce a valid header value from a SHA-256 checksum&quot;)
    }
}

impl Checksum for Sha256 {
    fn update(
        &amp;mut self,
        bytes: &amp;[u8],
    ) -&gt; Result&lt;(), Box&lt;(dyn std::error::Error + Send + Sync + 'static)&gt;&gt; {
        Self::update(self, bytes)
    }
    fn headers(
        &amp;self,
    ) -&gt; Result&lt;Option&lt;HeaderMap&gt;, Box&lt;(dyn std::error::Error + Send + Sync + 'static)&gt;&gt; {
        Self::headers(self)
    }
    fn header_name(&amp;self) -&gt; HeaderName {
        Self::header_name()
    }
    fn finalize(&amp;self) -&gt; Result&lt;Bytes, BoxError&gt; {
        Self::finalize(self)
    }
    fn size(&amp;self) -&gt; u64 {
        Self::size()
    }
}

#[derive(Debug, Default)]
struct Md5 {
    hasher: md5::Md5,
}

impl Md5 {
    fn update(&amp;mut self, bytes: &amp;[u8]) -&gt; Result&lt;(), BoxError&gt; {
        self.hasher.write_all(bytes)?;

        Ok(())
    }

    fn headers(&amp;self) -&gt; Result&lt;Option&lt;HeaderMap&lt;HeaderValue&gt;&gt;, BoxError&gt; {
        let mut header_map = HeaderMap::new();
        header_map.insert(Self::header_name(), self.header_value());

        Ok(Some(header_map))
    }

    fn finalize(&amp;self) -&gt; Result&lt;Bytes, BoxError&gt; {
        Ok(Bytes::copy_from_slice(
            self.hasher.clone().finalize().as_slice(),
        ))
    }

    // Size of the checksum in bytes
    fn size() -&gt; u64 {
        16
    }

    fn header_name() -&gt; HeaderName {
        MD5_HEADER_NAME
    }

    fn header_value(&amp;self) -&gt; HeaderValue {
        // We clone the hasher because `Hasher::finalize` consumes `self`
        let hash = self.hasher.clone().finalize();
        HeaderValue::from_str(&amp;base64::encode(&amp;hash[..]))
            .expect(&quot;will always produce a valid header value from an MD5 checksum&quot;)
    }
}

impl Checksum for Md5 {
    fn update(
        &amp;mut self,
        bytes: &amp;[u8],
    ) -&gt; Result&lt;(), Box&lt;(dyn std::error::Error + Send + Sync + 'static)&gt;&gt; {
        Self::update(self, bytes)
    }
    fn headers(
        &amp;self,
    ) -&gt; Result&lt;Option&lt;HeaderMap&gt;, Box&lt;(dyn std::error::Error + Send + Sync + 'static)&gt;&gt; {
        Self::headers(self)
    }
    fn header_name(&amp;self) -&gt; HeaderName {
        Self::header_name()
    }
    fn finalize(&amp;self) -&gt; Result&lt;Bytes, BoxError&gt; {
        Self::finalize(self)
    }
    fn size(&amp;self) -&gt; u64 {
        Self::size()
    }
}

// We have existing tests for the checksums, those don't require an update
<span class="boring">}
</span></code></pre></pre>
<h3 id="checksumbody"><a class="header" href="#checksumbody"><code>ChecksumBody</code></a></h3>
<p>When creating a checksum-validated request with an in-memory request body, we can read the body, calculate a checksum, and insert the checksum header, all before sending the request. When creating a checksum-validated request with a streaming request body, we don't have that luxury. Instead, we must calculate a checksum while sending the body, and append that checksum as a <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Trailer">trailer</a>.</p>
<p>We will accomplish this by wrapping the <code>SdkBody</code> that requires validation within a <code>ChecksumBody</code>. Afterwards, we'll need to wrap the <code>ChecksumBody</code> in yet another layer which we'll discuss in the <a href="rfcs/rfc0016_flexible_checksum_support.html#awschunkedbody-and-awschunkedbodyoptions"><code>AwsChunkedBody</code> and <code>AwsChunkedBodyOptions</code></a> section.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// In aws-smithy-checksums/src/body.rs
use crate::{new_checksum, Checksum};

use aws_smithy_http::body::SdkBody;
use aws_smithy_http::header::append_merge_header_maps;
use aws_smithy_types::base64;

use bytes::{Buf, Bytes};
use http::header::HeaderName;
use http::{HeaderMap, HeaderValue};
use http_body::{Body, SizeHint};
use pin_project::pin_project;

use std::fmt::Display;
use std::pin::Pin;
use std::task::{Context, Poll};

/// A `ChecksumBody` will read and calculate a request body as it's being sent. Once the body has
/// been completely read, it'll append a trailer with the calculated checksum.
#[pin_project]
pub struct ChecksumBody&lt;InnerBody&gt; {
    #[pin]
    inner: InnerBody,
    #[pin]
    checksum: Box&lt;dyn Checksum&gt;,
}

impl ChecksumBody&lt;SdkBody&gt; {
    /// Given an `SdkBody` and the name of a checksum algorithm as a `&amp;str`, create a new
    /// `ChecksumBody&lt;SdkBody&gt;`. Valid checksum algorithm names are defined in this crate's
    /// [root module](super).
    ///
    /// # Panics
    ///
    /// This will panic if the given checksum algorithm is not supported.
    pub fn new(body: SdkBody, checksum_algorithm: &amp;str) -&gt; Self {
        Self {
            checksum: new_checksum(checksum_algorithm),
            inner: body,
        }
    }

    /// Return the name of the trailer that will be emitted by this `ChecksumBody`
    pub fn trailer_name(&amp;self) -&gt; HeaderName {
        self.checksum.header_name()
    }

    /// Calculate and return the sum of the:
    /// - checksum when base64 encoded
    /// - trailer name
    /// - trailer separator
    ///
    /// This is necessary for calculating the true size of the request body for certain
    /// content-encodings.
    pub fn trailer_length(&amp;self) -&gt; u64 {
        let trailer_name_size_in_bytes = self.checksum.header_name().as_str().len() as u64;
        let base64_encoded_checksum_size_in_bytes = base64::encoded_length(self.checksum.size());

        (trailer_name_size_in_bytes
            // HTTP trailer names and values may be separated by either a single colon or a single
            // colon and a whitespace. In the AWS Rust SDK, we use a single colon.
            + &quot;:&quot;.len() as u64
            + base64_encoded_checksum_size_in_bytes)
    }

    fn poll_inner(
        self: Pin&lt;&amp;mut Self&gt;,
        cx: &amp;mut Context&lt;'_&gt;,
    ) -&gt; Poll&lt;Option&lt;Result&lt;Bytes, aws_smithy_http::body::Error&gt;&gt;&gt; {
        let this = self.project();
        let inner = this.inner;
        let mut checksum = this.checksum;

        match inner.poll_data(cx) {
            Poll::Ready(Some(Ok(mut data))) =&gt; {
                let len = data.chunk().len();
                let bytes = data.copy_to_bytes(len);

                if let Err(e) = checksum.update(&amp;bytes) {
                    return Poll::Ready(Some(Err(e)));
                }

                Poll::Ready(Some(Ok(bytes)))
            }
            Poll::Ready(None) =&gt; Poll::Ready(None),
            Poll::Ready(Some(Err(e))) =&gt; Poll::Ready(Some(Err(e))),
            Poll::Pending =&gt; Poll::Pending,
        }
    }
}

impl http_body::Body for ChecksumBody&lt;SdkBody&gt; {
    type Data = Bytes;
    type Error = aws_smithy_http::body::Error;

    fn poll_data(
        self: Pin&lt;&amp;mut Self&gt;,
        cx: &amp;mut Context&lt;'_&gt;,
    ) -&gt; Poll&lt;Option&lt;Result&lt;Self::Data, Self::Error&gt;&gt;&gt; {
        self.poll_inner(cx)
    }

    fn poll_trailers(
        self: Pin&lt;&amp;mut Self&gt;,
        cx: &amp;mut Context&lt;'_&gt;,
    ) -&gt; Poll&lt;Result&lt;Option&lt;HeaderMap&lt;HeaderValue&gt;&gt;, Self::Error&gt;&gt; {
        let this = self.project();
        match (
            this.checksum.headers(),
            http_body::Body::poll_trailers(this.inner, cx),
        ) {
            // If everything is ready, return trailers, merging them if we have more than one map
            (Ok(outer_trailers), Poll::Ready(Ok(inner_trailers))) =&gt; {
                let trailers = match (outer_trailers, inner_trailers) {
                    // Values from the inner trailer map take precedent over values from the outer map
                    (Some(outer), Some(inner)) =&gt; Some(append_merge_header_maps(inner, outer)),
                    // If only one or neither produced trailers, just combine the `Option`s with `or`
                    (outer, inner) =&gt; outer.or(inner),
                };
                Poll::Ready(Ok(trailers))
            }
            // If the inner poll is Ok but the outer body's checksum callback encountered an error,
            // return the error
            (Err(e), Poll::Ready(Ok(_))) =&gt; Poll::Ready(Err(e)),
            // Otherwise return the result of the inner poll.
            // It may be pending or it may be ready with an error.
            (_, inner_poll) =&gt; inner_poll,
        }
    }

    fn is_end_stream(&amp;self) -&gt; bool {
        self.inner.is_end_stream()
    }

    fn size_hint(&amp;self) -&gt; SizeHint {
        let body_size_hint = self.inner.size_hint();
        match body_size_hint.exact() {
            Some(size) =&gt; {
                let checksum_size_hint = self.checksum.size();
                SizeHint::with_exact(size + checksum_size_hint)
            }
            // TODO is this the right behavior?
            None =&gt; {
                let checksum_size_hint = self.checksum.size();
                let mut summed_size_hint = SizeHint::new();
                summed_size_hint.set_lower(body_size_hint.lower() + checksum_size_hint);

                if let Some(body_size_hint_upper) = body_size_hint.upper() {
                    summed_size_hint.set_upper(body_size_hint_upper + checksum_size_hint);
                }

                summed_size_hint
            }
        }
    }
}

// The tests I have written are omitted from this RFC for brevity. The request body checksum calculation and trailer size calculations are all tested.
<span class="boring">}
</span></code></pre></pre>
<h3 id="checksumvalidatedbody"><a class="header" href="#checksumvalidatedbody"><code>ChecksumValidatedBody</code></a></h3>
<p>Users may request checksum validation for response bodies. That capability is provided by <code>ChecksumValidatedBody</code>, which will calculate a checksum as the response body is being read. Once all data has been read, the calculated checksum is compared to a precalculated checksum set during body creation. If the checksums don't match, then the body will emit an error.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// In aws-smithy-checksums/src/body.rs
/// A response body that will calculate a checksum as it is read. If all data is read and the
/// calculated checksum doesn't match a precalculated checksum, this body will emit an
/// [asw_smithy_http::body::Error].
#[pin_project]
pub struct ChecksumValidatedBody&lt;InnerBody&gt; {
    #[pin]
    inner: InnerBody,
    #[pin]
    checksum: Box&lt;dyn Checksum&gt;,
    precalculated_checksum: Bytes,
}

impl ChecksumValidatedBody&lt;SdkBody&gt; {
    /// Given an `SdkBody`, the name of a checksum algorithm as a `&amp;str`, and a precalculated
    /// checksum represented as `Bytes`, create a new `ChecksumValidatedBody&lt;SdkBody&gt;`.
    /// Valid checksum algorithm names are defined in this crate's [root module](super).
    ///
    /// # Panics
    ///
    /// This will panic if the given checksum algorithm is not supported.
    pub fn new(body: SdkBody, checksum_algorithm: &amp;str, precalculated_checksum: Bytes) -&gt; Self {
        Self {
            checksum: new_checksum(checksum_algorithm),
            inner: body,
            precalculated_checksum,
        }
    }

    fn poll_inner(
        self: Pin&lt;&amp;mut Self&gt;,
        cx: &amp;mut Context&lt;'_&gt;,
    ) -&gt; Poll&lt;Option&lt;Result&lt;Bytes, aws_smithy_http::body::Error&gt;&gt;&gt; {
        let this = self.project();
        let inner = this.inner;
        let mut checksum = this.checksum;

        match inner.poll_data(cx) {
            Poll::Ready(Some(Ok(mut data))) =&gt; {
                let len = data.chunk().len();
                let bytes = data.copy_to_bytes(len);

                if let Err(e) = checksum.update(&amp;bytes) {
                    return Poll::Ready(Some(Err(e)));
                }

                Poll::Ready(Some(Ok(bytes)))
            }
            // Once the inner body has stopped returning data, check the checksum
            // and return an error if it doesn't match.
            Poll::Ready(None) =&gt; {
                let actual_checksum = {
                    match checksum.finalize() {
                        Ok(checksum) =&gt; checksum,
                        Err(err) =&gt; {
                            return Poll::Ready(Some(Err(err)));
                        }
                    }
                };
                if *this.precalculated_checksum == actual_checksum {
                    Poll::Ready(None)
                } else {
                    // So many parens it's starting to look like LISP
                    Poll::Ready(Some(Err(Box::new(Error::checksum_mismatch(
                        this.precalculated_checksum.clone(),
                        actual_checksum,
                    )))))
                }
            }
            Poll::Ready(Some(Err(e))) =&gt; Poll::Ready(Some(Err(e))),
            Poll::Pending =&gt; Poll::Pending,
        }
    }
}

/// Errors related to checksum calculation and validation
#[derive(Debug, Eq, PartialEq)]
#[non_exhaustive]
pub enum Error {
    /// The actual checksum didn't match the expected checksum. The checksummed data has been
    /// altered since the expected checksum was calculated.
    ChecksumMismatch { expected: Bytes, actual: Bytes },
}

impl Error {
    /// Given an expected checksum and an actual checksum in `Bytes` form, create a new
    /// `Error::ChecksumMismatch`.
    pub fn checksum_mismatch(expected: Bytes, actual: Bytes) -&gt; Self {
        Self::ChecksumMismatch { expected, actual }
    }
}

impl Display for Error {
    fn fmt(&amp;self, f: &amp;mut std::fmt::Formatter&lt;'_&gt;) -&gt; Result&lt;(), std::fmt::Error&gt; {
        match self {
            Error::ChecksumMismatch { expected, actual } =&gt; write!(
                f,
                &quot;body checksum mismatch. expected body checksum to be {:x} but it was {:x}&quot;,
                expected, actual
            ),
        }
    }
}

impl std::error::Error for Error {}

impl http_body::Body for ChecksumValidatedBody&lt;SdkBody&gt; {
    type Data = Bytes;
    type Error = aws_smithy_http::body::Error;

    fn poll_data(
        self: Pin&lt;&amp;mut Self&gt;,
        cx: &amp;mut Context&lt;'_&gt;,
    ) -&gt; Poll&lt;Option&lt;Result&lt;Self::Data, Self::Error&gt;&gt;&gt; {
        self.poll_inner(cx)
    }

    fn poll_trailers(
        self: Pin&lt;&amp;mut Self&gt;,
        cx: &amp;mut Context&lt;'_&gt;,
    ) -&gt; Poll&lt;Result&lt;Option&lt;HeaderMap&lt;HeaderValue&gt;&gt;, Self::Error&gt;&gt; {
        self.project().inner.poll_trailers(cx)
    }

    // Once the inner body returns true for is_end_stream, we still need to
    // verify the checksum; Therefore, we always return false here.
    fn is_end_stream(&amp;self) -&gt; bool {
        false
    }

    fn size_hint(&amp;self) -&gt; SizeHint {
        self.inner.size_hint()
    }
}

// The tests I have written are omitted from this RFC for brevity. The response body checksum verification is tested.
<span class="boring">}
</span></code></pre></pre>
<h3 id="awschunkedbody-and-awschunkedbodyoptions"><a class="header" href="#awschunkedbody-and-awschunkedbodyoptions"><code>AwsChunkedBody</code> and <code>AwsChunkedBodyOptions</code></a></h3>
<p>In order to send a request with checksum trailers, we must use an AWS-specific content encoding called <code>aws-chunked</code>. This encoding requires that we:</p>
<ul>
<li>Divide the original body content into one or more chunks. For our purposes we only ever use one chunk.</li>
<li>Append a hexadecimal chunk size header to each chunk.</li>
<li>Suffix each chunk with a <a href="https://developer.mozilla.org/en-US/docs/Glossary/CRLF">CRLF (carriage return line feed)</a>.</li>
<li>Send a 0 and CRLF to close the original body content section.</li>
<li>Send trailers as part of the request body, suffixing each with a CRLF.</li>
<li>Send a final CRLF to close the request body.</li>
</ul>
<p>As an example, Sending a regular request body with a SHA-256 checksum would look similar to this:</p>
<pre><code class="language-HTTP">PUT SOMEURL HTTP/1.1
x-amz-checksum-sha256: ZOyIygCyaOW6GjVnihtTFtIS9PNmskdyMlNKiuyjfzw=
Content-Length: 11
...

Hello world
</code></pre>
<p>and the <code>aws-chunked</code> version would look like this:</p>
<pre><code class="language-HTTP">PUT SOMEURL HTTP/1.1
x-amz-trailer: x-amz-checksum-sha256
x-amz-decoded-content-length: 11
Content-Encoding: aws-chunked
Content-Length: 87
...

B\r\n
Hello world\r\n
0\r\n
x-amz-checksum-sha256:ZOyIygCyaOW6GjVnihtTFtIS9PNmskdyMlNKiuyjfzw=\r\n
\r\n
</code></pre>
<p><em><strong>NOTES:</strong></em></p>
<ul>
<li><em>In the second example, <code>B</code> is the hexadecimal representation of 11.</em></li>
<li><em>Authorization and other headers are omitted from the examples above for brevity.</em></li>
<li><em>When using <code>aws-chunked</code> content encoding, S3 requires that we send the <code>x-amz-decoded-content-length</code> with the length of the original body content.</em></li>
</ul>
<p>This encoding scheme is performed by <code>AwsChunkedBody</code> and configured with <code>AwsChunkedBodyOptions</code>.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// In aws-http/src/content_encoding.rs
use aws_smithy_checksums::body::ChecksumBody;
use aws_smithy_http::body::SdkBody;

use bytes::{Buf, Bytes, BytesMut};
use http::{HeaderMap, HeaderValue};
use http_body::{Body, SizeHint};
use pin_project::pin_project;

use std::pin::Pin;
use std::task::{Context, Poll};

const CRLF: &amp;str = &quot;\r\n&quot;;
const CHUNK_TERMINATOR: &amp;str = &quot;0\r\n&quot;;

/// Content encoding header value constants
pub mod header_value {
    /// Header value denoting &quot;aws-chunked&quot; encoding
    pub const AWS_CHUNKED: &amp;str = &quot;aws-chunked&quot;;
}

/// Options used when constructing an [`AwsChunkedBody`][AwsChunkedBody].
#[derive(Debug, Default)]
#[non_exhaustive]
pub struct AwsChunkedBodyOptions {
    /// The total size of the stream. For unsigned encoding this implies that
    /// there will only be a single chunk containing the underlying payload,
    /// unless ChunkLength is also specified.
    pub stream_length: Option&lt;u64&gt;,
    /// The maximum size of each chunk to be sent.
    ///
    /// If ChunkLength and stream_length are both specified, the stream will be
    /// broken up into chunk_length chunks. The encoded length of the aws-chunked
    /// encoding can still be determined as long as all trailers, if any, have a
    /// fixed length.
    pub chunk_length: Option&lt;u64&gt;,
    /// The length of each trailer sent within an `AwsChunkedBody`. Necessary in
    /// order to correctly calculate the total size of the body accurately.
    pub trailer_lens: Vec&lt;u64&gt;,
}

impl AwsChunkedBodyOptions {
    /// Create a new [`AwsChunkedBodyOptions`][AwsChunkedBodyOptions]
    pub fn new() -&gt; Self {
        Self::default()
    }

    /// Set stream length
    pub fn with_stream_length(mut self, stream_length: u64) -&gt; Self {
        self.stream_length = Some(stream_length);
        self
    }

    /// Set chunk length
    pub fn with_chunk_length(mut self, chunk_length: u64) -&gt; Self {
        self.chunk_length = Some(chunk_length);
        self
    }

    /// Set a trailer len
    pub fn with_trailer_len(mut self, trailer_len: u64) -&gt; Self {
        self.trailer_lens.push(trailer_len);
        self
    }
}

#[derive(Debug, PartialEq, Eq)]
enum AwsChunkedBodyState {
    WritingChunkSize,
    WritingChunk,
    WritingTrailers,
    Closed,
}

/// A request body compatible with `Content-Encoding: aws-chunked`
///
/// Chunked-Body grammar is defined in [ABNF] as:
///
/// ```txt
/// Chunked-Body    = *chunk
///                   last-chunk
///                   chunked-trailer
///                   CRLF
///
/// chunk           = chunk-size CRLF chunk-data CRLF
/// chunk-size      = 1*HEXDIG
/// last-chunk      = 1*(&quot;0&quot;) CRLF
/// chunked-trailer = *( entity-header CRLF )
/// entity-header   = field-name &quot;:&quot; OWS field-value OWS
/// ```
/// For more info on what the abbreviations mean, see https://datatracker.ietf.org/doc/html/rfc7230#section-1.2
///
/// [ABNF]:https://en.wikipedia.org/wiki/Augmented_Backus%E2%80%93Naur_form
#[derive(Debug)]
#[pin_project]
pub struct AwsChunkedBody&lt;InnerBody&gt; {
    #[pin]
    inner: InnerBody,
    #[pin]
    state: AwsChunkedBodyState,
    options: AwsChunkedBodyOptions,
}

// Currently, we only use this in terms of a streaming request body with checksum trailers
type Inner = ChecksumBody&lt;SdkBody&gt;;

impl AwsChunkedBody&lt;Inner&gt; {
    /// Wrap the given body in an outer body compatible with `Content-Encoding: aws-chunked`
    pub fn new(body: Inner, options: AwsChunkedBodyOptions) -&gt; Self {
        Self {
            inner: body,
            state: AwsChunkedBodyState::WritingChunkSize,
            options,
        }
    }

    fn encoded_length(&amp;self) -&gt; Option&lt;u64&gt; {
        if self.options.chunk_length.is_none() &amp;&amp; self.options.stream_length.is_none() {
            return None;
        }

        let mut length = 0;
        let stream_length = self.options.stream_length.unwrap_or_default();
        if stream_length != 0 {
            if let Some(chunk_length) = self.options.chunk_length {
                let num_chunks = stream_length / chunk_length;
                length += num_chunks * get_unsigned_chunk_bytes_length(chunk_length);
                let remainder = stream_length % chunk_length;
                if remainder != 0 {
                    length += get_unsigned_chunk_bytes_length(remainder);
                }
            } else {
                length += get_unsigned_chunk_bytes_length(stream_length);
            }
        }

        // End chunk
        length += CHUNK_TERMINATOR.len() as u64;

        // Trailers
        for len in self.options.trailer_lens.iter() {
            length += len + CRLF.len() as u64;
        }

        // Encoding terminator
        length += CRLF.len() as u64;

        Some(length)
    }
}

fn prefix_with_chunk_size(data: Bytes, chunk_size: u64) -&gt; Bytes {
    // Len is the size of the entire chunk as defined in `AwsChunkedBodyOptions`
    let mut prefixed_data = BytesMut::from(format!(&quot;{:X?}\r\n&quot;, chunk_size).as_bytes());
    prefixed_data.extend_from_slice(&amp;data);

    prefixed_data.into()
}

fn get_unsigned_chunk_bytes_length(payload_length: u64) -&gt; u64 {
    let hex_repr_len = int_log16(payload_length);
    hex_repr_len + CRLF.len() as u64 + payload_length + CRLF.len() as u64
}

fn trailers_as_aws_chunked_bytes(
    total_length_of_trailers_in_bytes: u64,
    trailer_map: Option&lt;HeaderMap&gt;,
) -&gt; Bytes {
    use std::fmt::Write;

    // On 32-bit operating systems, we might not be able to convert the u64 to a usize, so we just
    // use `String::new` in that case.
    let mut trailers = match usize::try_from(total_length_of_trailers_in_bytes) {
        Ok(total_length_of_trailers_in_bytes) =&gt; {
            String::with_capacity(total_length_of_trailers_in_bytes)
        }
        Err(_) =&gt; String::new(),
    };
    let mut already_wrote_first_trailer = false;

    if let Some(trailer_map) = trailer_map {
        for (header_name, header_value) in trailer_map.into_iter() {
            match header_name {
                // New name, new value
                Some(header_name) =&gt; {
                    if already_wrote_first_trailer {
                        // First trailer shouldn't have a preceding CRLF, but every trailer after it should
                        trailers.write_str(CRLF).unwrap();
                    } else {
                        already_wrote_first_trailer = true;
                    }

                    trailers.write_str(header_name.as_str()).unwrap();
                    trailers.write_char(':').unwrap();
                }
                // Same name, new value
                None =&gt; {
                    trailers.write_char(',').unwrap();
                }
            }
            trailers.write_str(header_value.to_str().unwrap()).unwrap();
        }
    }

    // Write CRLF to end the body
    trailers.write_str(CRLF).unwrap();
    // If we wrote at least one trailer, we need to write an extra CRLF
    if total_length_of_trailers_in_bytes != 0 {
        trailers.write_str(CRLF).unwrap();
    }

    trailers.into()
}

impl Body for AwsChunkedBody&lt;Inner&gt; {
    type Data = Bytes;
    type Error = aws_smithy_http::body::Error;

    fn poll_data(
        self: Pin&lt;&amp;mut Self&gt;,
        cx: &amp;mut Context&lt;'_&gt;,
    ) -&gt; Poll&lt;Option&lt;Result&lt;Self::Data, Self::Error&gt;&gt;&gt; {
        tracing::info!(&quot;polling AwsChunkedBody&quot;);
        let mut this = self.project();

        match *this.state {
            AwsChunkedBodyState::WritingChunkSize =&gt; match this.inner.poll_data(cx) {
                Poll::Ready(Some(Ok(data))) =&gt; {
                    // A chunk must be prefixed by chunk size in hexadecimal
                    tracing::info!(&quot;writing chunk size and start of chunk&quot;);
                    *this.state = AwsChunkedBodyState::WritingChunk;
                    let total_chunk_size = this
                        .options
                        .chunk_length
                        .or(this.options.stream_length)
                        .unwrap_or_default();
                    Poll::Ready(Some(Ok(prefix_with_chunk_size(data, total_chunk_size))))
                }
                Poll::Ready(None) =&gt; {
                    tracing::info!(&quot;chunk was empty, writing last-chunk&quot;);
                    *this.state = AwsChunkedBodyState::WritingTrailers;
                    Poll::Ready(Some(Ok(Bytes::from(&quot;0\r\n&quot;))))
                }
                Poll::Ready(Some(Err(e))) =&gt; Poll::Ready(Some(Err(e))),
                Poll::Pending =&gt; Poll::Pending,
            },
            AwsChunkedBodyState::WritingChunk =&gt; match this.inner.poll_data(cx) {
                Poll::Ready(Some(Ok(mut data))) =&gt; {
                    tracing::info!(&quot;writing rest of chunk data&quot;);
                    Poll::Ready(Some(Ok(data.copy_to_bytes(data.len()))))
                }
                Poll::Ready(None) =&gt; {
                    tracing::info!(&quot;no more chunk data, writing CRLF and last-chunk&quot;);
                    *this.state = AwsChunkedBodyState::WritingTrailers;
                    Poll::Ready(Some(Ok(Bytes::from(&quot;\r\n0\r\n&quot;))))
                }
                Poll::Ready(Some(Err(e))) =&gt; Poll::Ready(Some(Err(e))),
                Poll::Pending =&gt; Poll::Pending,
            },
            AwsChunkedBodyState::WritingTrailers =&gt; {
                return match this.inner.poll_trailers(cx) {
                    Poll::Ready(Ok(trailers)) =&gt; {
                        *this.state = AwsChunkedBodyState::Closed;
                        let total_length_of_trailers_in_bytes =
                            this.options.trailer_lens.iter().fold(0, |acc, n| acc + n);

                        Poll::Ready(Some(Ok(trailers_as_aws_chunked_bytes(
                            total_length_of_trailers_in_bytes,
                            trailers,
                        ))))
                    }
                    Poll::Pending =&gt; Poll::Pending,
                    Poll::Ready(Err(e)) =&gt; Poll::Ready(Some(Err(e))),
                };
            }
            AwsChunkedBodyState::Closed =&gt; {
                return Poll::Ready(None);
            }
        }
    }

    fn poll_trailers(
        self: Pin&lt;&amp;mut Self&gt;,
        _cx: &amp;mut Context&lt;'_&gt;,
    ) -&gt; Poll&lt;Result&lt;Option&lt;HeaderMap&lt;HeaderValue&gt;&gt;, Self::Error&gt;&gt; {
        // Trailers were already appended to the body because of the content encoding scheme
        Poll::Ready(Ok(None))
    }

    fn is_end_stream(&amp;self) -&gt; bool {
        self.state == AwsChunkedBodyState::Closed
    }

    fn size_hint(&amp;self) -&gt; SizeHint {
        SizeHint::with_exact(
            self.encoded_length()
                .expect(&quot;Requests made with aws-chunked encoding must have known size&quot;)
                as u64,
        )
    }
}

// Used for finding how many hexadecimal digits it takes to represent a base 10 integer
fn int_log16&lt;T&gt;(mut i: T) -&gt; u64
where
    T: std::ops::DivAssign + PartialOrd + From&lt;u8&gt; + Copy,
{
    let mut len = 0;
    let zero = T::from(0);
    let sixteen = T::from(16);

    while i &gt; zero {
        i /= sixteen;
        len += 1;
    }

    len
}

#[cfg(test)]
mod tests {
    use super::AwsChunkedBody;
    use crate::content_encoding::AwsChunkedBodyOptions;
    use aws_smithy_checksums::body::ChecksumBody;
    use aws_smithy_http::body::SdkBody;
    use bytes::Buf;
    use bytes_utils::SegmentedBuf;
    use http_body::Body;
    use std::io::Read;

    #[tokio::test]
    async fn test_aws_chunked_encoded_body() {
        let input_text = &quot;Hello world&quot;;
        let sdk_body = SdkBody::from(input_text);
        let checksum_body = ChecksumBody::new(sdk_body, &quot;sha256&quot;);
        let aws_chunked_body_options = AwsChunkedBodyOptions {
            stream_length: Some(input_text.len() as u64),
            chunk_length: None,
            trailer_lens: vec![
                &quot;x-amz-checksum-sha256:ZOyIygCyaOW6GjVnihtTFtIS9PNmskdyMlNKiuyjfzw=&quot;.len() as u64,
            ],
        };
        let mut aws_chunked_body = AwsChunkedBody::new(checksum_body, aws_chunked_body_options);

        let mut output = SegmentedBuf::new();
        while let Some(buf) = aws_chunked_body.data().await {
            output.push(buf.unwrap());
        }

        let mut actual_output = String::new();
        output
            .reader()
            .read_to_string(&amp;mut actual_output)
            .expect(&quot;Doesn't cause IO errors&quot;);

        let expected_output = &quot;B\r\nHello world\r\n0\r\nx-amz-checksum-sha256:ZOyIygCyaOW6GjVnihtTFtIS9PNmskdyMlNKiuyjfzw=\r\n\r\n&quot;;

        // Verify data is complete and correctly encoded
        assert_eq!(expected_output, actual_output);

        assert!(
            aws_chunked_body
                .trailers()
                .await
                .expect(&quot;checksum generation was without error&quot;)
                .is_none(),
            &quot;aws-chunked encoded bodies don't have normal HTTP trailers&quot;
        );
    }

    #[tokio::test]
    async fn test_empty_aws_chunked_encoded_body() {
        let sdk_body = SdkBody::from(&quot;&quot;);
        let checksum_body = ChecksumBody::new(sdk_body, &quot;sha256&quot;);
        let aws_chunked_body_options = AwsChunkedBodyOptions {
            stream_length: Some(0),
            chunk_length: None,
            trailer_lens: vec![
                &quot;x-amz-checksum-sha256:47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=&quot;.len() as u64,
            ],
        };
        let mut aws_chunked_body = AwsChunkedBody::new(checksum_body, aws_chunked_body_options);

        let mut output = SegmentedBuf::new();
        while let Some(buf) = aws_chunked_body.data().await {
            output.push(buf.unwrap());
        }

        let mut actual_output = String::new();
        output
            .reader()
            .read_to_string(&amp;mut actual_output)
            .expect(&quot;Doesn't cause IO errors&quot;);

        let expected_output =
            &quot;0\r\nx-amz-checksum-sha256:47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=\r\n\r\n&quot;;

        // Verify data is complete and correctly encoded
        assert_eq!(expected_output, actual_output);

        assert!(
            aws_chunked_body
                .trailers()
                .await
                .expect(&quot;checksum generation was without error&quot;)
                .is_none(),
            &quot;aws-chunked encoded bodies don't have normal HTTP trailers&quot;
        );
    }
}
<span class="boring">}
</span></code></pre></pre>
<h3 id="sigv4-update"><a class="header" href="#sigv4-update">Sigv4 Update</a></h3>
<p>When sending checksum-verified requests with a streaming body, we must update the usual signing process. Instead of signing the request based on the request body's checksum, we must sign it with a special header instead:</p>
<pre><code class="language-HTTP">Authorization: &lt;computed authorization header value using &quot;STREAMING-UNSIGNED-PAYLOAD-TRAILER&quot;&gt;
x-amz-content-sha256: STREAMING-UNSIGNED-PAYLOAD-TRAILER
</code></pre>
<p>Setting <code>STREAMING-UNSIGNED-PAYLOAD-TRAILER</code> tells the signer that we're sending an unsigned streaming body that will be followed by trailers.</p>
<p>We can achieve this by:</p>
<ul>
<li>Adding a new variant to <code>SignableBody</code>:
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// A signable HTTP request body
#[derive(Debug, Clone, Eq, PartialEq)]
#[non_exhaustive]
pub enum SignableBody&lt;'a&gt; {
    // existing variants have been omitted for brevity...

    /// An unsigned payload with trailers
    ///
    /// StreamingUnsignedPayloadTrailer is used for streaming requests where the contents of the
    /// body cannot be known prior to signing **AND** which include HTTP trailers.
    StreamingUnsignedPayloadTrailer,
}
<span class="boring">}
</span></code></pre></pre>
</li>
<li>Updating the <code>CanonicalRequest::payload_hash</code> method to include the new <code>SignableBody</code> variant:
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn payload_hash&lt;'b&gt;(body: &amp;'b SignableBody&lt;'b&gt;) -&gt; Cow&lt;'b, str&gt; {
    // Payload hash computation
    //
    // Based on the input body, set the payload_hash of the canonical request:
    // Either:
    // - compute a hash
    // - use the precomputed hash
    // - use `UnsignedPayload`
    // - use `StreamingUnsignedPayloadTrailer`
    match body {
        SignableBody::Bytes(data) =&gt; Cow::Owned(sha256_hex_string(data)),
        SignableBody::Precomputed(digest) =&gt; Cow::Borrowed(digest.as_str()),
        SignableBody::UnsignedPayload =&gt; Cow::Borrowed(UNSIGNED_PAYLOAD),
        SignableBody::StreamingUnsignedPayloadTrailer =&gt; {
            Cow::Borrowed(STREAMING_UNSIGNED_PAYLOAD_TRAILER)
        }
    }
}
<span class="boring">}
</span></code></pre></pre>
</li>
<li><em>(in generated code)</em> Inserting the <code>SignableBody</code> into the request property bag when making a checksum-verified streaming request:
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>if self.checksum_algorithm.is_some() {
    request
        .properties_mut()
        .insert(aws_sig_auth::signer::SignableBody::StreamingUnsignedPayloadTrailer);
}
<span class="boring">}
</span></code></pre></pre>
</li>
</ul>
<p>It's possible to send <code>aws-chunked</code> requests where each chunk is signed individually. Because this feature isn't strictly necessary for flexible checksums, I've avoided implementing it.</p>
<h3 id="inlineables"><a class="header" href="#inlineables">Inlineables</a></h3>
<p>In order to avoid writing lots of Rust in Kotlin, I have implemented request and response building functions as inlineables:</p>
<ul>
<li>Building checksum-validated requests with in-memory request bodies:
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// In aws/rust-runtime/aws-inlineable/src/streaming_body_with_checksum.rs
/// Given a `&amp;mut http::request::Request`, and checksum algorithm name, calculate a checksum and
/// then modify the request to include the checksum as a header.
pub fn build_checksum_validated_request(
    request: &amp;mut http::request::Request&lt;aws_smithy_http::body::SdkBody&gt;,
    checksum_algorithm: &amp;str,
) -&gt; Result&lt;(), aws_smithy_http::operation::BuildError&gt; {
    let data = request.body().bytes().unwrap_or_default();

    let mut checksum = aws_smithy_checksums::new_checksum(checksum_algorithm);
    checksum
        .update(data)
        .map_err(|err| aws_smithy_http::operation::BuildError::Other(err))?;
    let checksum = checksum
        .finalize()
        .map_err(|err| aws_smithy_http::operation::BuildError::Other(err))?;

    request.headers_mut().insert(
        aws_smithy_checksums::checksum_algorithm_to_checksum_header_name(checksum_algorithm),
        aws_smithy_types::base64::encode(&amp;checksum[..])
            .parse()
            .expect(&quot;base64-encoded checksums are always valid header values&quot;),
    );

    Ok(())
}
<span class="boring">}
</span></code></pre></pre>
</li>
<li>Building checksum-validated requests with streaming request bodies:
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// Given an `http::request::Builder`, `SdkBody`, and a checksum algorithm name, return a
/// `Request&lt;SdkBody&gt;` with checksum trailers where the content is `aws-chunked` encoded.
pub fn build_checksum_validated_request_with_streaming_body(
    request_builder: http::request::Builder,
    body: aws_smithy_http::body::SdkBody,
    checksum_algorithm: &amp;str,
) -&gt; Result&lt;http::Request&lt;aws_smithy_http::body::SdkBody&gt;, aws_smithy_http::operation::BuildError&gt; {
    use http_body::Body;

    let original_body_size = body
        .size_hint()
        .exact()
        .expect(&quot;body must be sized if checksum is requested&quot;);
    let body = aws_smithy_checksums::body::ChecksumBody::new(body, checksum_algorithm);
    let checksum_trailer_name = body.trailer_name();
    let aws_chunked_body_options = aws_http::content_encoding::AwsChunkedBodyOptions::new()
        .with_stream_length(original_body_size as usize)
        .with_trailer_len(body.trailer_length() as usize);

    let body = aws_http::content_encoding::AwsChunkedBody::new(body, aws_chunked_body_options);
    let encoded_content_length = body
        .size_hint()
        .exact()
        .expect(&quot;encoded_length must return known size&quot;);
    let request_builder = request_builder
        .header(
            http::header::CONTENT_LENGTH,
            http::HeaderValue::from(encoded_content_length),
        )
        .header(
            http::header::HeaderName::from_static(&quot;x-amz-decoded-content-length&quot;),
            http::HeaderValue::from(original_body_size),
        )
        .header(
            http::header::HeaderName::from_static(&quot;x-amz-trailer&quot;),
            checksum_trailer_name,
        )
        .header(
            http::header::CONTENT_ENCODING,
            aws_http::content_encoding::header_value::AWS_CHUNKED.as_bytes(),
        );

    let body = aws_smithy_http::body::SdkBody::from_dyn(http_body::combinators::BoxBody::new(body));

    request_builder
        .body(body)
        .map_err(|err| aws_smithy_http::operation::BuildError::Other(Box::new(err)))
}
<span class="boring">}
</span></code></pre></pre>
</li>
<li>Building checksum-validated responses:
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// Given a `Response&lt;SdkBody&gt;`, checksum algorithm name, and pre-calculated checksum, return a
/// `Response&lt;SdkBody&gt;` where the body will processed with the checksum algorithm and checked
/// against the pre-calculated checksum.
pub fn build_checksum_validated_sdk_body(
    body: aws_smithy_http::body::SdkBody,
    checksum_algorithm: &amp;str,
    precalculated_checksum: bytes::Bytes,
) -&gt; aws_smithy_http::body::SdkBody {
    let body = aws_smithy_checksums::body::ChecksumValidatedBody::new(
        body,
        checksum_algorithm,
        precalculated_checksum.clone(),
    );
    aws_smithy_http::body::SdkBody::from_dyn(http_body::combinators::BoxBody::new(body))
}

/// Given the name of a checksum algorithm and a `HeaderMap`, extract the checksum value from the
/// corresponding header as `Some(Bytes)`. If the header is unset, return `None`.
pub fn check_headers_for_precalculated_checksum(
    headers: &amp;http::HeaderMap&lt;http::HeaderValue&gt;,
) -&gt; Option&lt;(&amp;'static str, bytes::Bytes)&gt; {
    for header_name in aws_smithy_checksums::CHECKSUM_HEADERS_IN_PRIORITY_ORDER {
        if let Some(precalculated_checksum) = headers.get(&amp;header_name) {
            let checksum_algorithm =
                aws_smithy_checksums::checksum_header_name_to_checksum_algorithm(&amp;header_name);
            let precalculated_checksum =
                bytes::Bytes::copy_from_slice(precalculated_checksum.as_bytes());

            return Some((checksum_algorithm, precalculated_checksum));
        }
    }

    None
}
<span class="boring">}
</span></code></pre></pre>
</li>
</ul>
<h2 id="codegen"><a class="header" href="#codegen">Codegen</a></h2>
<p>Codegen will be updated to insert the appropriate inlineable functions for operations that are tagged with the <code>@httpchecksum</code> trait. Some operations will require an MD5 checksum fallback if the user hasn't set a checksum themselves.</p>
<p>Users also have the option of supplying a precalculated checksum of their own. This is already handled by our current header insertion logic and won't require updating the existing implementation. Because this checksum validation behavior is AWS-specific, it will be defined in SDK codegen.</p>
<h2 id="implementation-checklist"><a class="header" href="#implementation-checklist">Implementation Checklist</a></h2>
<ul>
<li><input disabled="" type="checkbox"/>
Implement codegen for building checksum-validated requests:
<ul>
<li><input disabled="" type="checkbox"/>
In-memory request bodies
<ul>
<li><input disabled="" type="checkbox"/>
Support MD5 fallback behavior for services that enable it.</li>
</ul>
</li>
<li><input disabled="" type="checkbox"/>
Streaming request bodies</li>
</ul>
</li>
<li><input disabled="" type="checkbox"/>
Implement codegen for building checksum-validated responses:</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-customizable-client-operations"><a class="header" href="#rfc-customizable-client-operations">RFC: Customizable Client Operations</a></h1>
<blockquote>
<p>Status: Accepted</p>
</blockquote>
<p>For a summarized list of proposed changes, see the <a href="rfcs/rfc0017_customizable_client_operations.html#changes-checklist">Changes Checklist</a> section.</p>
<p>SDK customers occasionally need to add additional HTTP headers to requests, and currently,
the SDK has no easy way to accomplish this. At time of writing, the lower level Smithy
client has to be used to create an operation, and then the HTTP request augmented on
that operation type. For example:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let input = SomeOperationInput::builder().some_value(5).build()?;

let operation = {
    let op = input.make_operation(&amp;service_config).await?;
    let (request, response) = op.into_request_response();

    let request = request.augment(|req, _props| {
        req.headers_mut().insert(
            HeaderName::from_static(&quot;x-some-header&quot;),
            HeaderValue::from_static(&quot;some-value&quot;)
        );
        Result::&lt;_, Infallible&gt;::Ok(req)
    })?;

    Operation::from_parts(request, response)
};

let response = smithy_client.call(operation).await?;
<span class="boring">}
</span></code></pre></pre>
<p>This approach is both difficult to discover and implement since it requires acquiring
a Smithy client rather than the generated fluent client, and it's anything but ergonomic.</p>
<p>This RFC proposes an easier way to augment requests that is compatible with the fluent
client.</p>
<h2 id="terminology-9"><a class="header" href="#terminology-9">Terminology</a></h2>
<ul>
<li><strong>Smithy Client</strong>: A <code>aws_smithy_client::Client&lt;C, M, R&gt;</code> struct that is responsible for gluing together
the connector, middleware, and retry policy.</li>
<li><strong>Fluent Client</strong>: A code generated <code>Client</code> that has methods for each service operation on it.
A fluent builder is generated alongside it to make construction easier.</li>
</ul>
<h2 id="proposal-1"><a class="header" href="#proposal-1">Proposal</a></h2>
<p>The code generated fluent builders returned by the fluent client should have a method added to them,
similar to <code>send</code>, but that returns a customizable request. The customer experience should look as
follows:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let response = client.some_operation()
    .some_value(5)
    .customize()
    .await?
    .mutate_request(|mut req| {
        req.headers_mut().insert(
            HeaderName::from_static(&quot;x-some-header&quot;),
            HeaderValue::from_static(&quot;some-value&quot;)
        );
    })
    .send()
    .await?;
<span class="boring">}
</span></code></pre></pre>
<p>This new async <code>customize</code> method would return the following:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct CustomizableOperation&lt;O, R&gt; {
    handle: Arc&lt;Handle&gt;,
    operation: Operation&lt;O, R&gt;,
}

impl&lt;O, R&gt; CustomizableOperation&lt;O, R&gt; {
    // Allows for customizing the operation's request
    fn map_request&lt;E&gt;(
        mut self,
        f: impl FnOnce(Request&lt;SdkBody&gt;) -&gt; Result&lt;Request&lt;SdkBody&gt;, E&gt;,
    ) -&gt; Result&lt;Self, E&gt; {
        let (request, response) = self.operation.into_request_response();
        let request = request.augment(|req, _props| f(req))?;
        self.operation = Operation::from_parts(request, response);
        Ok(self)
    }

    // Convenience for `map_request` where infallible direct mutation of request is acceptable
    fn mutate_request&lt;E&gt;(
        mut self,
        f: impl FnOnce(&amp;mut Request&lt;SdkBody&gt;) -&gt; (),
    ) -&gt; Self {
        self.map_request(|mut req| {
            f(&amp;mut req);
            Result::&lt;_, Infallible&gt;::Ok(req)
        }).expect(&quot;infallible&quot;);
        Ok(self)
    }

    // Allows for customizing the entire operation
    fn map_operation&lt;E&gt;(
        mut self,
        f: impl FnOnce(Operation&lt;O, R&gt;) -&gt; Result&lt;Operation&lt;O, R&gt;, E&gt;,
    ) -&gt; Result&lt;Self, E&gt; {
        self.operation = f(self.operation)?;
        Ok(self)
    }

    // Direct access to read the request
    fn request(&amp;self) -&gt; &amp;Request&lt;SdkBody&gt; {
        self.operation.request()
    }

    // Direct access to mutate the request
    fn request_mut(&amp;mut self) -&gt; &amp;mut Request&lt;SdkBody&gt; {
        self.operation.request_mut()
    }

    // Sends the operation's request
    async fn send&lt;T, E&gt;(self) -&gt; Result&lt;T, SdkError&lt;E&gt;&gt;
    where
        O: ParseHttpResponse&lt;Output = Result&lt;T, E&gt;&gt; + Send + Sync + Clone + 'static,
        E: std::error::Error,
        R: ClassifyResponse&lt;SdkSuccess&lt;T&gt;, SdkError&lt;E&gt;&gt; + Send + Sync,
    {
        self.handle.client.call(self.operation).await
    }
}
<span class="boring">}
</span></code></pre></pre>
<p>Additionally, for those who want to avoid closures, the <code>Operation</code> type will have
<code>request</code> and <code>request_mut</code> methods added to it to get direct access to its underlying
HTTP request.</p>
<p>The <code>CustomizableOperation</code> type will then mirror these functions so that the experience
can look as follows:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let mut operation = client.some_operation()
    .some_value(5)
    .customize()
    .await?;
operation.request_mut()
    .headers_mut()
    .insert(
        HeaderName::from_static(&quot;x-some-header&quot;),
        HeaderValue::from_static(&quot;some-value&quot;)
    );
let response = operation.send().await?;
<span class="boring">}
</span></code></pre></pre>
<h3 id="why-not-remove-async-from-customize-to-make-this-more-ergonomic"><a class="header" href="#why-not-remove-async-from-customize-to-make-this-more-ergonomic">Why not remove <code>async</code> from <code>customize</code> to make this more ergonomic?</a></h3>
<p>In the proposal above, customers must <code>await</code> the result of <code>customize</code> in order
to get the <code>CustomizableOperation</code>. This is a result of the underlying <code>map_operation</code>
function that <code>customize</code> needs to call being async, which was made async during
the implementation of customizations for Glacier (see #797, #801, and #1474). It
is possible to move these Glacier customizations into middleware to make <code>map_operation</code>
sync, but keeping it async is much more future-proof since if a future customization
or feature requires it to be async, it won't be a breaking change in the future.</p>
<h3 id="why-the-name-customize"><a class="header" href="#why-the-name-customize">Why the name <code>customize</code>?</a></h3>
<p>Alternatively, the name <code>build</code> could be used, but this increases the odds that
customers won't realize that they can call <code>send</code> directly, and then call a longer
<code>build</code>/<code>send</code> chain when customization isn't needed:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>client.some_operation()
    .some_value()
    .build() // Oops, didn't need to do this
    .send()
    .await?;
<span class="boring">}
</span></code></pre></pre>
<p>vs.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>client.some_operation()
    .some_value()
    .send()
    .await?;
<span class="boring">}
</span></code></pre></pre>
<p>Additionally, no AWS services at time of writing have a member named <code>customize</code>
that would conflict with the new function, so adding it would not be a breaking change.</p>
<h2 id="changes-checklist-11"><a class="header" href="#changes-checklist-11">Changes Checklist</a></h2>
<ul>
<li><input disabled="" type="checkbox"/>
Create <code>CustomizableOperation</code> as an inlinable, and code generate it into <code>client</code> so that it has access to <code>Handle</code></li>
<li><input disabled="" type="checkbox"/>
Code generate the <code>customize</code> method on fluent builders</li>
<li><input disabled="" type="checkbox"/>
Update the <code>RustReservedWords</code> class to include <code>customize</code></li>
<li><input disabled="" type="checkbox"/>
Add ability to mutate the HTTP request on <code>Operation</code></li>
<li><input disabled="" type="checkbox"/>
Add examples for both approaches</li>
<li><input disabled="" type="checkbox"/>
Comment on older discussions asking about how to do this with this improved approach</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="contributing"><a class="header" href="#contributing">Contributing</a></h1>
<p>This is a collection of written resources for smithy-rs and SDK contributors.</p>
<ul>
<li><a href="contributing/./contributing/writing_and_debugging_a_low-level_feature_that_relies_on_HTTP.html">Writing and debugging a low-level feature that relies on HTTP</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="writing-and-debugging-a-low-level-feature-that-relies-on-http"><a class="header" href="#writing-and-debugging-a-low-level-feature-that-relies-on-http">Writing and debugging a low-level feature that relies on HTTP</a></h1>
<h2 id="background"><a class="header" href="#background">Background</a></h2>
<p>This article came about as a result of all the difficulties I encountered while developing the request checksums feature
laid out in the internal-only Flexible Checksums spec <em>(the feature is also highlighted in <a href="https://aws.amazon.com/blogs/aws/new-additional-checksum-algorithms-for-amazon-s3/">this public blog post</a>.)</em>
I spent much more time developing the feature than I had anticipated. In this article, I'll talk about:</p>
<ul>
<li>How the SDK sends requests with a body</li>
<li>How the SDK sends requests with a streaming body</li>
<li>The various issues I encountered and how I addressed them</li>
<li>Key takeaways for contributors developing similar low-level features</li>
</ul>
<h2 id="how-the-sdk-sends-requests-with-a-body"><a class="header" href="#how-the-sdk-sends-requests-with-a-body">How the SDK sends requests with a body</a></h2>
<p>All interactions between the SDK and a service are modeled as <a href="contributing/../transport/operation.html">&quot;operations&quot;</a>. Operations contain:</p>
<ul>
<li>A base HTTP request (with a potentially streaming body)</li>
<li>A typed property bag of configuration options</li>
<li>A fully generic response handler</li>
</ul>
<p>Users create operations piecemeal with a fluent builder. The options set in the builder are then used to create the
inner HTTP request, becoming headers or triggering specific request-building functionality (In this case, calculating a
checksum and attaching it either as a header or a trailer.)</p>
<p>Here's <a href="https://github.com/awslabs/aws-sdk-rust/blob/1bdfba7f53e77a478f60a1a387e4d9d31fd918fc/sdk/qldbsession/src/input.rs#L197">an example from the QLDB SDK of creating a body</a> from inputs and inserting it into the request to be sent:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let body = aws_smithy_http::body::SdkBody::from(
    crate::operation_ser::serialize_operation_crate_operation_send_command(&amp;self)?,
);

if let Some(content_length) = body.content_length() {
    request = aws_smithy_http::header::set_request_header_if_absent(
        request,
        http::header::CONTENT_LENGTH,
        content_length,
    );
}
let request = request.body(body).expect(&quot;should be valid request&quot;);
<span class="boring">}
</span></code></pre></pre>
<p>Most all request body creation in the SDKs looks like that. Note how it automatically sets the <code>Content-Length</code> header
whenever the size of the body is known; It'll be relevant later. The body is read into memory and can be inspected
before the request is sent. This allows for things like calculating a checksum and then inserting it into the request
as a header.</p>
<h2 id="how-the-sdk-sends-requests-with-a-streaming-body"><a class="header" href="#how-the-sdk-sends-requests-with-a-streaming-body">How the SDK sends requests with a streaming body</a></h2>
<p>Often, sending a request with a streaming body looks much the same. However, it's not possible to read a streaming
body until you've sent the request. Any metadata that needs to be calculated by inspecting the body must be sent as
trailers. Additionally, some metadata, like <code>Content-Length</code>, can't be sent as a trailer at all.
<a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Trailer#directives">MDN maintains a helpful list</a> of metadata that can only be sent as a header.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// When trailers are set, we must send an AWS-specific header that lists them named `x-amz-trailer`.
// For example, when sending a SHA256 checksum as a trailer,
// we have to send an `x-amz-trailer` header telling the service to watch out for it:
request
    .headers_mut()
    .insert(
        http::header::HeaderName::from_static(&quot;x-amz-trailer&quot;),
        http::header::HeaderValue::from_static(&quot;x-amz-checksum-sha256&quot;),
    );
<span class="boring">}
</span></code></pre></pre>
<h2 id="the-issues-i-encountered-while-implementing-checksums-for-streaming-request-bodies"><a class="header" href="#the-issues-i-encountered-while-implementing-checksums-for-streaming-request-bodies">The issues I encountered while implementing checksums for streaming request bodies</a></h2>
<h3 id="content-encoding-aws-chunked"><a class="header" href="#content-encoding-aws-chunked"><code>Content-Encoding: aws-chunked</code></a></h3>
<p>When sending a request body with trailers, we must use an AWS-specific content encoding called <code>aws-chunked</code>. To encode
a request body for <code>aws-chunked</code> requires us to know the length of each chunk we're going to send before we send it. We
have to prefix each chunk with its size in bytes, represented by one or more <a href="https://en.wikipedia.org/wiki/Hexadecimal">hexadecimal</a> digits. To close the body, we
send a final chunk with a zero. For example, the body &quot;Hello world&quot; would look like this when encoded:</p>
<pre><code>B\r\n
Hello world\r\n
0\r\n
</code></pre>
<p>When sending a request body encoded in this way, we need to set two length headers:</p>
<ul>
<li><code>Content-Length</code> is the length of the entire request body, including the chunk size prefix and zero terminator. In the
example above, this would be 19.</li>
<li><code>x-amz-decoded-content-length</code> is the length of the decoded request body. In the example above, this would be 11.</li>
</ul>
<p><em><strong>NOTE:</strong> <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Encoding"><code>Content-Encoding</code></a> is distinct from <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Transfer-Encoding"><code>Transfer-Encoding</code></a>. It's possible to
construct a request with both <code>Content-Encoding: chunked</code> AND <code>Transfer-Encoding: chunked</code>, although we don't ever need
to do that for SDK requests.</em></p>
<h3 id="s3-requires-a-content-length-unless-you-also-set-transfer-encoding-chunked"><a class="header" href="#s3-requires-a-content-length-unless-you-also-set-transfer-encoding-chunked">S3 requires a <code>Content-Length</code> unless you also set <code>Transfer-Encoding: chunked</code></a></h3>
<p>S3 does not require you to send a <code>Content-Length</code> header if you set the <code>Transfer-Encoding: chunked</code> header. That's
very helpful because it's not always possible to know the total length of a stream of bytes if that's what you're
constructing your request body from. However, when sending trailers, this part of the spec can be misleading.</p>
<ol>
<li>When sending a streaming request, we must send metadata like checksums as trailers</li>
<li>To send a request body with trailers, we must set the <code>Content-Encoding: aws-chunked</code> header</li>
<li>When using <code>aws-chunked</code> encoding for a request body, we must set the <code>x-amz-decoded-content-length</code> header with the
pre-encoding length of the request body.</li>
</ol>
<p>This means that we can't actually avoid having to know and specify the length of the request body when sending a request
to S3. This turns out to not be much of a problem for common use of the SDKs because most streaming request bodies are
constructed from files. In these cases we can ask the operating system for the file size before sending the request. So
long as that size doesn't change during sending of the request, all is well. In any other case, the request will fail.</p>
<h3 id="adding-trailers-to-a-request-changes-the-size-of-that-request"><a class="header" href="#adding-trailers-to-a-request-changes-the-size-of-that-request">Adding trailers to a request changes the size of that request</a></h3>
<p>Headers don't count towards the size of a request body, but trailers do. That means we need to take trailers (which
aren't sent until after the body) into account when setting the <code>Content-Length</code> header (which are sent before the
body.) This means that without setting <code>Transfer-Encoding: chunked</code>, the SDKs only support trailers of known length.
In the case of checksums, we're lucky because they're always going to be the same size. We must also take into account
the fact that checksum values are base64 encoded before being set (this lengthens them.)</p>
<h3 id="hyper-supports-http-request-trailers-but-isnt-compatible-with-content-encoding-aws-chunked"><a class="header" href="#hyper-supports-http-request-trailers-but-isnt-compatible-with-content-encoding-aws-chunked"><code>hyper</code> supports HTTP request trailers but isn't compatible with <code>Content-Encoding: aws-chunked</code></a></h3>
<p>This was a big source of confusion for me, and I only figured out what was happening with the help of <a href="https://github.com/seanmonstar">@seanmonstar</a>.
When using <code>aws-chunked</code> encoding, the trailers have to be appended to the body as part of <code>poll_data</code> instead of
relying on the <code>poll_trailers</code> method. The working <code>http_body::Body</code> implementation of an <code>aws-chunked</code> encoded body
looked like this:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl Body for AwsChunkedBody&lt;Inner&gt; {
    type Data = Bytes;
    type Error = aws_smithy_http::body::Error;

    fn poll_data(
        self: Pin&lt;&amp;mut Self&gt;,
        cx: &amp;mut Context&lt;'_&gt;,
    ) -&gt; Poll&lt;Option&lt;Result&lt;Self::Data, Self::Error&gt;&gt;&gt; {
        let this = self.project();
        if *this.already_wrote_trailers {
            return Poll::Ready(None);
        }

        if *this.already_wrote_chunk_terminator {
            return match this.inner.poll_trailers(cx) {
                Poll::Ready(Ok(trailers)) =&gt; {
                    *this.already_wrote_trailers = true;
                    let total_length_of_trailers_in_bytes = this.options.trailer_lens.iter().sum();

                    Poll::Ready(Some(Ok(trailers_as_aws_chunked_bytes(
                        total_length_of_trailers_in_bytes,
                        trailers,
                    ))))
                }
                Poll::Pending =&gt; Poll::Pending,
                Poll::Ready(err) =&gt; Poll::Ready(Some(err)),
            };
        };

        match this.inner.poll_data(cx) {
            Poll::Ready(Some(Ok(mut data))) =&gt; {
                let bytes = if *this.already_wrote_chunk_size_prefix {
                    data.copy_to_bytes(data.len())
                } else {
                    // A chunk must be prefixed by chunk size in hexadecimal
                    *this.already_wrote_chunk_size_prefix = true;
                    let total_chunk_size = this
                        .options
                        .chunk_length
                        .or(this.options.stream_length)
                        .unwrap_or_default();
                    prefix_with_total_chunk_size(data, total_chunk_size)
                };

                Poll::Ready(Some(Ok(bytes)))
            }
            Poll::Ready(None) =&gt; {
                *this.already_wrote_chunk_terminator = true;
                Poll::Ready(Some(Ok(Bytes::from(&quot;\r\n0\r\n&quot;))))
            }
            Poll::Ready(Some(Err(e))) =&gt; Poll::Ready(Some(Err(e))),
            Poll::Pending =&gt; Poll::Pending,
        }
    }

    fn poll_trailers(
        self: Pin&lt;&amp;mut Self&gt;,
        _cx: &amp;mut Context&lt;'_&gt;,
    ) -&gt; Poll&lt;Result&lt;Option&lt;HeaderMap&lt;HeaderValue&gt;&gt;, Self::Error&gt;&gt; {
        // When using aws-chunked content encoding, trailers have to be appended to the body
        Poll::Ready(Ok(None))
    }

    fn is_end_stream(&amp;self) -&gt; bool {
        self.already_wrote_trailers
    }

    fn size_hint(&amp;self) -&gt; SizeHint {
        SizeHint::with_exact(
            self.encoded_length()
                .expect(&quot;Requests made with aws-chunked encoding must have known size&quot;)
                as u64,
        )
    }
}
<span class="boring">}
</span></code></pre></pre>
<h3 id="the-stream-is-closing-early-and-i-dont-know-why"><a class="header" href="#the-stream-is-closing-early-and-i-dont-know-why">&quot;The stream is closing early, and I don't know why&quot;</a></h3>
<p>In my early implementation of <code>http_body::Body</code> for an <code>aws-chunked</code> encoded body, the body wasn't being completely read
out. The problem turned out to be that I was delegating to the <code>is_end_stream</code> trait method of the inner body. Because
the innermost body had no knowledge of the trailers I needed to send, it was reporting that the stream had ended.
The fix was to instead rely on the outermost body's knowledge of its own state in order to determine if all data had
been read.</p>
<h2 id="what-helped-me-to-understand-the-problems-and-their-solutions"><a class="header" href="#what-helped-me-to-understand-the-problems-and-their-solutions">What helped me to understand the problems and their solutions</a></h2>
<ul>
<li>
<p><strong>Reaching out to others that had specific knowledge of a problem:</strong> Talking to a developer that had tackled this
feature for another SDK was a big help. Special thanks is due to <a href="https://github.com/jasdel">@jasdel</a> and the Go v2 SDK team.
<a href="https://github.com/aws/aws-sdk-go-v2/blob/c214cb61990441aa165e216a3f7e845c50d21939/service/internal/checksum/aws_chunked_encoding.go#L90">Their implementation</a> of an <code>aws-chunked</code> encoded body was the basis for
my own implementation.</p>
</li>
<li>
<p><strong>Avoiding codegen</strong>: The process of updating codegen code and then running codegen for each new change you make is
slow compared to running codegen once at the beginning of development and then just manually editing the generated SDK
as necessary. I still needed to run <code>./gradlew :aws:sdk:relocateAwsRuntime :aws:sdk:relocateRuntime</code> whenever I made
changes to a runtime crate but that was quick because it's just copying the files. Keep as much code out of codegen as
possible. It's much easier to modify/debug Rust than it is to write a working codegen module that does the same thing.
Whenever possible, write the codegen modules later, once the design has settled.</p>
</li>
<li>
<p><strong>Using the <code>Display</code> impl for errors:</strong> The <code>Display</code> impl for an error can ofter contain helpful info that might not
be visible when printing with the <code>Debug</code> impl. Case in point was an error I was getting because of the
<code>is_end_stream</code> issue. When <code>Debug</code> printed, the error looked like this:</p>
<pre><code>DispatchFailure(ConnectorError { err: hyper::Error(User(Body), hyper::Error(BodyWriteAborted)), kind: User })
</code></pre>
<p>That wasn't too helpful for me on its own. I looked into the <code>hyper</code> source code and found that the <code>Display</code> impl
contained a helpful message, so I matched into the error and printed the <code>hyper::Error</code> with the <code>Display</code> impl:</p>
<pre><code>user body write aborted: early end, expected 2 more bytes'
</code></pre>
<p>This helped me understand that I wasn't encoding things correctly and was missing a CRLF.</p>
</li>
<li>
<p><strong>Echo Server</strong>: I first used netcat and then later a small echo server written in Rust to see the raw HTTP request
being sent out by the SDK as I was working on it. The Rust SDK supports setting endpoints for request. This is often
used to send requests to something like <a href="https://localstack.cloud/">LocalStack</a>, but I used it to send request to <code>localhost</code> instead:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[tokio::test]
async fn test_checksum_on_streaming_request_against_s3() {
    let sdk_config = aws_config::from_env()
        .endpoint_resolver(Endpoint::immutable(&quot;http://localhost:8080&quot;.parse().expect(&quot;valid URI&quot;)))
        .load().await;
    let s3_client = aws_sdk_s3::Client::new(&amp;sdk_config);

    let input_text = b&quot;Hello world&quot;;
    let _res = s3_client
        .put_object()
        .bucket(&quot;some-real-bucket&quot;)
        .key(&quot;test.txt&quot;)
        .body(aws_sdk_s3::types::ByteStream::from_static(input_text))
        .checksum_algorithm(ChecksumAlgorithm::Sha256)
        .send()
        .await
        .unwrap();
}
<span class="boring">}
</span></code></pre></pre>
<p>The echo server was based off of an <a href="https://github.com/tokio-rs/axum">axum</a> example and looked like this:</p>
<pre><pre class="playground"><code class="language-rust">use axum::{
  body::{Body, Bytes},
  http::{request::Parts, Request, StatusCode},
  middleware::{self, Next},
  response::IntoResponse,
  routing::put,
  Router,
};
use std::net::SocketAddr;
use tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt};

#[tokio::main]
async fn main() {
  tracing_subscriber::registry().with(tracing_subscriber::EnvFilter::new(
    std::env::var(&quot;RUST_LOG&quot;).unwrap_or_else(|_| &quot;trace&quot;.into()),
  ))
  .with(tracing_subscriber::fmt::layer())
  .init();

  let app = Router::new()
      .route(&quot;/&quot;, put(|| async move { &quot;200 OK&quot; }))
      .layer(middleware::from_fn(print_request_response));

  let addr = SocketAddr::from(([127, 0, 0, 1], 3000));
  tracing::debug!(&quot;listening on {}&quot;, addr);
  axum::Server::bind(&amp;addr)
      .serve(app.into_make_service())
      .await
      .unwrap();
}

async fn print_request_response(
  req: Request&lt;Body&gt;,
  next: Next&lt;Body&gt;,
) -&gt; Result&lt;impl IntoResponse, (StatusCode, String)&gt; {
    let (parts, body) = req.into_parts();

    print_parts(&amp;parts).await;
    let bytes = buffer_and_print(&quot;request&quot;, body).await?;
    let req = Request::from_parts(parts, Body::from(bytes));

    let res = next.run(req).await;

    Ok(res)
}

async fn print_parts(parts: &amp;Parts) {
    tracing::debug!(&quot;{:#?}&quot;, parts);
}

async fn buffer_and_print&lt;B&gt;(direction: &amp;str, body: B) -&gt; Result&lt;Bytes, (StatusCode, String)&gt;
where
  B: axum::body::HttpBody&lt;Data = Bytes&gt;,
  B::Error: std::fmt::Display,
{
    let bytes = match hyper::body::to_bytes(body).await {
        Ok(bytes) =&gt; bytes,
        Err(err) =&gt; {
            return Err((
                StatusCode::BAD_REQUEST,
                format!(&quot;failed to read {} body: {}&quot;, direction, err),
            ));
        }
    };

    if let Ok(body) = std::str::from_utf8(&amp;bytes) {
        tracing::debug!(&quot;{} body = {:?}&quot;, direction, body);
    }

    Ok(bytes)
}
</code></pre></pre>
<h2 id=""><a class="header" href="#"></a></h2>
</li>
</ul>
<p>](writing_and_debugging_a_low-level_feature_that_relies_on_HTTP.md)</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script type="text/javascript">
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        <script type="text/javascript" src="static/mermaid.min.js"></script>
        <script type="text/javascript" src="static/mermaid-init.js"></script>

        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </body>
</html>
