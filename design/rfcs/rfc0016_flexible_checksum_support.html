<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>RFC-0016: Supporting Flexible Checksums - AWS Rust SDK Design</title>


        <!-- Custom HTML head -->
        
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../highlight.css">
        <link rel="stylesheet" href="../tomorrow-night.css">
        <link rel="stylesheet" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->

    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="../overview.html"><strong aria-hidden="true">1.</strong> Design Overview</a></li><li class="chapter-item expanded "><a href="../tenets.html"><strong aria-hidden="true">2.</strong> Tenets</a></li><li class="chapter-item expanded "><a href="../faq.html"><strong aria-hidden="true">3.</strong> Design FAQ</a></li><li class="chapter-item expanded "><a href="../transport/overview.html"><strong aria-hidden="true">4.</strong> Transport</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../transport/operation.html"><strong aria-hidden="true">4.1.</strong> HTTP Operations</a></li><li class="chapter-item expanded "><a href="../transport/middleware.html"><strong aria-hidden="true">4.2.</strong> HTTP Middleware</a></li></ol></li><li class="chapter-item expanded "><a href="../smithy/overview.html"><strong aria-hidden="true">5.</strong> Smithy</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../smithy/simple_shapes.html"><strong aria-hidden="true">5.1.</strong> Simple Shapes</a></li><li class="chapter-item expanded "><a href="../smithy/recursive_shapes.html"><strong aria-hidden="true">5.2.</strong> Recursive Shapes</a></li><li class="chapter-item expanded "><a href="../smithy/aggregate_shapes.html"><strong aria-hidden="true">5.3.</strong> Aggregate Shapes</a></li><li class="chapter-item expanded "><a href="../smithy/endpoint.html"><strong aria-hidden="true">5.4.</strong> Endpoint Resolution</a></li><li class="chapter-item expanded "><a href="../smithy/backwards-compat.html"><strong aria-hidden="true">5.5.</strong> Backwards Compatibility</a></li></ol></li><li class="chapter-item expanded "><a href="../rfcs/overview.html"><strong aria-hidden="true">6.</strong> RFCs</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../rfcs/rfc0001_shared_config.html"><strong aria-hidden="true">6.1.</strong> RFC-0001: Sharing configuration between multiple clients</a></li><li class="chapter-item expanded "><a href="../rfcs/rfc0002_http_versions.html"><strong aria-hidden="true">6.2.</strong> RFC-0002: Supporting multiple HTTP versions for SDKs that use Event Stream</a></li><li class="chapter-item expanded "><a href="../rfcs/rfc0003_presigning_api.html"><strong aria-hidden="true">6.3.</strong> RFC-0003: API for Pre-signed URLs</a></li><li class="chapter-item expanded "><a href="../rfcs/rfc0004_retry_behavior.html"><strong aria-hidden="true">6.4.</strong> RFC-0004: Retry Behavior</a></li><li class="chapter-item expanded "><a href="../rfcs/rfc0005_service_generation.html"><strong aria-hidden="true">6.5.</strong> RFC-0005: Smithy Rust service framework</a></li><li class="chapter-item expanded "><a href="../rfcs/rfc0006_service_specific_middleware.html"><strong aria-hidden="true">6.6.</strong> RFC-0006: Service-specific middleware</a></li><li class="chapter-item expanded "><a href="../rfcs/rfc0007_split_release_process.html"><strong aria-hidden="true">6.7.</strong> RFC-0007: Split release process</a></li><li class="chapter-item expanded "><a href="../rfcs/rfc0008_paginators.html"><strong aria-hidden="true">6.8.</strong> RFC-0008: Paginators</a></li><li class="chapter-item expanded "><a href="../rfcs/rfc0009_example_consolidation.html"><strong aria-hidden="true">6.9.</strong> RFC-0009: Example Consolidation</a></li><li class="chapter-item expanded "><a href="../rfcs/rfc0010_waiters.html"><strong aria-hidden="true">6.10.</strong> RFC-0010: Waiters</a></li><li class="chapter-item expanded "><a href="../rfcs/rfc0011_crates_io_alpha_publishing.html"><strong aria-hidden="true">6.11.</strong> RFC-0011: Publishing Alpha to Crates.io</a></li><li class="chapter-item expanded "><a href="../rfcs/rfc0012_independent_crate_versioning.html"><strong aria-hidden="true">6.12.</strong> RFC-0012: Independent Crate Versioning</a></li><li class="chapter-item expanded "><a href="../rfcs/rfc0013_body_callback_apis.html"><strong aria-hidden="true">6.13.</strong> RFC-0013: Body Callback APIs</a></li><li class="chapter-item expanded "><a href="../rfcs/rfc0014_timeout_config.html"><strong aria-hidden="true">6.14.</strong> RFC-0014: Fine-grained timeout configuration</a></li><li class="chapter-item expanded "><a href="../rfcs/rfc0015_using_features_responsibly.html"><strong aria-hidden="true">6.15.</strong> RFC-0015: How Cargo "features" should be used in the SDK and runtime crates</a></li><li class="chapter-item expanded "><a href="../rfcs/rfc0016_flexible_checksum_support.html" class="active"><strong aria-hidden="true">6.16.</strong> RFC-0016: Supporting Flexible Checksums</a></li><li class="chapter-item expanded "><a href="../rfcs/rfc0017_customizable_client_operations.html"><strong aria-hidden="true">6.17.</strong> RFC-0017: Customizable Client Operations</a></li><li class="chapter-item expanded "><a href="../rfcs/rfc0018_logging_sensitive.html"><strong aria-hidden="true">6.18.</strong> RFC-0018: Logging in the Presence of Sensitive Data</a></li><li class="chapter-item expanded "><a href="../rfcs/rfc0019_event_streams_errors.html"><strong aria-hidden="true">6.19.</strong> RFC-0019: Event Streams Errors</a></li></ol></li><li class="chapter-item expanded "><a href="../contributing/overview.html"><strong aria-hidden="true">7.</strong> Contributing</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../contributing/writing_and_debugging_a_low-level_feature_that_relies_on_HTTP.html"><strong aria-hidden="true">7.1.</strong> Writing and debugging a low-level feature that relies on HTTP</a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">AWS Rust SDK Design</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="rfc-supporting-flexible-checksums"><a class="header" href="#rfc-supporting-flexible-checksums">RFC: Supporting Flexible Checksums</a></h1>
<blockquote>
<p>Status: Implemented</p>
</blockquote>
<p>We can't currently update the S3 SDK because we don't support the new &quot;Flexible Checksums&quot; feature. This RFC describes this new feature and details how we should implement it in <code>smithy-rs</code>.</p>
<h2 id="what-is-the-flexible-checksums-feature"><a class="header" href="#what-is-the-flexible-checksums-feature">What is the &quot;Flexible Checksums&quot; feature?</a></h2>
<p>S3 has previously supported MD5 checksum validation of data. Now, it supports more checksum algorithms like CRC32, CRC32C, SHA-1, and SHA-256. This validation is available when putting objects to S3 and when getting them from S3. For more information, see <a href="https://aws.amazon.com/blogs/aws/new-additional-checksum-algorithms-for-amazon-s3/">this AWS News Blog post</a>.</p>
<h2 id="implementing-checksums"><a class="header" href="#implementing-checksums">Implementing Checksums</a></h2>
<p>Checksum callbacks were introduced as a result of the acceptance of <a href="./rfc0013_body_callback_apis.html">RFC0013</a> and this RFC proposes a refactor to those callbacks, as well as several new wrappers for <code>SdkBody</code> that will provide new functionality.</p>
<h3 id="refactoring-aws-smithy-checksums"><a class="header" href="#refactoring-aws-smithy-checksums">Refactoring aws-smithy-checksums</a></h3>
<p>TLDR; This refactor of aws-smithy-checksums:</p>
<ul>
<li>
<p><strong>Removes the &quot;callback&quot; terminology:</strong> As a word, &quot;callback&quot; doesn't carry any useful information, and doesn't aid in understanding.</p>
</li>
<li>
<p><strong>Removes support for the <code>BodyCallback</code> API:</strong> Instead of adding checksum callbacks to a body, we're going to use a &quot;body wrapping&quot; instead. &quot;Body wrapping&quot; is demonstrated in the <a href="#checksumbody"><code>ChecksumBody</code></a>, <a href="#awschunkedbody-and-awschunkedbodyoptions"><code>AwsChunkedBody</code></a>, and <a href="#checksumvalidatedbody"><code>ChecksumValidatedBody</code></a> sections.</p>
<p><em>NOTE: This doesn't remove the <code>BodyCallback</code> trait. That will still exist, we just won't use it.</em></p>
</li>
<li>
<p><strong>Updates terminology to focus on &quot;headers&quot; instead of &quot;trailers&quot;:</strong> Because the types we deal with in this module are named for HTTP headers, I chose to use that terminology instead. My hope is that this will be less strange to people reading this code.</p>
</li>
<li>
<p><strong>Adds <code>fn checksum_algorithm_to_checksum_header_name</code>:</strong> a function that's used in generated code to set a checksum request header.</p>
</li>
<li>
<p><strong>Adds <code>fn checksum_header_name_to_checksum_algorithm</code>:</strong> a function that's used in generated code when creating a checksum-validating response body.</p>
</li>
<li>
<p><strong>Add new checksum-related &quot;body wrapping&quot; HTTP body types</strong>: These are defined in the <code>body</code> module and will be shown later in this RFC.</p>
</li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// In aws-smithy-checksums/src/lib.rs
//! Checksum calculation and verification callbacks

use aws_smithy_types::base64;

use bytes::Bytes;
use http::header::{HeaderMap, HeaderName, HeaderValue};
use sha1::Digest;
use std::io::Write;

pub mod body;

// Valid checksum algorithm names
pub const CRC_32_NAME: &amp;str = &quot;crc32&quot;;
pub const CRC_32_C_NAME: &amp;str = &quot;crc32c&quot;;
pub const SHA_1_NAME: &amp;str = &quot;sha1&quot;;
pub const SHA_256_NAME: &amp;str = &quot;sha256&quot;;

pub const CRC_32_HEADER_NAME: HeaderName = HeaderName::from_static(&quot;x-amz-checksum-crc32&quot;);
pub const CRC_32_C_HEADER_NAME: HeaderName = HeaderName::from_static(&quot;x-amz-checksum-crc32c&quot;);
pub const SHA_1_HEADER_NAME: HeaderName = HeaderName::from_static(&quot;x-amz-checksum-sha1&quot;);
pub const SHA_256_HEADER_NAME: HeaderName = HeaderName::from_static(&quot;x-amz-checksum-sha256&quot;);

// Preserved for compatibility purposes. This should never be used by users, only within smithy-rs
const MD5_NAME: &amp;str = &quot;md5&quot;;
const MD5_HEADER_NAME: HeaderName = HeaderName::from_static(&quot;content-md5&quot;);

/// Given a `&amp;str` representing a checksum algorithm, return the corresponding `HeaderName`
/// for that checksum algorithm.
pub fn checksum_algorithm_to_checksum_header_name(checksum_algorithm: &amp;str) -&gt; HeaderName {
    if checksum_algorithm.eq_ignore_ascii_case(CRC_32_NAME) {
        CRC_32_HEADER_NAME
    } else if checksum_algorithm.eq_ignore_ascii_case(CRC_32_C_NAME) {
        CRC_32_C_HEADER_NAME
    } else if checksum_algorithm.eq_ignore_ascii_case(SHA_1_NAME) {
        SHA_1_HEADER_NAME
    } else if checksum_algorithm.eq_ignore_ascii_case(SHA_256_NAME) {
        SHA_256_HEADER_NAME
    } else if checksum_algorithm.eq_ignore_ascii_case(MD5_NAME) {
        MD5_HEADER_NAME
    } else {
        // TODO what's the best way to handle this case?
        HeaderName::from_static(&quot;x-amz-checksum-unknown&quot;)
    }
}

/// Given a `HeaderName` representing a checksum algorithm, return the name of that algorithm
/// as a `&amp;'static str`.
pub fn checksum_header_name_to_checksum_algorithm(
    checksum_header_name: &amp;HeaderName,
) -&gt; &amp;'static str {
    if checksum_header_name == CRC_32_HEADER_NAME {
        CRC_32_NAME
    } else if checksum_header_name == CRC_32_C_HEADER_NAME {
        CRC_32_C_NAME
    } else if checksum_header_name == SHA_1_HEADER_NAME {
        SHA_1_NAME
    } else if checksum_header_name == SHA_256_HEADER_NAME {
        SHA_256_NAME
    } else if checksum_header_name == MD5_HEADER_NAME {
        MD5_NAME
    } else {
        // TODO what's the best way to handle this case?
        &quot;unknown-checksum-algorithm&quot;
    }
}

/// When a response has to be checksum-verified, we have to check possible headers until we find the
/// header with the precalculated checksum. Because a service may send back multiple headers, we have
/// to check them in order based on how fast each checksum is to calculate.
pub const CHECKSUM_HEADERS_IN_PRIORITY_ORDER: [HeaderName; 4] = [
    CRC_32_C_HEADER_NAME,
    CRC_32_HEADER_NAME,
    SHA_1_HEADER_NAME,
    SHA_256_HEADER_NAME,
];

type BoxError = Box&lt;dyn std::error::Error + Send + Sync&gt;;

/// Checksum algorithms are use to validate the integrity of data. Structs that implement this trait
/// can be used as checksum calculators. This trait requires Send + Sync because these checksums are
/// often used in a threaded context.
pub trait Checksum: Send + Sync {
    /// Given a slice of bytes, update this checksum's internal state.
    fn update(&amp;mut self, bytes: &amp;[u8]) -&gt; Result&lt;(), BoxError&gt;;
    /// Either return this checksum as a `HeaderMap` containing one HTTP header, or return an error
    /// describing why checksum calculation failed.
    fn headers(&amp;self) -&gt; Result&lt;Option&lt;HeaderMap&lt;HeaderValue&gt;&gt;, BoxError&gt;;
    /// Return the `HeaderName` used to represent this checksum algorithm
    fn header_name(&amp;self) -&gt; HeaderName;
    /// &quot;Finalize&quot; this checksum, returning the calculated value as `Bytes` or an error that
    /// occurred during checksum calculation. To print this value in a human-readable hexadecimal
    /// format, you can print it using Rust's builtin [formatter].
    ///
    /// _**NOTE:** typically, &quot;finalizing&quot; a checksum in Rust will take ownership of the checksum
    /// struct. In this method, we clone the checksum's state before finalizing because checksums
    /// may be used in a situation where taking ownership is not possible._
    ///
    /// [formatter]: https://doc.rust-lang.org/std/fmt/trait.UpperHex.html
    fn finalize(&amp;self) -&gt; Result&lt;Bytes, BoxError&gt;;
    /// Return the size of this checksum algorithms resulting checksum, in bytes. For example, the
    /// CRC32 checksum algorithm calculates a 32 bit checksum, so a CRC32 checksum struct
    /// implementing this trait method would return 4.
    fn size(&amp;self) -&gt; u64;
}

/// Create a new `Box&lt;dyn Checksum&gt;` from an algorithm name. Valid algorithm names are defined as
/// `const`s in this module.
pub fn new_checksum(checksum_algorithm: &amp;str) -&gt; Box&lt;dyn Checksum&gt; {
    if checksum_algorithm.eq_ignore_ascii_case(CRC_32_NAME) {
        Box::new(Crc32::default())
    } else if checksum_algorithm.eq_ignore_ascii_case(CRC_32_C_NAME) {
        Box::new(Crc32c::default())
    } else if checksum_algorithm.eq_ignore_ascii_case(SHA_1_NAME) {
        Box::new(Sha1::default())
    } else if checksum_algorithm.eq_ignore_ascii_case(SHA_256_NAME) {
        Box::new(Sha256::default())
    } else if checksum_algorithm.eq_ignore_ascii_case(MD5_NAME) {
        // It's possible to create an MD5 and we do this in some situations for compatibility.
        // We deliberately hide this from users so that they don't go using it.
        Box::new(Md5::default())
    } else {
        panic!(&quot;unsupported checksum algorithm '{}'&quot;, checksum_algorithm)
    }
}

#[derive(Debug, Default)]
struct Crc32 {
    hasher: crc32fast::Hasher,
}

impl Crc32 {
    fn update(&amp;mut self, bytes: &amp;[u8]) -&gt; Result&lt;(), BoxError&gt; {
        self.hasher.update(bytes);

        Ok(())
    }

    fn headers(&amp;self) -&gt; Result&lt;Option&lt;HeaderMap&lt;HeaderValue&gt;&gt;, BoxError&gt; {
        let mut header_map = HeaderMap::new();
        header_map.insert(Self::header_name(), self.header_value());

        Ok(Some(header_map))
    }

    fn finalize(&amp;self) -&gt; Result&lt;Bytes, BoxError&gt; {
        Ok(Bytes::copy_from_slice(
            &amp;self.hasher.clone().finalize().to_be_bytes(),
        ))
    }

    // Size of the checksum in bytes
    fn size() -&gt; u64 {
        4
    }

    fn header_name() -&gt; HeaderName {
        CRC_32_HEADER_NAME
    }

    fn header_value(&amp;self) -&gt; HeaderValue {
        // We clone the hasher because `Hasher::finalize` consumes `self`
        let hash = self.hasher.clone().finalize();
        HeaderValue::from_str(&amp;base64::encode(u32::to_be_bytes(hash)))
            .expect(&quot;will always produce a valid header value from a CRC32 checksum&quot;)
    }
}

impl Checksum for Crc32 {
    fn update(
        &amp;mut self,
        bytes: &amp;[u8],
    ) -&gt; Result&lt;(), Box&lt;(dyn std::error::Error + Send + Sync + 'static)&gt;&gt; {
        Self::update(self, bytes)
    }
    fn headers(
        &amp;self,
    ) -&gt; Result&lt;Option&lt;HeaderMap&gt;, Box&lt;(dyn std::error::Error + Send + Sync + 'static)&gt;&gt; {
        Self::headers(self)
    }
    fn header_name(&amp;self) -&gt; HeaderName {
        Self::header_name()
    }
    fn finalize(&amp;self) -&gt; Result&lt;Bytes, BoxError&gt; {
        Self::finalize(self)
    }
    fn size(&amp;self) -&gt; u64 {
        Self::size()
    }
}

#[derive(Debug, Default)]
struct Crc32c {
    state: Option&lt;u32&gt;,
}

impl Crc32c {
    fn update(&amp;mut self, bytes: &amp;[u8]) -&gt; Result&lt;(), BoxError&gt; {
        self.state = match self.state {
            Some(crc) =&gt; Some(crc32c::crc32c_append(crc, bytes)),
            None =&gt; Some(crc32c::crc32c(bytes)),
        };

        Ok(())
    }

    fn headers(&amp;self) -&gt; Result&lt;Option&lt;HeaderMap&lt;HeaderValue&gt;&gt;, BoxError&gt; {
        let mut header_map = HeaderMap::new();
        header_map.insert(Self::header_name(), self.header_value());

        Ok(Some(header_map))
    }

    fn finalize(&amp;self) -&gt; Result&lt;Bytes, BoxError&gt; {
        Ok(Bytes::copy_from_slice(
            &amp;self.state.unwrap_or_default().to_be_bytes(),
        ))
    }

    // Size of the checksum in bytes
    fn size() -&gt; u64 {
        4
    }

    fn header_name() -&gt; HeaderName {
        CRC_32_C_HEADER_NAME
    }

    fn header_value(&amp;self) -&gt; HeaderValue {
        // If no data was provided to this callback and no CRC was ever calculated, return zero as the checksum.
        let hash = self.state.unwrap_or_default();
        HeaderValue::from_str(&amp;base64::encode(u32::to_be_bytes(hash)))
            .expect(&quot;will always produce a valid header value from a CRC32C checksum&quot;)
    }
}

impl Checksum for Crc32c {
    fn update(
        &amp;mut self,
        bytes: &amp;[u8],
    ) -&gt; Result&lt;(), Box&lt;(dyn std::error::Error + Send + Sync + 'static)&gt;&gt; {
        Self::update(self, bytes)
    }
    fn headers(
        &amp;self,
    ) -&gt; Result&lt;Option&lt;HeaderMap&gt;, Box&lt;(dyn std::error::Error + Send + Sync + 'static)&gt;&gt; {
        Self::headers(self)
    }
    fn header_name(&amp;self) -&gt; HeaderName {
        Self::header_name()
    }
    fn finalize(&amp;self) -&gt; Result&lt;Bytes, BoxError&gt; {
        Self::finalize(self)
    }
    fn size(&amp;self) -&gt; u64 {
        Self::size()
    }
}

#[derive(Debug, Default)]
struct Sha1 {
    hasher: sha1::Sha1,
}

impl Sha1 {
    fn update(&amp;mut self, bytes: &amp;[u8]) -&gt; Result&lt;(), BoxError&gt; {
        self.hasher.write_all(bytes)?;

        Ok(())
    }

    fn headers(&amp;self) -&gt; Result&lt;Option&lt;HeaderMap&lt;HeaderValue&gt;&gt;, BoxError&gt; {
        let mut header_map = HeaderMap::new();
        header_map.insert(Self::header_name(), self.header_value());

        Ok(Some(header_map))
    }

    fn finalize(&amp;self) -&gt; Result&lt;Bytes, BoxError&gt; {
        Ok(Bytes::copy_from_slice(
            self.hasher.clone().finalize().as_slice(),
        ))
    }

    // Size of the checksum in bytes
    fn size() -&gt; u64 {
        20
    }

    fn header_name() -&gt; HeaderName {
        SHA_1_HEADER_NAME
    }

    fn header_value(&amp;self) -&gt; HeaderValue {
        // We clone the hasher because `Hasher::finalize` consumes `self`
        let hash = self.hasher.clone().finalize();
        HeaderValue::from_str(&amp;base64::encode(&amp;hash[..]))
            .expect(&quot;will always produce a valid header value from a SHA-1 checksum&quot;)
    }
}

impl Checksum for Sha1 {
    fn update(
        &amp;mut self,
        bytes: &amp;[u8],
    ) -&gt; Result&lt;(), Box&lt;(dyn std::error::Error + Send + Sync + 'static)&gt;&gt; {
        Self::update(self, bytes)
    }
    fn headers(
        &amp;self,
    ) -&gt; Result&lt;Option&lt;HeaderMap&gt;, Box&lt;(dyn std::error::Error + Send + Sync + 'static)&gt;&gt; {
        Self::headers(self)
    }
    fn header_name(&amp;self) -&gt; HeaderName {
        Self::header_name()
    }
    fn finalize(&amp;self) -&gt; Result&lt;Bytes, BoxError&gt; {
        Self::finalize(self)
    }
    fn size(&amp;self) -&gt; u64 {
        Self::size()
    }
}

#[derive(Debug, Default)]
struct Sha256 {
    hasher: sha2::Sha256,
}

impl Sha256 {
    fn update(&amp;mut self, bytes: &amp;[u8]) -&gt; Result&lt;(), BoxError&gt; {
        self.hasher.write_all(bytes)?;

        Ok(())
    }

    fn headers(&amp;self) -&gt; Result&lt;Option&lt;HeaderMap&lt;HeaderValue&gt;&gt;, BoxError&gt; {
        let mut header_map = HeaderMap::new();
        header_map.insert(Self::header_name(), self.header_value());

        Ok(Some(header_map))
    }

    fn finalize(&amp;self) -&gt; Result&lt;Bytes, BoxError&gt; {
        Ok(Bytes::copy_from_slice(
            self.hasher.clone().finalize().as_slice(),
        ))
    }

    // Size of the checksum in bytes
    fn size() -&gt; u64 {
        32
    }

    fn header_name() -&gt; HeaderName {
        SHA_256_HEADER_NAME
    }

    fn header_value(&amp;self) -&gt; HeaderValue {
        // We clone the hasher because `Hasher::finalize` consumes `self`
        let hash = self.hasher.clone().finalize();
        HeaderValue::from_str(&amp;base64::encode(&amp;hash[..]))
            .expect(&quot;will always produce a valid header value from a SHA-256 checksum&quot;)
    }
}

impl Checksum for Sha256 {
    fn update(
        &amp;mut self,
        bytes: &amp;[u8],
    ) -&gt; Result&lt;(), Box&lt;(dyn std::error::Error + Send + Sync + 'static)&gt;&gt; {
        Self::update(self, bytes)
    }
    fn headers(
        &amp;self,
    ) -&gt; Result&lt;Option&lt;HeaderMap&gt;, Box&lt;(dyn std::error::Error + Send + Sync + 'static)&gt;&gt; {
        Self::headers(self)
    }
    fn header_name(&amp;self) -&gt; HeaderName {
        Self::header_name()
    }
    fn finalize(&amp;self) -&gt; Result&lt;Bytes, BoxError&gt; {
        Self::finalize(self)
    }
    fn size(&amp;self) -&gt; u64 {
        Self::size()
    }
}

#[derive(Debug, Default)]
struct Md5 {
    hasher: md5::Md5,
}

impl Md5 {
    fn update(&amp;mut self, bytes: &amp;[u8]) -&gt; Result&lt;(), BoxError&gt; {
        self.hasher.write_all(bytes)?;

        Ok(())
    }

    fn headers(&amp;self) -&gt; Result&lt;Option&lt;HeaderMap&lt;HeaderValue&gt;&gt;, BoxError&gt; {
        let mut header_map = HeaderMap::new();
        header_map.insert(Self::header_name(), self.header_value());

        Ok(Some(header_map))
    }

    fn finalize(&amp;self) -&gt; Result&lt;Bytes, BoxError&gt; {
        Ok(Bytes::copy_from_slice(
            self.hasher.clone().finalize().as_slice(),
        ))
    }

    // Size of the checksum in bytes
    fn size() -&gt; u64 {
        16
    }

    fn header_name() -&gt; HeaderName {
        MD5_HEADER_NAME
    }

    fn header_value(&amp;self) -&gt; HeaderValue {
        // We clone the hasher because `Hasher::finalize` consumes `self`
        let hash = self.hasher.clone().finalize();
        HeaderValue::from_str(&amp;base64::encode(&amp;hash[..]))
            .expect(&quot;will always produce a valid header value from an MD5 checksum&quot;)
    }
}

impl Checksum for Md5 {
    fn update(
        &amp;mut self,
        bytes: &amp;[u8],
    ) -&gt; Result&lt;(), Box&lt;(dyn std::error::Error + Send + Sync + 'static)&gt;&gt; {
        Self::update(self, bytes)
    }
    fn headers(
        &amp;self,
    ) -&gt; Result&lt;Option&lt;HeaderMap&gt;, Box&lt;(dyn std::error::Error + Send + Sync + 'static)&gt;&gt; {
        Self::headers(self)
    }
    fn header_name(&amp;self) -&gt; HeaderName {
        Self::header_name()
    }
    fn finalize(&amp;self) -&gt; Result&lt;Bytes, BoxError&gt; {
        Self::finalize(self)
    }
    fn size(&amp;self) -&gt; u64 {
        Self::size()
    }
}

// We have existing tests for the checksums, those don't require an update
<span class="boring">}
</span></code></pre></pre>
<h3 id="checksumbody"><a class="header" href="#checksumbody"><code>ChecksumBody</code></a></h3>
<p>When creating a checksum-validated request with an in-memory request body, we can read the body, calculate a checksum, and insert the checksum header, all before sending the request. When creating a checksum-validated request with a streaming request body, we don't have that luxury. Instead, we must calculate a checksum while sending the body, and append that checksum as a <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Trailer">trailer</a>.</p>
<p>We will accomplish this by wrapping the <code>SdkBody</code> that requires validation within a <code>ChecksumBody</code>. Afterwards, we'll need to wrap the <code>ChecksumBody</code> in yet another layer which we'll discuss in the <a href="#awschunkedbody-and-awschunkedbodyoptions"><code>AwsChunkedBody</code> and <code>AwsChunkedBodyOptions</code></a> section.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// In aws-smithy-checksums/src/body.rs
use crate::{new_checksum, Checksum};

use aws_smithy_http::body::SdkBody;
use aws_smithy_http::header::append_merge_header_maps;
use aws_smithy_types::base64;

use bytes::{Buf, Bytes};
use http::header::HeaderName;
use http::{HeaderMap, HeaderValue};
use http_body::{Body, SizeHint};
use pin_project::pin_project;

use std::fmt::Display;
use std::pin::Pin;
use std::task::{Context, Poll};

/// A `ChecksumBody` will read and calculate a request body as it's being sent. Once the body has
/// been completely read, it'll append a trailer with the calculated checksum.
#[pin_project]
pub struct ChecksumBody&lt;InnerBody&gt; {
    #[pin]
    inner: InnerBody,
    #[pin]
    checksum: Box&lt;dyn Checksum&gt;,
}

impl ChecksumBody&lt;SdkBody&gt; {
    /// Given an `SdkBody` and the name of a checksum algorithm as a `&amp;str`, create a new
    /// `ChecksumBody&lt;SdkBody&gt;`. Valid checksum algorithm names are defined in this crate's
    /// [root module](super).
    ///
    /// # Panics
    ///
    /// This will panic if the given checksum algorithm is not supported.
    pub fn new(body: SdkBody, checksum_algorithm: &amp;str) -&gt; Self {
        Self {
            checksum: new_checksum(checksum_algorithm),
            inner: body,
        }
    }

    /// Return the name of the trailer that will be emitted by this `ChecksumBody`
    pub fn trailer_name(&amp;self) -&gt; HeaderName {
        self.checksum.header_name()
    }

    /// Calculate and return the sum of the:
    /// - checksum when base64 encoded
    /// - trailer name
    /// - trailer separator
    ///
    /// This is necessary for calculating the true size of the request body for certain
    /// content-encodings.
    pub fn trailer_length(&amp;self) -&gt; u64 {
        let trailer_name_size_in_bytes = self.checksum.header_name().as_str().len() as u64;
        let base64_encoded_checksum_size_in_bytes = base64::encoded_length(self.checksum.size());

        (trailer_name_size_in_bytes
            // HTTP trailer names and values may be separated by either a single colon or a single
            // colon and a whitespace. In the AWS Rust SDK, we use a single colon.
            + &quot;:&quot;.len() as u64
            + base64_encoded_checksum_size_in_bytes)
    }

    fn poll_inner(
        self: Pin&lt;&amp;mut Self&gt;,
        cx: &amp;mut Context&lt;'_&gt;,
    ) -&gt; Poll&lt;Option&lt;Result&lt;Bytes, aws_smithy_http::body::Error&gt;&gt;&gt; {
        let this = self.project();
        let inner = this.inner;
        let mut checksum = this.checksum;

        match inner.poll_data(cx) {
            Poll::Ready(Some(Ok(mut data))) =&gt; {
                let len = data.chunk().len();
                let bytes = data.copy_to_bytes(len);

                if let Err(e) = checksum.update(&amp;bytes) {
                    return Poll::Ready(Some(Err(e)));
                }

                Poll::Ready(Some(Ok(bytes)))
            }
            Poll::Ready(None) =&gt; Poll::Ready(None),
            Poll::Ready(Some(Err(e))) =&gt; Poll::Ready(Some(Err(e))),
            Poll::Pending =&gt; Poll::Pending,
        }
    }
}

impl http_body::Body for ChecksumBody&lt;SdkBody&gt; {
    type Data = Bytes;
    type Error = aws_smithy_http::body::Error;

    fn poll_data(
        self: Pin&lt;&amp;mut Self&gt;,
        cx: &amp;mut Context&lt;'_&gt;,
    ) -&gt; Poll&lt;Option&lt;Result&lt;Self::Data, Self::Error&gt;&gt;&gt; {
        self.poll_inner(cx)
    }

    fn poll_trailers(
        self: Pin&lt;&amp;mut Self&gt;,
        cx: &amp;mut Context&lt;'_&gt;,
    ) -&gt; Poll&lt;Result&lt;Option&lt;HeaderMap&lt;HeaderValue&gt;&gt;, Self::Error&gt;&gt; {
        let this = self.project();
        match (
            this.checksum.headers(),
            http_body::Body::poll_trailers(this.inner, cx),
        ) {
            // If everything is ready, return trailers, merging them if we have more than one map
            (Ok(outer_trailers), Poll::Ready(Ok(inner_trailers))) =&gt; {
                let trailers = match (outer_trailers, inner_trailers) {
                    // Values from the inner trailer map take precedent over values from the outer map
                    (Some(outer), Some(inner)) =&gt; Some(append_merge_header_maps(inner, outer)),
                    // If only one or neither produced trailers, just combine the `Option`s with `or`
                    (outer, inner) =&gt; outer.or(inner),
                };
                Poll::Ready(Ok(trailers))
            }
            // If the inner poll is Ok but the outer body's checksum callback encountered an error,
            // return the error
            (Err(e), Poll::Ready(Ok(_))) =&gt; Poll::Ready(Err(e)),
            // Otherwise return the result of the inner poll.
            // It may be pending or it may be ready with an error.
            (_, inner_poll) =&gt; inner_poll,
        }
    }

    fn is_end_stream(&amp;self) -&gt; bool {
        self.inner.is_end_stream()
    }

    fn size_hint(&amp;self) -&gt; SizeHint {
        let body_size_hint = self.inner.size_hint();
        match body_size_hint.exact() {
            Some(size) =&gt; {
                let checksum_size_hint = self.checksum.size();
                SizeHint::with_exact(size + checksum_size_hint)
            }
            // TODO is this the right behavior?
            None =&gt; {
                let checksum_size_hint = self.checksum.size();
                let mut summed_size_hint = SizeHint::new();
                summed_size_hint.set_lower(body_size_hint.lower() + checksum_size_hint);

                if let Some(body_size_hint_upper) = body_size_hint.upper() {
                    summed_size_hint.set_upper(body_size_hint_upper + checksum_size_hint);
                }

                summed_size_hint
            }
        }
    }
}

// The tests I have written are omitted from this RFC for brevity. The request body checksum calculation and trailer size calculations are all tested.
<span class="boring">}
</span></code></pre></pre>
<h3 id="checksumvalidatedbody"><a class="header" href="#checksumvalidatedbody"><code>ChecksumValidatedBody</code></a></h3>
<p>Users may request checksum validation for response bodies. That capability is provided by <code>ChecksumValidatedBody</code>, which will calculate a checksum as the response body is being read. Once all data has been read, the calculated checksum is compared to a precalculated checksum set during body creation. If the checksums don't match, then the body will emit an error.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// In aws-smithy-checksums/src/body.rs
/// A response body that will calculate a checksum as it is read. If all data is read and the
/// calculated checksum doesn't match a precalculated checksum, this body will emit an
/// [asw_smithy_http::body::Error].
#[pin_project]
pub struct ChecksumValidatedBody&lt;InnerBody&gt; {
    #[pin]
    inner: InnerBody,
    #[pin]
    checksum: Box&lt;dyn Checksum&gt;,
    precalculated_checksum: Bytes,
}

impl ChecksumValidatedBody&lt;SdkBody&gt; {
    /// Given an `SdkBody`, the name of a checksum algorithm as a `&amp;str`, and a precalculated
    /// checksum represented as `Bytes`, create a new `ChecksumValidatedBody&lt;SdkBody&gt;`.
    /// Valid checksum algorithm names are defined in this crate's [root module](super).
    ///
    /// # Panics
    ///
    /// This will panic if the given checksum algorithm is not supported.
    pub fn new(body: SdkBody, checksum_algorithm: &amp;str, precalculated_checksum: Bytes) -&gt; Self {
        Self {
            checksum: new_checksum(checksum_algorithm),
            inner: body,
            precalculated_checksum,
        }
    }

    fn poll_inner(
        self: Pin&lt;&amp;mut Self&gt;,
        cx: &amp;mut Context&lt;'_&gt;,
    ) -&gt; Poll&lt;Option&lt;Result&lt;Bytes, aws_smithy_http::body::Error&gt;&gt;&gt; {
        let this = self.project();
        let inner = this.inner;
        let mut checksum = this.checksum;

        match inner.poll_data(cx) {
            Poll::Ready(Some(Ok(mut data))) =&gt; {
                let len = data.chunk().len();
                let bytes = data.copy_to_bytes(len);

                if let Err(e) = checksum.update(&amp;bytes) {
                    return Poll::Ready(Some(Err(e)));
                }

                Poll::Ready(Some(Ok(bytes)))
            }
            // Once the inner body has stopped returning data, check the checksum
            // and return an error if it doesn't match.
            Poll::Ready(None) =&gt; {
                let actual_checksum = {
                    match checksum.finalize() {
                        Ok(checksum) =&gt; checksum,
                        Err(err) =&gt; {
                            return Poll::Ready(Some(Err(err)));
                        }
                    }
                };
                if *this.precalculated_checksum == actual_checksum {
                    Poll::Ready(None)
                } else {
                    // So many parens it's starting to look like LISP
                    Poll::Ready(Some(Err(Box::new(Error::checksum_mismatch(
                        this.precalculated_checksum.clone(),
                        actual_checksum,
                    )))))
                }
            }
            Poll::Ready(Some(Err(e))) =&gt; Poll::Ready(Some(Err(e))),
            Poll::Pending =&gt; Poll::Pending,
        }
    }
}

/// Errors related to checksum calculation and validation
#[derive(Debug, Eq, PartialEq)]
#[non_exhaustive]
pub enum Error {
    /// The actual checksum didn't match the expected checksum. The checksummed data has been
    /// altered since the expected checksum was calculated.
    ChecksumMismatch { expected: Bytes, actual: Bytes },
}

impl Error {
    /// Given an expected checksum and an actual checksum in `Bytes` form, create a new
    /// `Error::ChecksumMismatch`.
    pub fn checksum_mismatch(expected: Bytes, actual: Bytes) -&gt; Self {
        Self::ChecksumMismatch { expected, actual }
    }
}

impl Display for Error {
    fn fmt(&amp;self, f: &amp;mut std::fmt::Formatter&lt;'_&gt;) -&gt; Result&lt;(), std::fmt::Error&gt; {
        match self {
            Error::ChecksumMismatch { expected, actual } =&gt; write!(
                f,
                &quot;body checksum mismatch. expected body checksum to be {:x} but it was {:x}&quot;,
                expected, actual
            ),
        }
    }
}

impl std::error::Error for Error {}

impl http_body::Body for ChecksumValidatedBody&lt;SdkBody&gt; {
    type Data = Bytes;
    type Error = aws_smithy_http::body::Error;

    fn poll_data(
        self: Pin&lt;&amp;mut Self&gt;,
        cx: &amp;mut Context&lt;'_&gt;,
    ) -&gt; Poll&lt;Option&lt;Result&lt;Self::Data, Self::Error&gt;&gt;&gt; {
        self.poll_inner(cx)
    }

    fn poll_trailers(
        self: Pin&lt;&amp;mut Self&gt;,
        cx: &amp;mut Context&lt;'_&gt;,
    ) -&gt; Poll&lt;Result&lt;Option&lt;HeaderMap&lt;HeaderValue&gt;&gt;, Self::Error&gt;&gt; {
        self.project().inner.poll_trailers(cx)
    }

    // Once the inner body returns true for is_end_stream, we still need to
    // verify the checksum; Therefore, we always return false here.
    fn is_end_stream(&amp;self) -&gt; bool {
        false
    }

    fn size_hint(&amp;self) -&gt; SizeHint {
        self.inner.size_hint()
    }
}

// The tests I have written are omitted from this RFC for brevity. The response body checksum verification is tested.
<span class="boring">}
</span></code></pre></pre>
<h3 id="awschunkedbody-and-awschunkedbodyoptions"><a class="header" href="#awschunkedbody-and-awschunkedbodyoptions"><code>AwsChunkedBody</code> and <code>AwsChunkedBodyOptions</code></a></h3>
<p>In order to send a request with checksum trailers, we must use an AWS-specific content encoding called <code>aws-chunked</code>. This encoding requires that we:</p>
<ul>
<li>Divide the original body content into one or more chunks. For our purposes we only ever use one chunk.</li>
<li>Append a hexadecimal chunk size header to each chunk.</li>
<li>Suffix each chunk with a <a href="https://developer.mozilla.org/en-US/docs/Glossary/CRLF">CRLF (carriage return line feed)</a>.</li>
<li>Send a 0 and CRLF to close the original body content section.</li>
<li>Send trailers as part of the request body, suffixing each with a CRLF.</li>
<li>Send a final CRLF to close the request body.</li>
</ul>
<p>As an example, Sending a regular request body with a SHA-256 checksum would look similar to this:</p>
<pre><code class="language-HTTP">PUT SOMEURL HTTP/1.1
x-amz-checksum-sha256: ZOyIygCyaOW6GjVnihtTFtIS9PNmskdyMlNKiuyjfzw=
Content-Length: 11
...

Hello world
</code></pre>
<p>and the <code>aws-chunked</code> version would look like this:</p>
<pre><code class="language-HTTP">PUT SOMEURL HTTP/1.1
x-amz-trailer: x-amz-checksum-sha256
x-amz-decoded-content-length: 11
Content-Encoding: aws-chunked
Content-Length: 87
...

B\r\n
Hello world\r\n
0\r\n
x-amz-checksum-sha256:ZOyIygCyaOW6GjVnihtTFtIS9PNmskdyMlNKiuyjfzw=\r\n
\r\n
</code></pre>
<p><em><strong>NOTES:</strong></em></p>
<ul>
<li><em>In the second example, <code>B</code> is the hexadecimal representation of 11.</em></li>
<li><em>Authorization and other headers are omitted from the examples above for brevity.</em></li>
<li><em>When using <code>aws-chunked</code> content encoding, S3 requires that we send the <code>x-amz-decoded-content-length</code> with the length of the original body content.</em></li>
</ul>
<p>This encoding scheme is performed by <code>AwsChunkedBody</code> and configured with <code>AwsChunkedBodyOptions</code>.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// In aws-http/src/content_encoding.rs
use aws_smithy_checksums::body::ChecksumBody;
use aws_smithy_http::body::SdkBody;

use bytes::{Buf, Bytes, BytesMut};
use http::{HeaderMap, HeaderValue};
use http_body::{Body, SizeHint};
use pin_project::pin_project;

use std::pin::Pin;
use std::task::{Context, Poll};

const CRLF: &amp;str = &quot;\r\n&quot;;
const CHUNK_TERMINATOR: &amp;str = &quot;0\r\n&quot;;

/// Content encoding header value constants
pub mod header_value {
    /// Header value denoting &quot;aws-chunked&quot; encoding
    pub const AWS_CHUNKED: &amp;str = &quot;aws-chunked&quot;;
}

/// Options used when constructing an [`AwsChunkedBody`][AwsChunkedBody].
#[derive(Debug, Default)]
#[non_exhaustive]
pub struct AwsChunkedBodyOptions {
    /// The total size of the stream. For unsigned encoding this implies that
    /// there will only be a single chunk containing the underlying payload,
    /// unless ChunkLength is also specified.
    pub stream_length: Option&lt;u64&gt;,
    /// The maximum size of each chunk to be sent.
    ///
    /// If ChunkLength and stream_length are both specified, the stream will be
    /// broken up into chunk_length chunks. The encoded length of the aws-chunked
    /// encoding can still be determined as long as all trailers, if any, have a
    /// fixed length.
    pub chunk_length: Option&lt;u64&gt;,
    /// The length of each trailer sent within an `AwsChunkedBody`. Necessary in
    /// order to correctly calculate the total size of the body accurately.
    pub trailer_lens: Vec&lt;u64&gt;,
}

impl AwsChunkedBodyOptions {
    /// Create a new [`AwsChunkedBodyOptions`][AwsChunkedBodyOptions]
    pub fn new() -&gt; Self {
        Self::default()
    }

    /// Set stream length
    pub fn with_stream_length(mut self, stream_length: u64) -&gt; Self {
        self.stream_length = Some(stream_length);
        self
    }

    /// Set chunk length
    pub fn with_chunk_length(mut self, chunk_length: u64) -&gt; Self {
        self.chunk_length = Some(chunk_length);
        self
    }

    /// Set a trailer len
    pub fn with_trailer_len(mut self, trailer_len: u64) -&gt; Self {
        self.trailer_lens.push(trailer_len);
        self
    }
}

#[derive(Debug, PartialEq, Eq)]
enum AwsChunkedBodyState {
    WritingChunkSize,
    WritingChunk,
    WritingTrailers,
    Closed,
}

/// A request body compatible with `Content-Encoding: aws-chunked`
///
/// Chunked-Body grammar is defined in [ABNF] as:
///
/// ```txt
/// Chunked-Body    = *chunk
///                   last-chunk
///                   chunked-trailer
///                   CRLF
///
/// chunk           = chunk-size CRLF chunk-data CRLF
/// chunk-size      = 1*HEXDIG
/// last-chunk      = 1*(&quot;0&quot;) CRLF
/// chunked-trailer = *( entity-header CRLF )
/// entity-header   = field-name &quot;:&quot; OWS field-value OWS
/// ```
/// For more info on what the abbreviations mean, see https://datatracker.ietf.org/doc/html/rfc7230#section-1.2
///
/// [ABNF]:https://en.wikipedia.org/wiki/Augmented_Backus%E2%80%93Naur_form
#[derive(Debug)]
#[pin_project]
pub struct AwsChunkedBody&lt;InnerBody&gt; {
    #[pin]
    inner: InnerBody,
    #[pin]
    state: AwsChunkedBodyState,
    options: AwsChunkedBodyOptions,
}

// Currently, we only use this in terms of a streaming request body with checksum trailers
type Inner = ChecksumBody&lt;SdkBody&gt;;

impl AwsChunkedBody&lt;Inner&gt; {
    /// Wrap the given body in an outer body compatible with `Content-Encoding: aws-chunked`
    pub fn new(body: Inner, options: AwsChunkedBodyOptions) -&gt; Self {
        Self {
            inner: body,
            state: AwsChunkedBodyState::WritingChunkSize,
            options,
        }
    }

    fn encoded_length(&amp;self) -&gt; Option&lt;u64&gt; {
        if self.options.chunk_length.is_none() &amp;&amp; self.options.stream_length.is_none() {
            return None;
        }

        let mut length = 0;
        let stream_length = self.options.stream_length.unwrap_or_default();
        if stream_length != 0 {
            if let Some(chunk_length) = self.options.chunk_length {
                let num_chunks = stream_length / chunk_length;
                length += num_chunks * get_unsigned_chunk_bytes_length(chunk_length);
                let remainder = stream_length % chunk_length;
                if remainder != 0 {
                    length += get_unsigned_chunk_bytes_length(remainder);
                }
            } else {
                length += get_unsigned_chunk_bytes_length(stream_length);
            }
        }

        // End chunk
        length += CHUNK_TERMINATOR.len() as u64;

        // Trailers
        for len in self.options.trailer_lens.iter() {
            length += len + CRLF.len() as u64;
        }

        // Encoding terminator
        length += CRLF.len() as u64;

        Some(length)
    }
}

fn prefix_with_chunk_size(data: Bytes, chunk_size: u64) -&gt; Bytes {
    // Len is the size of the entire chunk as defined in `AwsChunkedBodyOptions`
    let mut prefixed_data = BytesMut::from(format!(&quot;{:X?}\r\n&quot;, chunk_size).as_bytes());
    prefixed_data.extend_from_slice(&amp;data);

    prefixed_data.into()
}

fn get_unsigned_chunk_bytes_length(payload_length: u64) -&gt; u64 {
    let hex_repr_len = int_log16(payload_length);
    hex_repr_len + CRLF.len() as u64 + payload_length + CRLF.len() as u64
}

fn trailers_as_aws_chunked_bytes(
    total_length_of_trailers_in_bytes: u64,
    trailer_map: Option&lt;HeaderMap&gt;,
) -&gt; Bytes {
    use std::fmt::Write;

    // On 32-bit operating systems, we might not be able to convert the u64 to a usize, so we just
    // use `String::new` in that case.
    let mut trailers = match usize::try_from(total_length_of_trailers_in_bytes) {
        Ok(total_length_of_trailers_in_bytes) =&gt; {
            String::with_capacity(total_length_of_trailers_in_bytes)
        }
        Err(_) =&gt; String::new(),
    };
    let mut already_wrote_first_trailer = false;

    if let Some(trailer_map) = trailer_map {
        for (header_name, header_value) in trailer_map.into_iter() {
            match header_name {
                // New name, new value
                Some(header_name) =&gt; {
                    if already_wrote_first_trailer {
                        // First trailer shouldn't have a preceding CRLF, but every trailer after it should
                        trailers.write_str(CRLF).unwrap();
                    } else {
                        already_wrote_first_trailer = true;
                    }

                    trailers.write_str(header_name.as_str()).unwrap();
                    trailers.write_char(':').unwrap();
                }
                // Same name, new value
                None =&gt; {
                    trailers.write_char(',').unwrap();
                }
            }
            trailers.write_str(header_value.to_str().unwrap()).unwrap();
        }
    }

    // Write CRLF to end the body
    trailers.write_str(CRLF).unwrap();
    // If we wrote at least one trailer, we need to write an extra CRLF
    if total_length_of_trailers_in_bytes != 0 {
        trailers.write_str(CRLF).unwrap();
    }

    trailers.into()
}

impl Body for AwsChunkedBody&lt;Inner&gt; {
    type Data = Bytes;
    type Error = aws_smithy_http::body::Error;

    fn poll_data(
        self: Pin&lt;&amp;mut Self&gt;,
        cx: &amp;mut Context&lt;'_&gt;,
    ) -&gt; Poll&lt;Option&lt;Result&lt;Self::Data, Self::Error&gt;&gt;&gt; {
        tracing::info!(&quot;polling AwsChunkedBody&quot;);
        let mut this = self.project();

        match *this.state {
            AwsChunkedBodyState::WritingChunkSize =&gt; match this.inner.poll_data(cx) {
                Poll::Ready(Some(Ok(data))) =&gt; {
                    // A chunk must be prefixed by chunk size in hexadecimal
                    tracing::info!(&quot;writing chunk size and start of chunk&quot;);
                    *this.state = AwsChunkedBodyState::WritingChunk;
                    let total_chunk_size = this
                        .options
                        .chunk_length
                        .or(this.options.stream_length)
                        .unwrap_or_default();
                    Poll::Ready(Some(Ok(prefix_with_chunk_size(data, total_chunk_size))))
                }
                Poll::Ready(None) =&gt; {
                    tracing::info!(&quot;chunk was empty, writing last-chunk&quot;);
                    *this.state = AwsChunkedBodyState::WritingTrailers;
                    Poll::Ready(Some(Ok(Bytes::from(&quot;0\r\n&quot;))))
                }
                Poll::Ready(Some(Err(e))) =&gt; Poll::Ready(Some(Err(e))),
                Poll::Pending =&gt; Poll::Pending,
            },
            AwsChunkedBodyState::WritingChunk =&gt; match this.inner.poll_data(cx) {
                Poll::Ready(Some(Ok(mut data))) =&gt; {
                    tracing::info!(&quot;writing rest of chunk data&quot;);
                    Poll::Ready(Some(Ok(data.copy_to_bytes(data.len()))))
                }
                Poll::Ready(None) =&gt; {
                    tracing::info!(&quot;no more chunk data, writing CRLF and last-chunk&quot;);
                    *this.state = AwsChunkedBodyState::WritingTrailers;
                    Poll::Ready(Some(Ok(Bytes::from(&quot;\r\n0\r\n&quot;))))
                }
                Poll::Ready(Some(Err(e))) =&gt; Poll::Ready(Some(Err(e))),
                Poll::Pending =&gt; Poll::Pending,
            },
            AwsChunkedBodyState::WritingTrailers =&gt; {
                return match this.inner.poll_trailers(cx) {
                    Poll::Ready(Ok(trailers)) =&gt; {
                        *this.state = AwsChunkedBodyState::Closed;
                        let total_length_of_trailers_in_bytes =
                            this.options.trailer_lens.iter().fold(0, |acc, n| acc + n);

                        Poll::Ready(Some(Ok(trailers_as_aws_chunked_bytes(
                            total_length_of_trailers_in_bytes,
                            trailers,
                        ))))
                    }
                    Poll::Pending =&gt; Poll::Pending,
                    Poll::Ready(Err(e)) =&gt; Poll::Ready(Some(Err(e))),
                };
            }
            AwsChunkedBodyState::Closed =&gt; {
                return Poll::Ready(None);
            }
        }
    }

    fn poll_trailers(
        self: Pin&lt;&amp;mut Self&gt;,
        _cx: &amp;mut Context&lt;'_&gt;,
    ) -&gt; Poll&lt;Result&lt;Option&lt;HeaderMap&lt;HeaderValue&gt;&gt;, Self::Error&gt;&gt; {
        // Trailers were already appended to the body because of the content encoding scheme
        Poll::Ready(Ok(None))
    }

    fn is_end_stream(&amp;self) -&gt; bool {
        self.state == AwsChunkedBodyState::Closed
    }

    fn size_hint(&amp;self) -&gt; SizeHint {
        SizeHint::with_exact(
            self.encoded_length()
                .expect(&quot;Requests made with aws-chunked encoding must have known size&quot;)
                as u64,
        )
    }
}

// Used for finding how many hexadecimal digits it takes to represent a base 10 integer
fn int_log16&lt;T&gt;(mut i: T) -&gt; u64
where
    T: std::ops::DivAssign + PartialOrd + From&lt;u8&gt; + Copy,
{
    let mut len = 0;
    let zero = T::from(0);
    let sixteen = T::from(16);

    while i &gt; zero {
        i /= sixteen;
        len += 1;
    }

    len
}

#[cfg(test)]
mod tests {
    use super::AwsChunkedBody;
    use crate::content_encoding::AwsChunkedBodyOptions;
    use aws_smithy_checksums::body::ChecksumBody;
    use aws_smithy_http::body::SdkBody;
    use bytes::Buf;
    use bytes_utils::SegmentedBuf;
    use http_body::Body;
    use std::io::Read;

    #[tokio::test]
    async fn test_aws_chunked_encoded_body() {
        let input_text = &quot;Hello world&quot;;
        let sdk_body = SdkBody::from(input_text);
        let checksum_body = ChecksumBody::new(sdk_body, &quot;sha256&quot;);
        let aws_chunked_body_options = AwsChunkedBodyOptions {
            stream_length: Some(input_text.len() as u64),
            chunk_length: None,
            trailer_lens: vec![
                &quot;x-amz-checksum-sha256:ZOyIygCyaOW6GjVnihtTFtIS9PNmskdyMlNKiuyjfzw=&quot;.len() as u64,
            ],
        };
        let mut aws_chunked_body = AwsChunkedBody::new(checksum_body, aws_chunked_body_options);

        let mut output = SegmentedBuf::new();
        while let Some(buf) = aws_chunked_body.data().await {
            output.push(buf.unwrap());
        }

        let mut actual_output = String::new();
        output
            .reader()
            .read_to_string(&amp;mut actual_output)
            .expect(&quot;Doesn't cause IO errors&quot;);

        let expected_output = &quot;B\r\nHello world\r\n0\r\nx-amz-checksum-sha256:ZOyIygCyaOW6GjVnihtTFtIS9PNmskdyMlNKiuyjfzw=\r\n\r\n&quot;;

        // Verify data is complete and correctly encoded
        assert_eq!(expected_output, actual_output);

        assert!(
            aws_chunked_body
                .trailers()
                .await
                .expect(&quot;checksum generation was without error&quot;)
                .is_none(),
            &quot;aws-chunked encoded bodies don't have normal HTTP trailers&quot;
        );
    }

    #[tokio::test]
    async fn test_empty_aws_chunked_encoded_body() {
        let sdk_body = SdkBody::from(&quot;&quot;);
        let checksum_body = ChecksumBody::new(sdk_body, &quot;sha256&quot;);
        let aws_chunked_body_options = AwsChunkedBodyOptions {
            stream_length: Some(0),
            chunk_length: None,
            trailer_lens: vec![
                &quot;x-amz-checksum-sha256:47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=&quot;.len() as u64,
            ],
        };
        let mut aws_chunked_body = AwsChunkedBody::new(checksum_body, aws_chunked_body_options);

        let mut output = SegmentedBuf::new();
        while let Some(buf) = aws_chunked_body.data().await {
            output.push(buf.unwrap());
        }

        let mut actual_output = String::new();
        output
            .reader()
            .read_to_string(&amp;mut actual_output)
            .expect(&quot;Doesn't cause IO errors&quot;);

        let expected_output =
            &quot;0\r\nx-amz-checksum-sha256:47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=\r\n\r\n&quot;;

        // Verify data is complete and correctly encoded
        assert_eq!(expected_output, actual_output);

        assert!(
            aws_chunked_body
                .trailers()
                .await
                .expect(&quot;checksum generation was without error&quot;)
                .is_none(),
            &quot;aws-chunked encoded bodies don't have normal HTTP trailers&quot;
        );
    }
}
<span class="boring">}
</span></code></pre></pre>
<h3 id="sigv4-update"><a class="header" href="#sigv4-update">Sigv4 Update</a></h3>
<p>When sending checksum-verified requests with a streaming body, we must update the usual signing process. Instead of signing the request based on the request body's checksum, we must sign it with a special header instead:</p>
<pre><code class="language-HTTP">Authorization: &lt;computed authorization header value using &quot;STREAMING-UNSIGNED-PAYLOAD-TRAILER&quot;&gt;
x-amz-content-sha256: STREAMING-UNSIGNED-PAYLOAD-TRAILER
</code></pre>
<p>Setting <code>STREAMING-UNSIGNED-PAYLOAD-TRAILER</code> tells the signer that we're sending an unsigned streaming body that will be followed by trailers.</p>
<p>We can achieve this by:</p>
<ul>
<li>Adding a new variant to <code>SignableBody</code>:
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// A signable HTTP request body
#[derive(Debug, Clone, Eq, PartialEq)]
#[non_exhaustive]
pub enum SignableBody&lt;'a&gt; {
    // existing variants have been omitted for brevity...

    /// An unsigned payload with trailers
    ///
    /// StreamingUnsignedPayloadTrailer is used for streaming requests where the contents of the
    /// body cannot be known prior to signing **AND** which include HTTP trailers.
    StreamingUnsignedPayloadTrailer,
}
<span class="boring">}
</span></code></pre></pre>
</li>
<li>Updating the <code>CanonicalRequest::payload_hash</code> method to include the new <code>SignableBody</code> variant:
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn payload_hash&lt;'b&gt;(body: &amp;'b SignableBody&lt;'b&gt;) -&gt; Cow&lt;'b, str&gt; {
    // Payload hash computation
    //
    // Based on the input body, set the payload_hash of the canonical request:
    // Either:
    // - compute a hash
    // - use the precomputed hash
    // - use `UnsignedPayload`
    // - use `StreamingUnsignedPayloadTrailer`
    match body {
        SignableBody::Bytes(data) =&gt; Cow::Owned(sha256_hex_string(data)),
        SignableBody::Precomputed(digest) =&gt; Cow::Borrowed(digest.as_str()),
        SignableBody::UnsignedPayload =&gt; Cow::Borrowed(UNSIGNED_PAYLOAD),
        SignableBody::StreamingUnsignedPayloadTrailer =&gt; {
            Cow::Borrowed(STREAMING_UNSIGNED_PAYLOAD_TRAILER)
        }
    }
}
<span class="boring">}
</span></code></pre></pre>
</li>
<li><em>(in generated code)</em> Inserting the <code>SignableBody</code> into the request property bag when making a checksum-verified streaming request:
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>if self.checksum_algorithm.is_some() {
    request
        .properties_mut()
        .insert(aws_sig_auth::signer::SignableBody::StreamingUnsignedPayloadTrailer);
}
<span class="boring">}
</span></code></pre></pre>
</li>
</ul>
<p>It's possible to send <code>aws-chunked</code> requests where each chunk is signed individually. Because this feature isn't strictly necessary for flexible checksums, I've avoided implementing it.</p>
<h3 id="inlineables"><a class="header" href="#inlineables">Inlineables</a></h3>
<p>In order to avoid writing lots of Rust in Kotlin, I have implemented request and response building functions as inlineables:</p>
<ul>
<li>Building checksum-validated requests with in-memory request bodies:
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// In aws/rust-runtime/aws-inlineable/src/streaming_body_with_checksum.rs
/// Given a `&amp;mut http::request::Request`, and checksum algorithm name, calculate a checksum and
/// then modify the request to include the checksum as a header.
pub fn build_checksum_validated_request(
    request: &amp;mut http::request::Request&lt;aws_smithy_http::body::SdkBody&gt;,
    checksum_algorithm: &amp;str,
) -&gt; Result&lt;(), aws_smithy_http::operation::BuildError&gt; {
    let data = request.body().bytes().unwrap_or_default();

    let mut checksum = aws_smithy_checksums::new_checksum(checksum_algorithm);
    checksum
        .update(data)
        .map_err(|err| aws_smithy_http::operation::BuildError::Other(err))?;
    let checksum = checksum
        .finalize()
        .map_err(|err| aws_smithy_http::operation::BuildError::Other(err))?;

    request.headers_mut().insert(
        aws_smithy_checksums::checksum_algorithm_to_checksum_header_name(checksum_algorithm),
        aws_smithy_types::base64::encode(&amp;checksum[..])
            .parse()
            .expect(&quot;base64-encoded checksums are always valid header values&quot;),
    );

    Ok(())
}
<span class="boring">}
</span></code></pre></pre>
</li>
<li>Building checksum-validated requests with streaming request bodies:
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// Given an `http::request::Builder`, `SdkBody`, and a checksum algorithm name, return a
/// `Request&lt;SdkBody&gt;` with checksum trailers where the content is `aws-chunked` encoded.
pub fn build_checksum_validated_request_with_streaming_body(
    request_builder: http::request::Builder,
    body: aws_smithy_http::body::SdkBody,
    checksum_algorithm: &amp;str,
) -&gt; Result&lt;http::Request&lt;aws_smithy_http::body::SdkBody&gt;, aws_smithy_http::operation::BuildError&gt; {
    use http_body::Body;

    let original_body_size = body
        .size_hint()
        .exact()
        .expect(&quot;body must be sized if checksum is requested&quot;);
    let body = aws_smithy_checksums::body::ChecksumBody::new(body, checksum_algorithm);
    let checksum_trailer_name = body.trailer_name();
    let aws_chunked_body_options = aws_http::content_encoding::AwsChunkedBodyOptions::new()
        .with_stream_length(original_body_size as usize)
        .with_trailer_len(body.trailer_length() as usize);

    let body = aws_http::content_encoding::AwsChunkedBody::new(body, aws_chunked_body_options);
    let encoded_content_length = body
        .size_hint()
        .exact()
        .expect(&quot;encoded_length must return known size&quot;);
    let request_builder = request_builder
        .header(
            http::header::CONTENT_LENGTH,
            http::HeaderValue::from(encoded_content_length),
        )
        .header(
            http::header::HeaderName::from_static(&quot;x-amz-decoded-content-length&quot;),
            http::HeaderValue::from(original_body_size),
        )
        .header(
            http::header::HeaderName::from_static(&quot;x-amz-trailer&quot;),
            checksum_trailer_name,
        )
        .header(
            http::header::CONTENT_ENCODING,
            aws_http::content_encoding::header_value::AWS_CHUNKED.as_bytes(),
        );

    let body = aws_smithy_http::body::SdkBody::from_dyn(http_body::combinators::BoxBody::new(body));

    request_builder
        .body(body)
        .map_err(|err| aws_smithy_http::operation::BuildError::Other(Box::new(err)))
}
<span class="boring">}
</span></code></pre></pre>
</li>
<li>Building checksum-validated responses:
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// Given a `Response&lt;SdkBody&gt;`, checksum algorithm name, and pre-calculated checksum, return a
/// `Response&lt;SdkBody&gt;` where the body will processed with the checksum algorithm and checked
/// against the pre-calculated checksum.
pub fn build_checksum_validated_sdk_body(
    body: aws_smithy_http::body::SdkBody,
    checksum_algorithm: &amp;str,
    precalculated_checksum: bytes::Bytes,
) -&gt; aws_smithy_http::body::SdkBody {
    let body = aws_smithy_checksums::body::ChecksumValidatedBody::new(
        body,
        checksum_algorithm,
        precalculated_checksum.clone(),
    );
    aws_smithy_http::body::SdkBody::from_dyn(http_body::combinators::BoxBody::new(body))
}

/// Given the name of a checksum algorithm and a `HeaderMap`, extract the checksum value from the
/// corresponding header as `Some(Bytes)`. If the header is unset, return `None`.
pub fn check_headers_for_precalculated_checksum(
    headers: &amp;http::HeaderMap&lt;http::HeaderValue&gt;,
) -&gt; Option&lt;(&amp;'static str, bytes::Bytes)&gt; {
    for header_name in aws_smithy_checksums::CHECKSUM_HEADERS_IN_PRIORITY_ORDER {
        if let Some(precalculated_checksum) = headers.get(&amp;header_name) {
            let checksum_algorithm =
                aws_smithy_checksums::checksum_header_name_to_checksum_algorithm(&amp;header_name);
            let precalculated_checksum =
                bytes::Bytes::copy_from_slice(precalculated_checksum.as_bytes());

            return Some((checksum_algorithm, precalculated_checksum));
        }
    }

    None
}
<span class="boring">}
</span></code></pre></pre>
</li>
</ul>
<h2 id="codegen"><a class="header" href="#codegen">Codegen</a></h2>
<p>Codegen will be updated to insert the appropriate inlineable functions for operations that are tagged with the <code>@httpchecksum</code> trait. Some operations will require an MD5 checksum fallback if the user hasn't set a checksum themselves.</p>
<p>Users also have the option of supplying a precalculated checksum of their own. This is already handled by our current header insertion logic and won't require updating the existing implementation. Because this checksum validation behavior is AWS-specific, it will be defined in SDK codegen.</p>
<h2 id="implementation-checklist"><a class="header" href="#implementation-checklist">Implementation Checklist</a></h2>
<ul>
<li><input disabled="" type="checkbox"/>
Implement codegen for building checksum-validated requests:
<ul>
<li><input disabled="" type="checkbox"/>
In-memory request bodies
<ul>
<li><input disabled="" type="checkbox"/>
Support MD5 fallback behavior for services that enable it.</li>
</ul>
</li>
<li><input disabled="" type="checkbox"/>
Streaming request bodies</li>
</ul>
</li>
<li><input disabled="" type="checkbox"/>
Implement codegen for building checksum-validated responses:</li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../rfcs/rfc0015_using_features_responsibly.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next" href="../rfcs/rfc0017_customizable_client_operations.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../rfcs/rfc0015_using_features_responsibly.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next" href="../rfcs/rfc0017_customizable_client_operations.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script type="text/javascript">
            window.playground_copyable = true;
        </script>


        <script src="../elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../searcher.js" type="text/javascript" charset="utf-8"></script>

        <script src="../clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="../book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        <script type="text/javascript" src="../static/mermaid.min.js"></script>
        <script type="text/javascript" src="../static/mermaid-init.js"></script>


    </body>
</html>
